Under review as a conference paper at ICLR 2018
IMPROVING THE IMPROVED TRAINING OF WASSERSTEIN GANS
Anonymous authors Paper under double-blind review
ABSTRACT
Despite being impactful on a variety of problems and applications, the generative adversarial nets (GANs) are remarkably difficult to train. This issue is formally analyzed by Arjovsky & Bottou (2017), who also propose an alternative direction to avoid the caveats in the minmax two-player training of GANs. The corresponding algorithm, namely, Wasserstein GAN (WGAN) hinges on the 1-Lipschitz continuity of the discriminators. In this paper, we propose a novel approach for enforcing the Lipschitz continuity in the training procedure of WGANs. Our approach seamlessly connects WGAN with one of the recent semi-supervised learning approaches. As a result, it gives rise to not only better photo-realistic samples than the previous methods but also state-of-the-art semi-supervised learning results. In particular, to the best of our knowledge, our approach gives rise to the inception score of more than 5.0 with only 1,000 CIFAR10 images and is the first that exceeds the accuracy of 90% the CIFAR10 datasets using only 4,000 labeled images.
1 INTRODUCTION
We have witnessed a great surge of interests in deep generative networks in recent years (Kingma & Welling, 2013; Goodfellow et al., 2014; Li et al., 2015). The central idea therein is to feed a random vector to a (e.g., feedforward) neural network and take the output as the desired sample. This sampling procedure is very efficient without the need of any Markov chains.
In order to train such a deep generative network, two broad categories of methods are proposed. The first is to use stochastic variational inference (Kingma & Welling, 2013; Rezende et al., 2014; Kingma et al., 2014) to optimize the lower bound of the data likelihood. The other is to use the samples as a proxy to minimize the distribution divergence between the model and the real through a two-player game (Goodfellow et al., 2014; Salimans et al., 2016), maximum mean discrepancy (Li et al., 2015; Dziugaite et al., 2015; Li et al., 2017b), f-divergence (Nowozin et al., 2016; Nock et al., 2017), and the most recent Wasserstein distance (Arjovsky et al., 2017; Gulrajani et al., 2017).
With no doubt, the generative adversarial networks (GANs) among them (Goodfellow et al., 2014) have the biggest impact thus far on a variety of problems and applications (Radford et al., 2015; Denton et al., 2015; Im et al., 2016; Isola et al., 2016; Springenberg, 2015; Sutskever et al., 2015; Odena, 2016; Zhu et al., 2017). GANs learn the generative network (generator) by playing a twoplayer game between the generator and an auxiliary discriminator network. While the generator has no difference from other deep generative models in the sense that it translates a random vector into a desired sample, it is impossible to calculate the sample likelihood from it. Instead, the discriminator serves to evaluate the quality of the generated samples by checking how difficult it is to differentiate them from real data points.
However, it is remarkably difficult to train GANs without good heuristics (Goodfellow et al., 2014; Salimans et al., 2016; Radford et al., 2015) which may not generalize across different network architectures or application domains. The training dynamics are often unstable and the generated samples could collapse to restrictive modes. These issues are formally analyzed by Arjovsky & Bottou (2017), who also propose an alternative direction (Arjovsky et al., 2017) to avoid the caveats in the minmax two-player training of GANs. The corresponding algorithm, namely, Wasserstein GAN (WGAN), shows not only superior performance over GANs but also a nice correlation between the sample quality and the value function that GANs lack.
1

Under review as a conference paper at ICLR 2018

1.1 BACKGROUND: WGAN AND THE IMPROVED TRAINING OF WGAN

WGAN (Arjovsky et al., 2017) aims to learn the generator network G(z), for any random vector z  Pz, such that the Wasserstein distance is minimized between the resulting distribution PG over the generated samples {G(z)} and the real distribution Pr underlying the observed data points {x}; in other words, minG W (Pr, PG). The Wasserstein distance W (Pr, PG) is shown a more sensible cost function for learning the distributions supported by low-dimensional manifolds than the other
popular distribution divergences and distances -- in particular, the Jensen-Shannon (JS) divergence
employed in GANs (Goodfellow et al., 2014).

Due to the Kantorovich-Rubinstein duality (Villani, 2008) for calculating the Wasserstein distance, the value function of WGAN is then written as

min
G

max
DD

ExPr

D(x)

- Ez Pz

D(G(z)) ,

(1)

where D the set of 1-Lipschitz functions. Analogous to GANs, we still call D the "discriminator" although it is actually a real-valued function and not a classifier at all. Arjovsky et al. (2017) specify this family of functions D by neural networks and then use weight clipping to enforce the Lipschitz continuity. However, as the authors note, the networks' capacities become limited due to the weight clipping and there could be gradient vanishing problems in the training.

Improved training of WGAN. Gulrajani et al. (2017) give more concrete examples to illustrate the perils of the weight clipping and propose an alternative way of imposing the Lipschitz continuity. In particular, they introduce a gradient penalty term by noting that the differentiable discriminator D(·) is 1-Lipschitz if and only if the norm of its gradients is at most 1 everywhere,

GP |x := Ex xD(x) 2 - 1 2

(2)

where x is uniformly sampled from the straight line between a pair of data points sampled from the model PG and the real Pr, respectively.

Potential caveats. Unlike the weight clipping, however, by no means one can penalize everywhere using this term through a finite number of training iterations. As a result, the gradient penalty term GP takes effect only upon the sampled points x, leaving significant parts of the support domain not examined at all. In particular, consider the observed data points and their underlying manifold that supports the real distribution Pr. At the beginning of the training stage, the generated sample G(z) and hence x could be distant from the manifold. The Lipschitz continuity over the manifold is not enforced until the generative model PG becomes close enough to the real one Pr, if it can.

1.2 OUR APPROACH AND CONTRIBUTIONS

In light of the above pros and cons, we propose to improve the improved training of WGAN by additionally laying the Lipschitz continuity condition over the manifold of the real data x  Pr. Moreover, instead of focusing on one particular data point at a time, we devise a regularization over a pair of data points drawn near the manifold following the most basic definition of the 1-Lipschitz continuity. In particular, we perturb each real data point x twice and use a Lipschitz constant to bound the difference between the discriminator's responses to the perturbed data points x , x .

D

[]

Figure 1 illustrates our main idea. The gradient penalty

G(z) x^ x' x x''

GP |x often fails to check the continuity of region near the real data x, around which the discriminator func- Figure 1: Illustration of our main idea.

tion can freely violate the 1-Lipschitz continuity. We

alleviate this issue by explicitly checking the continuity

condition using the two perturbed version x , x near any observed real data point x.

2

Under review as a conference paper at ICLR 2018

In this paper, we make the following contributions. (1) We propose an alternative mechanism for enforcing the Lipschitz continuity over the family of discriminators by resorting to the basic definition of the Lipschitz continuity. It effectively improves the gradient penalty method (Gulrajani et al., 2017) and gives rise to generators with more photo-realistic samples and higher inception scores (Salimans et al., 2016). (2) Our approach is very data efficient in terms of being less prone to overfitting even for very small training sets. We do not observe obvious overfitting phenomena even when the model is trained on only 1000 images of CIFAR10 (Krizhevsky & Hinton, 2009). (3) Our approach can be seamlessly integrated with GANs to be a competitive semi-supervised training technique (Chapelle et al., 2009) thanks to that both inject noise to the real data points.
As results, we are able to report the state-of-the-art results on the generative model with a inception score of 8.81 ± 0.13 on CIFAR-10, and the semi-supervised learning results of 9.98 ± 0.21 on CIFAR10 using only 4,000 labeled images -- especially, they are significantly better than the existing GAN-based semi-supervised learning results.

2 APPROACH

We firstly review the definition of the Lipschitz continuity and then discuss how to use it to regularize the training of WGAN. We then arrive at an approach that can be seamlessly integrated with the semi-supervised learning method (Chapelle et al., 2009). By bringing the best of the two worlds, we report better semi-supervised learning results than both (Laine & Aila, 2016) and previously GAN-based methods.

2.1 IMPROVING THE IMPROVED TRAINING OF WGAN

Let d denote the 2 metric on an input space used in this paper. A discriminator D : X  Y is Lipschitz continuous if there exists a real constant M 0 such that, for all x1, x2  X ,

d(D(x1), D(x2)) M · d(x1, x2).

(3)

Immediately, we can add the following soft consistency term (CT ) to the value function of WGAN in order to penalize the violations to the inequality in eq. (3),

CT |x1,x2 = Ex1,x2

max

0, d(D(x1), D(x2)) - M d(x1, x2)

(4)

Remarks. Here we face the same snag as in (Gulrajani et al., 2017), i.e., it is impractical to sub-
stitute all the possibilities of (x1, x2) pairs into eq. (4). What pairs and which regions of the input set X should we check for eq. (4)? Arguably, it is fairly safe to limit our scope to the manifold that
supports the real data distribution Pr and its surrounding regions. After all, the distribution of the generative model PG is desired to be as close as possible to Pr. We use the notation M in eq. (3) and a different M in eq. (4) to reflect the fact that the continuity will be checked only sparsely at
some data points in practice.

Perturbing the real data. To this end, the very first version we tried was to directly add Gaussian noise  to each real data point, resulting in a pair of x + 1, x + 2, where x  Pr. However, as noted by Arjovsky et al. (2017) and Wu et al. (2016), we found that the samples from the generator become blurry due to the Gaussian noise used in the training. We have also tested the dropout noise that gives rise to generated MNIST samples, which are cut off here and there.
The success comes after we perturb the hidden layers of the discriminator using dropout, as opposed to the input x. When the dropout rate is small, the perturbed discriminator's output can be considered as the output of the clean discriminator in response to a "virtual" data point x that is not far from x. Thus, we denote by D(x ) the discriminator output after applying dropout to its hidden layers. In the same manner, we find the second virtual point x that is close to x by applying the dropout again to the hidden layers of the discriminator, and denote by D(x ) the corresponding output.
Note that, however, it becomes impossible to compute the distance d(x , x ) between the two virtual data points. In this work, we assume it is a constant and tune M to take account of it -- M is supposed to be fixed as a constant in its original form eq. (4) due to the goal of constraining the discriminators into Lipschitz continuous family. In our experiment, the best results are obtained when M = 0 or M = 0.2. For consistency, we use M = 0 to report all the results in this paper.

3

Under review as a conference paper at ICLR 2018

Algorithm 1 our proposed CT-GAN for training a perfect generator. Most experiments in the paper used the default values 1 = 10,2 = 2, N = 5,  = 0.0002, b = 64, iter = 106

Require: b, the batch size. 1,2, weights. , the Learning rate. iter, number of iterations. 1: for iter of training iterations do

2: for N of iterations do

3: for i = 1, ..., b do

4: Sample real data x  Pr,random vector z  Pz, a random number  U [0, 1]. 5: x^  x + (1 - )G(z)

6: L(i)  D(G(z)) - D(x) + 1GP |x + 2CT |x ,x

7: end for

8:

d



Adam(d

1 b

b i=1

L(i)

,

d,

)

9: end for

10: Sample b random vectors z(i)

11:

g



adam(g

1 b

b i=1

-D(G(z(i))),

g

,



)

12: end for

A consistency regularization. Our final consistency regularization takes the following form,

CT |x ,x = ExPr [max (0, d (D(x ), D(x )) + 0.1 · d (D-(x ), D-(x )) - M )] (5)
where D(x ) is the output of the discriminator given the input x and after we apply dropout to the hidden layers of the discriminator. We envision this is equivalent to passing a "virtual" data point x through the clean discriminator. We find that it slightly improves the performance by further controlling the second-to-last layer D-(·) of the discriminator, i.e., the d (D-(x ), D-(x )) term above.

This new consistent regularization CT |x ,x enforces the Lipschitz continuity over the data manifold and its surrounding regions, effectively complementing and improving the gradient penalty GP |x used in the improved training of WGAN. Putting them together, our new objective function for
updating the weigts of the discriminator is

L = EzPz [D(G(z))] - ExPr [D(x)] + 1GP |x + 2CT |x ,x .

(6)

Algorithm 1 shows the complete algorithm for learning a WGAN in this paper. For the hyperparameters, we borrow 1 = 10 from Gulrajani et al. (2017) and use 2 = 2 for all our experiments no matter on which dataset. Another hyper-parameter is M in eq. (5). As stated previously, M = 0 in our experiments.

2.2 A SEAMLESS CONNECTION WITH A SEMI-SUPERVISED LEARNING METHOD

In this section, we extend the WGAN to a semi-supervised learning approach by drawing insights from two related works.

· Following (Salimans et al., 2016), we modify the output layer of the discriminator such that it has K + 1 output neurons, where K is the number of classes of interest and the additional neuron is reserved for contrasting the generated samples with the real data using the Wasserstein distance in the WGAN. We use a (K + 1)-way softmax as the activation function of the last layer.
· Following (Laine & Aila, 2016), we add our consistency regularization CT |x ,x to the objective function of the semi-supervised training, in order to take advantage of the effect of temporal ensembling.

Figure 2 shows the framework for training the discriminator, with the objective function detailed below,

Lsemi = - Ex,yPx,y [log D(y|x)] - EzPz [log D(K + 1|G(z))]

- ExPr [log(1 - D(K + 1|x))] + CT |x ,x ,

(7)

where the first three terms are the same as in (Salimans et al., 2016), while the last consistency regularization is calculated after we apply dropout to the discriminator. The last term essentially leads

4

Under review as a conference paper at ICLR 2018

cross-entropy

y x augmentation

supervised label

network with dropout

flatten layer

FC with softmax

network with dropout

squared error
flatten layer

squared error
FC with softmax

Weighted sum loss

Figure 2: Framework for the semi-supervised training. For clarity, we have omitted the generator.

(a) GP-WGAN

(b) Ours

Figure 3: Images generated by (a) GP-WGAN (Gulrajani et al., 2017) and (b) Our CT-GAN, respectively.

to a temporal self-ensembling scheme to benefit the semi-supervised learning. Please see (Laine & Aila, 2016) for more insightful discussions about it.
3 EXPERIMENTAL RESULTS
We conduct experiments on the prevalent MNIST (LeCun et al., 1998), and CIFAR10 (Krizhevsky & Hinton, 2009) datasets. The code will be released for reproducibility of our results.
3.1 MNIST
The MNIST dataset provides 70,000 handwritten digits in total, and 10,000 of them are often left out for the testing purpose. Following (Gulrajani et al., 2017), we use only 1,000 of them to train the WGAN for a fair comparison with it. However, we use all the 60,000 training examples in the semi-supervised learning experiments and reveal the labels of 100 of them (10 per class). This setup is the same as in (Rasmus et al., 2015). Please see the Appendix for the network architectures of the generator and discriminator, respectively.
Qualitative results. Figure 3 shows the generated samples with improved training of WGAN by the gradient penalty (GP-WGAN), and ours with the consistency regularization (CT-WGAN), respectively, after 50,000 generator iterations. It is clear that our approach gives rise to more realistic samples than GP-WGAN. The contrasts of our samples between the foreground and the background are in general sharper than those of GP-WGAN.
Overfitting. We find that our approach is less prone to overfitting. To demonstrate this point, we show the convergence curves of the discriminator's value functions by GP-WGAN and our CT-GAN in Figure 4. The red curves are evaluated on the training set and the blue ones are on the test set. We can see that the results on the test set become saturated pretty early in GP-WGAN, while ours can consistently decrease costs on both the training and the test sets. This observation also holds for the CIFAR10 dataset.
5

Under review as a conference paper at ICLR 2018

negtive discriminator cost negtive discriminator cost

10 train_disc_cost
8 test_disc_cost
6
4
2
0
-20 100 200 300 400 500 generator iteration (x102)
(a)

10 train_disc_cost
8 test_disc_cost
6
4
2
0
-20 100 200 300 400 500 generator iteration (x102)
(b)

Figure 4: Convergence curves of the discriminator cost: (a) GP-WGAN and (b) Our CT-GAN.

Table 1: Comparing our semi-supervised learning approach with state-of-the-art ones on MNIST.

Method

Test error (%)

Ladder (Rasmus et al., 2015) VAT (Miyato et al., 2017) CatGAN (Springenberg, 2015) Improved GAN (Salimans et al., 2016) Triple GAN (Li et al., 2017a) Our CT-GAN

1.06±0.37
1.36 1.39±0.28 0.93±0.065 0.91±0.58 0.89 ± 0.13

Semi-supervised learning results. We compare our semi-supervised learning results with those of several competitive methods in Table 1. Our approach is among the best on this MNIST dataset.
3.2 CIFAR10
CIFAR10 (Krizhevsky & Hinton, 2009) contains natural images of 32×32. We train the WGAN using only 1,000 images again. For the semi-supervised learning approach, we follow the standard training/test split of the dataset but use only 4,000 labels in the training. Please see the Appendix for the network architectures.
Semi-supervised learning. First of all, we report the semi-supervised learning results in Table 2. The mean and standard errors are are obtained by running the experiments 5 rounds. Comparing to several very competitive methods, ours is able to achieve state-of-the-art results. Notably, our CT-GAN outperfroms all the GAN based methods by a large margin.
Qualitative results. Figure 5 contrasts the samples we generated to those by GP-WGAN when the generator is a small-scale convolutional neural network (detailed in the Appendix). Figure 7 shows the results by a larger-scale ResNet. Our results are more photo-realistic. Additionally, we also draw the histograms of the discriminator's weights in Figure 6 after we train it using GP-WGAN and CT-GAN, respectively. It is interesting to see that ours controls the weights within a smaller and more symmetric range [-0.67, 0.96] than the [-2.00, 10.12] by GP-WGAN, partially explaining why our approach is less prone to overfitting.
6

Under review as a conference paper at ICLR 2018

Table 2: Comparing our semi-supervised learning approach with state-of-the-art ones on CIFAR10

Method

Test error (%)

Ladder (Rasmus et al., 2015) VAT (Miyato et al., 2017) TE (Laine & Aila, 2016) Teacher-Student (Salimans et al., 2016) CatGANs (Salimans et al., 2016) Improved GANs (Salimans et al., 2016) ALI (Dumoulin et al., 2016) Triple GAN (Li et al., 2017a) Improved semi-GAN (Kumar et al., 2017) Our CT-GAN

20.40±0.47
10.55 12.16±0.24 12.31±0.28 19.58±0.58 18.63±2.32 17.99±1.62 16.99±0.36 16.78±1.80 9.98 ± 0.21

(a) (b)
Figure 5: Generated samples from GP-WGAN and our CT-GAN. Here the generator is a small-scale convolutional neural network (ref. Appendix). See Figure 7 for the samples by a ResNet.

40000 30000 20000 10000
0 0.4 0.3 0.2 0.1 0.0 0.1 0.2 0.3 0.4
(a)

40000 30000 20000 10000
0 0.4 0.3 0.2 0.1 0.0 0.1 0.2 0.3 0.4
(b)

Figure 6: Histograms of the weights of the discriminators trained by (a) GP-WGAN and (b) CTGAN, respectively.

Comparison of the inception scores. Finally, we compare our approach with GP-WGAN on the whole CIFAR10 training set for both unsupervised and supervised generative-purpose task using ResNet. For model selection, we use the the first 50,000 samples to compute the inception scores (Salimans et al., 2016), then choose the best model, and finally report the "test" score on another 50,000 samples. The experiment follows the previous setup in (Odena et al., 2016). From the comparison results in Tables 3, we conclude that our proposed model achieves the highest inception score in the CIFAR10 dataset, to the best of our knowledge. Correspondingly, the generated samples are shown in Figure 7.
7

Under review as a conference paper at ICLR 2018

Table 3: Inception score and accuracy of different models on CIFAR-10

Method

Supervised IS Unsupervised IS Accuracy(%)

SteinGANs (Wang & Liu, 2016) DCGANs (Wang & Liu, 2016) Improved GANs (Salimans et al., 2016) AC-GANs (Odena et al., 2016) GP-WGAN (Gulrajani et al., 2017) SGANs (Huang et al., 2016) ALI (Warde-Farley & Bengio, 2016) BEGAN (Berthelot et al., 2017) EGAN-Ent-VI (Dai et al., 2017) DFM (Warde-Farley & Bengio, 2016) Our CT-GAN

6.35 6.58 8.09±0.07 8.25±0.07 8.42±0.10 8.59±0.12 ­ ­ ­ ­ 8.81±0.13

­ 6.16±0.07
­
­ 7.86±0.07
­ 5.34±0.05
5.62 7.07±0.10 7.72±0.07 8.12±0.12

­ ­ ­ ­ 91.85 ­ ­ ­ ­ ­ 95.91

(a) (b) Figure 7: Generated samples by our model. (a). Generated samples by unsupervised model. (b). Generated samples by supervised model, each column corresponds to one class which is consistent with the CIFAR-10 dataset.
4 CONCLUSION
In this paper, we present a consistency term derived from Lipschitz inequality, which boosts the performance of GANs model. The proposed term has been demonstrated to be an efficient manner to ease the over-fitting problem when data amount is limited. Experiments show that our model obtains the state-of-the-art accuracy and Inception score on CIFAR-10 dataset for both semi-supervised learning task and generative model.
8

Under review as a conference paper at ICLR 2018
REFERENCES
Martin Arjovsky and Le´on Bottou. Towards principled methods for training generative adversarial networks. arXiv preprint arXiv:1701.04862, 2017.
Martin Arjovsky, Soumith Chintala, and Le´on Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875, 2017.
David Berthelot, Tom Schumm, and Luke Metz. Began: Boundary equilibrium generative adversarial networks. arXiv preprint arXiv:1703.10717, 2017.
Olivier Chapelle, Bernhard Scholkopf, and Alexander Zien. Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]. IEEE Transactions on Neural Networks, 20(3):542­542, 2009.
Zihang Dai, Amjad Almahairi, Philip Bachman, Eduard Hovy, and Aaron Courville. Calibrating energy-based generative adversarial networks. arXiv preprint arXiv:1702.01691, 2017.
Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative image models using a laplacian pyramid of adversarial networks. In Advances in neural information processing systems, pp. 1486­1494, 2015.
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropietro, and Aaron Courville. Adversarially learned inference. arXiv preprint arXiv:1606.00704, 2016.
Gintare Karolina Dziugaite, Daniel M Roy, and Zoubin Ghahramani. Training generative neural networks via maximum mean discrepancy optimization. arXiv preprint arXiv:1505.03906, 2015.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672­2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. arXiv preprint arXiv:1704.00028, 2017.
Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, and Serge Belongie. Stacked generative adversarial networks. arXiv preprint arXiv:1612.04357, 2016.
Daniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, and Roland Memisevic. Generating images with recurrent adversarial networks. arXiv preprint arXiv:1602.05110, 2016.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional adversarial networks. arXiv preprint arXiv:1611.07004, 2016.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems, pp. 3581­3589, 2014.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. 2009.
Abhishek Kumar, Prasanna Sattigeri, and P Thomas Fletcher. Improved semi-supervised learning with gans using manifold invariances. arXiv preprint arXiv:1705.08850, 2017.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint arXiv:1610.02242, 2016.
Yann LeCun, Le´on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278­2324, 1998.
Chongxuan Li, Kun Xu, Jun Zhu, and Bo Zhang. Triple generative adversarial nets. arXiv preprint arXiv:1703.02291, 2017a.
9

Under review as a conference paper at ICLR 2018
Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, and Barnaba´s Po´czos. Mmd gan: Towards deeper understanding of moment matching network. arXiv preprint arXiv:1705.08584, 2017b.
Yujia Li, Kevin Swersky, and Rich Zemel. Generative moment matching networks. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pp. 1718­1727, 2015.
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual adversarial training: a regularization method for supervised and semi-supervised learning. arXiv preprint arXiv:1704.03976, 2017.
Richard Nock, Zac Cranko, Aditya Krishna Menon, Lizhen Qu, and Robert C Williamson. f-gans in an information geometric nutshell. arXiv preprint arXiv:1707.04385, 2017.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers using variational divergence minimization. In Advances in Neural Information Processing Systems, pp. 271­279, 2016.
Augustus Odena. Semi-supervised learning with generative adversarial networks. arXiv preprint arXiv:1606.01583, 2016.
Augustus Odena, Christopher Olah, and Jonathon Shlens. Conditional image synthesis with auxiliary classifier gans. arXiv preprint arXiv:1610.09585, 2016.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semisupervised learning with ladder networks. In Advances in Neural Information Processing Systems, pp. 3546­3554, 2015.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234­2242, 2016.
Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative adversarial networks. arXiv preprint arXiv:1511.06390, 2015.
Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim Lillicrap, and Oriol Vinyals. Towards principled unsupervised learning. arXiv preprint arXiv:1511.06440, 2015.
Ce´dric Villani. Optimal transport: old and new, volume 338. Springer Science & Business Media, 2008.
Dilin Wang and Qiang Liu. Learning to draw samples: With application to amortized mle for generative adversarial learning. arXiv preprint arXiv:1611.01722, 2016.
David Warde-Farley and Yoshua Bengio. Improving generative adversarial networks with denoising feature matching. 2016.
Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, and Roger Grosse. On the quantitative analysis of decoder-based generative models. arXiv preprint arXiv:1611.04273, 2016.
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593, 2017.
10

Under review as a conference paper at ICLR 2018

Appendices
Table 4 (MNIST) and Table 5 (CIFAR-10) detail the network architectures used in our classificationpurpose CT-GAN, where the classifier is similar to the wildly used ones in most semi-supervised networks Laine & Aila (2016) except that we apply weight-norm rather than batch-norm. For the generator, we follow the improved GANs Salimans et al. (2016) structure, but in order not to reproduce the complicated images that aims to train a generator, we use less 50-dimensional noise as the input of generator.
For the Conv-large based networks used in CIFAR-10, they are all trained using Adam with a learning rate of 0.0003 and epochs 900. Adam momentum parameters are set to 1 = 0.5 and 2 = 0.999 by default.

Table 4: MNIST

Classifier C Input: Labels y, 28*28 Images x, Gaussian noise 0.3, MLP 1000, ReLU Gaussian noise 0.5, MLP 500, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 250, ReLU Gaussian noise 0.5, MLP 10, Softmax

Generator G Input: Noise 100 z MLP 500, Softplus, Batch norm MLP 500, Softplus, Batch norm MLP 784, Sigmoid, Weight norm

Table 5: CIFAR-10

Classifier C Input: Labels y, 32*32*3 Colored Image x,
0.2 Dropout 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =1, Stride =2, lReLU, Weight norm
0.5 Dropout 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =1, Stride =2, lReLU, Weight norm
0.5 Dropout 3*3 conv. 512, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 256, Pad =0, Stride =1, lReLU, Weight norm 3*3 conv. 128, Pad =0, Stride =1, lReLU, Weight norm
Global pool MLP 10, Weight norm, Softmax

Generator G Input: Noise 50 z MLP 8192, ReLU, Batch norm Reshape 512*4*4 5*5 deconv. 256*8*8, ReLU, Batch norm
5*5 deconv. 128*16*16, ReLU, Batch norm
5*5 deconv. 3*32*32, Tanh, Weight norm

For the generative purpose model, to give a fair comparison, the structure and hyper-parameters are kept exactly the same as in Gulrajani et al. (2017), except that we add three more layers of dropout inside hidden layers. For further architectural details, please refer to the code or Gulrajani et al. (2017).
In our experiments, we found that although the GP-WGAN (Gulrajani et al., 2017) applied lipschitz constraint on input sampling points, the actual reflected restriction on the 2 norm of the gradient is not so good as our CT-GAN model, we illustrate this fact in Figure 8. This further demonstrates that the influence of our soft Lipschitz constraint is more effective than the GP-WGAN (Gulrajani et al., 2017).
11

L-2 norm of gradient

Under review as a conference paper at ICLR 2018
2.4 CT-GAN GP-W GAN
2.2 2
1.8 1.6 1.4 1.2
10 50 100 150 200 250 generator iteration (×102)
Figure 8: The maximum 2 norm of gradients on CIFAR-10 testing set in each iteration with training of 1000 images selected from CIFAR-10 training set.
12

