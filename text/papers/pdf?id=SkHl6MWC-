Under review as a conference paper at ICLR 2018
REGULARIZATION NEURAL NETWORKS VIA CONSTRAINED VIRTUAL MOVEMENT FILED
Anonymous authors Paper under double-blind review
ABSTRACT
We provide a novel thinking of regularization neural networks. We smooth the objective of neural networks w.r.t small perturbations of the inputs. Different from previously works, we assume the perturbations are caused by the movement field. When the magnitude of movement field approaches 0, we call it virtual movement field. We measure the smoothness of the objective when virtual movement field is applied to inputs. By adding proper geometrical constraints to the movement field, this smoothness can be approximated in close-form. We define this approximated smoothness as the regularization term. By introducing the movement field, we provide the geometric meaning of the perturbations and the regularization terms. We derive three regularization terms which measure the smoothness w.r.t shift, rotation and scale respectively by adding different constraints into the movement field. We evaluate our methods on synthetic data, MNIST dataset and CIFAR-10 dataset. Experimental results show that our proposed method can significantly improve the baseline neural networks.
1 INTRODUCTION
Deep neural networks have achieved great success in recent years Lecun et al. (2015). By improving the depth of computational graphs and the accounts of trainable parameters, neural networks can fit the training dataset better. However, overfitting becomes a serious problem in supervised training especially when the free parameters are numerous.
One of the most effective ways to against overfitting is adding regularization terms into the original supervised objective function. Many regularization methods have been proposed for training neural networks, such as dropout Srivastava et al. (2014) and its variants Wang & Manning (2013); Kingma et al. (2015). From a Bayesian perspective, dropout regularizes neural networks by introducing randomness into the parameters. Another regularization way to against overfitting is generating new data by transform or perturbation the existing data. The objective of the generated data or the smoothness w.r.t the small perturbations can be regarded as a regularization term. Bachman et al. (2014) assume the perturbations are fully random. They use the model's sensitivity to those random perturbations in their construction of the regularization function. However, Goodfellow et al. (2015); Szegedy et al. (2014) found the robustness of neural networks can't be improved sufficiently with random noise. Instead of using randon pertubations, adversarial training (AT) Goodfellow et al. (2015) and virtual adversarial training (VAT) Miyato et al. (2016) find the so called adversarial perturbations by optimizing some objectives under simple constraints, such as L norm and L2 norm. Specifically, AT selects the adversarial perturbation direction which maximizes the objective of neural networks. This lead to set the direction of perturbation the same as the gradients of objective w.r.t the inputs. Once the optimal perturbation is obtained, they apply it to the inputs and get the perturbated inputs. Then AT minimizes the objective of both the original inputs and the perturbated inputs. VAT follows similar spirits of AT. The key difference is that VAT obtains the optimal perturbation by maximizing Kullback-Leibler divergence (KLD) between the outputs of models. This makes VAT applicable for semi-supervised learning. VAT also designs an iterative algorithm to approximate the optimal perturbation. Experimental results demonstrate that AT and VAT against the adversarial perturbation as well as improve the generalization ability of neural networks.
However, there are two drawbacks of AT and VAT.
1

Under review as a conference paper at ICLR 2018

· For a single batch of data, both AT and VAT need to run at least two farward-backward loops to complete the training process, which is time-consuming for big models.
· The obtained optimal perturbation lacks interpretability. For human perception, it is hard to fully understand why those adversarial perturbations are most likely to fool neural networks.
We try to overcome the above drawbacks by introducing constraints into the space of perturbations. In this work, we assume perturbations are caused by the movement filed of the lattice structured data, such as speech signals, images and videos. Movement field represents the motion vector of each pixel in the lattice. We call it virtual movement field when the magnitude of the movement field is sufficiently small. We smooth the objective of neural networks when the virtual movement field is applied to the inputs. In fact, smoothing the model often works to our advantage in practice. Inspired by AT, we first find the so called adversarial movement field which maximizes above sensibility under a set of constraints. This can be done in close-form if the set of constraints are carefully designed. We regard this sensibility term as a regularization term and we minimize the objective of neural networks together with this regularization term. We call our method as virtual movement training (VMT).
We summarize the advantages of VMT as follows:
· With appropriate constraints, the adversarial movement field and the corresponding sensibility term are obtained in close-form. Moreover, because the movement field and the perturbation caused by this field are virtual, it is unnecessary to get the pertubated inputs. Thus, the training process of each batch is completed in a single forward-backward loop which yields lower computational costs.
· By assuming that perturbations are caused by the movement filed and by introducing constraints into the movement filed, we make the adversarial perbutions much more interpretable.
· The priors can be embodied in constraints of the movement field.
In this work, we focus more on computational efficiency and geometrical interpretability of our method instead of againsting adversarial examples Szegedy et al. (2014). We derive three simple regularization terms based on introducing different constrains (shift, rotation and scale) into movement fields. These regularization terms measure how sensitive of neural networks under virtual (extremely small) shift, rotation and scale perturbations respectively.
We evaluate our method in a 1D synthetic data and two benchmark image classification datasets: MNIST and CIFAR-10. Experimental results demonstrate that our method remarkablely improves the baseline neural networks and is comparable to AT and VAT. In CIFAR-10, the running time of our method is significantly lower than the running time of AT and VAT.

2 METHODS

We first formally define the movement field and the virtual movement field. Then we formulate our method. Finally we provide three running examples.

2.1 VIRTUAL MOVEMENT FIELD

For data I  Rd1×d2···×dn , i.e. n dimension lattice structure and the length of ith dimension is di, we define the movement field V of as a n + 1 dimension tensor, that is V  Rd1×d2···×dn×n. Denote p  Zn as the position vector of I and Ip is the value in that position. Then Vp  Rn is the movement of location p, i.e. its new position would be p + Vp. Note that for 2 dimension lattice data such as images, their movement field is somewhat similar to the concept of optical flow. However,

throughout this paper, we still use the word of "movement field" because it is generalized to any

dimension of lattice data. If we assume data I is sampled from a underlying continues space or the

first order derivatives of I exists, we can approximate the value of the new position with the first

order Taylor series of the value of original position (when the movement is small). Formally

Ip+Vp = Ip +

Ip p

T
Vp

(1)

2

Under review as a conference paper at ICLR 2018

For Vp, there are two factors: the length and the direction. In some cases, we want to decompose those two factors. So we normalize it as follows:

Vp =

Vp E[VpT Vp]

(2)

Then the averege square length of V is equal to one. Denote V as the actual movement filed. We

call  the degree of the movement field. When  approaches 0, we call V the virtual movement field.

And in this paper, we always assume  approaches 0. Based on Eq.(1) and (2), if V is given, we

have:

Ip = 

Ip p

T
Vp

(3)

2.2 PROBELM FORMULATION

Given a dataset D = {(In, yn)|n = 1, 2, . . . , N }, where In and yn are ith pair of input and lable in D. Denote f as a function which is parameterized by . f maps the input space into the output space. For each pair of {In, yn}, we minimize the predefined loss function between the predicted

output and the label w.r.t .

arg min L(In, yn)


(4)

We hope L is stable for some particular kind of movements of I, e.g. rotation for images. We

can apply a small movement V to In and we get the new input In(V ). Since V is normalized.

Intuitively, we can measure the smoothness of L under the movement field V as follows:

L(In(V ), yn) - L(In, yn) 

(5)

That is the proportion between the change of objective and a small degree of inputs movement. When
training neural networks, in order to obtain the abouve smoothness, we need to run the forward com-
putational gragh two times: the one for L(In, yn), the another for L(In(V ), yn). However, in this work, we are interested in the extreme situation of Eq.(5): what if we apply a virtual movement field to Ip? Or how sensitive the objective w.r.t  when   0. Note that L can be reparameterized as a function of  by fixing other variables. Thus when   0, Eq.(5) is equivalent to

L() - L(0) L

lim =

0



 In,yn,,V

(6)

By the chain rule for differentiation

L =

L Ip

 p Ip 

(7)

Substitute Eq.(3) into it, we have

L L =
 p Ip

Ip p

T
Vp

(8)

The first term in the right side of the above equation is the gradient of objective w.r.t input which is easily obtained by back propagation. The second term is the gradient of input w.r.t its coordinates which is also called the directional derivative of signal. For discrete signal, it is approximated by
finite difference operator in practice. Thus, if V is given, we can obtain the smoothness of the objective when the corresponding virtual movement field applied to the input in a single forwardbackward loop.

However, the degree of freedom of V is extremely high for real-world data. We need to introduce
constraints into V . Those constraints should embody the priors of data and physical mechanisms of how it are generated. For example, the movement field of natural images should enjoy the properties of local smoothness and isotropy. We denote the set of constraints as C(V ). Note that the

3

Under review as a conference paper at ICLR 2018

14 12 10 8 6 4 2 00 2 4 6 8 10 12 14
(a) Shift

14 12 10 8 6 4 2 00 2 4 6 8 10 12 14
(b) Rotation

14 12 10 8 6 4 2 00 2 4 6 8 10 12 14
(c) Scale

Figure 1: Three kinds of movement fields: shift, rotation and scale are shown in (a), (b) and (c) respectively. These fields are generated in a 15 × 15 image.

Table 1: Summarization of movement fields and their corresponding regularization terms. The meaning of symbols can be find in section 2.2.

Vpshif t =

cos  sin 

Vprotation

=

1 Z

-p2 - c1 p1 - c2

Vpscale

=

1 Z

(p1 - c1) cos  (p2 - c2) sin 

Rshif t d=ef

L Ip p Ip p1

2
+

L Ip 2 p Ip p2

Rrotation d=ef

L p Ip

Ip T p

Vprotation

Rscale

d=ef

1 Z

p

L Ip

Ip p1

(p1

-

c1)

2
+

p

L Ip

Ip p2

(p2

-

c2)

2

normalization constraint in Eq.(2) is included in C(V ). We can expect that the degree of freedom of

V is sufficiently reduced under those constraints. If there are still freedom of V , we can randomly draw samples over those freedom. However, inspired by the adversarial training, we first find the adversarial movement field V  which maximizes the sensitivity of neural networks then we minimize the sensitivity of neural networks plus the original objective w.r.t  under V . Similar with the generative adversarial networks (GAN) Goodfellow et al. (2014), above problem can be formulated as a min-max game under constraints:

min max
V

L(I, y) + 

L 

I,V ,y,

,

s.t. C(V )

(9)

Once V  is obtained by solving the above max problem, the second term in 9 is determined (See Eq.(8)). We call it as the corresponding regularization term of V . Then 9 is reduced to

min L(I, y) + R(V )


(10)

Generally, solving the max problem in 9 is not an easy task. However, we will show that V  can be obtained in close-form if the constraint set is carefully designed. And in this paper, we just fous on this simple case because we hope to train each batch of data in a single forward-backward loop.

2.3 DESIGN THE MOVEMENT FIELD

Now we provide three sets of constraints for V which make the corresponding V  solved in closeform. All these movement fields are designed for 2D lattice data since image is one of the most important types of data in real world.

The first one is called Shift field. That is all pixels in 2D lattice are shifted by a same vector. Because V is normalized, the only freedm is the direction of the vector in 2D space. Formally

Vpshift = (cos , sin )T , p Combination Eq.(11) and Eq.(8), the max-subproblem in 9 is equivalent to

(11)

max


L Ip cos  + p Ip p1

L Ip sin  p Ip p2

(12)

4

Under review as a conference paper at ICLR 2018

where p1 and p2 are the first coordinate and the second coordinate of an image respectively. Then the optimal value of  is obtained easily. And the corresponding maximum value of |L/| in this

case is

Rshif t d=ef

2
L Ip + p Ip p1

2
L Ip p Ip p2

(13)

The second movement field is rotation field. In this work, we simply assume the center of rotation is the center of the image, i.e. (c1, c2).

Vprotation

=

1 Z

(-p2

-

c1,

p1

-

c2)T

(14)

where Z is the normalization constant described in Eq.(2). Thus the degree of freedom is 0 (The direction of rotation doesn't matter because we care about the absolute value of L/). Then Rrotation is obtained straightforwardly.

The third movement field is scale field which scales an image by different factors along two coordinates. Thus the degree of freedom is 1. We parameterize it by

Vpscale

=

1 Z ((p1

-

c1) cos , (p2

-

c2) sin )T

(15)

Then Rscale is obtained in a similar way as Rshift. We summary these three movement fileds and their corresponding derived regularization terms in Tab 2.3. Althrough other kinds of movement fields are possible to be designed, we just use these three movement fields to evaluate our method because they are simple, easy to implementation and geometrically meaningful.

2.4 PRACTICAL CONSIDERATIONS

As mentioned in section 2.2, for lattice data, the directional gradients are approximated by finite difference operator. In this work, we choose the simplest one:

Ix  Ix+1 - Ix-1 x 2

(16)

where x is an arbitrary coordinate in p. If the local smooth property is not well satisfied, above approximation is not accurate. This suggests that our method is more suitable for smooth data.

Another problem is that we find the magnitudes of L/I change rapidly with the network configurations. This makes the values of the corresponding regularization terms change rapidly with the network configurations. To keep the values of R in a stable range, we normalize L/I into a unit tensor.

3 DISCUSSTION AND RELATED WORKS

Our work was mainly motivated by the adversarial training Goodfellow et al. (2015) and was related

to the virtual adversarial training Miyato et al. (2016). Adversarial training can be reformulated as

follows:

min max L(I, y) + L(I + I, y), s.t. ||I|| < 1
 I

(17)

and I is approximated by sign(L/I) in their paper because the only constraint of I is L

norm. However, in our work, we assume I is caused by the movement field V . That is

I(V )  I + I

(18)

That is the perturbation I is constrained by both the movement field V and the directional gradients of I, instead of the simple norm constraint. Another key difference between AT and our method is   0 in our work, thus it is unnecessary to generate I + I and run additional forward-backward loop. By setting  sufficiently small, 17 is equivalent to

L

min max
 I

(1 + )L(I, y) +   I,I,y,

(19)

5

Under review as a conference paper at ICLR 2018

This formulation is similar with ours which suggests our method is an extreme case of AT if we ignore the difference between constraints of perturbations.
Denote f as the forward function of neural networks parameterized by . Then virtual adversarial training can be reformulated as follows:

min max L(I, y) + KLD[f(I)||f(I + I)], s.t. ||I||2 < 1
 I

(20)

The core difference between VAT and AT is that VAT minimizes KLD of the outputs of neural networks under adversarial pertubations. This property makes VAT applicable for semi-supervised learning. However, the KLD term makes it difficult to find the optimal perturbation. Thus Miyato et al. (2016) developed an iterative algorithm for approximation (their algorithm performs well in only one iteration).
Conceptually, our work was also related to data augmentation, such as image shift, image rotation and image scale. Roughly speaking, data augmentation methods generate new data by applying geometry transitions to original data. The degree of those geometry transitions should be large enough. For example, when applying image shift, images are shifted at least one pixel. In our work, we apply geometry transitions to data by design the corresponding movement fields. However, these geometry transitions are virtual because the degree of the movement fields close to 0. That is our work is an extreme case of data augmentation when particular movement fields are designed. Thus although not evaluated, we believe our method is complementary with data augmentation.
In summary, we focus more on computational efficiency and geometrical interpretability of our method. Thus our method is not required to be better than VT and VAT. However, we still compare them in next section.

4 EXPERIMENTAL RESULTS
We evaluate our proposed method for supervised classifications in three datasets: 1D synthetic dataset, MNIST and CIFAR-10. We compare it with the baseline, adversarial training with L2 constraint and virtual adversarial training. For each dataset, the shared hyper-parameters keep same for all methods. While separate hyper-parameters are tuned by cross-validation or copied from literature if they are provided. All neural networks are implemented in Tensorflow. We call our method VMT-shift, VMT-rotation and VMT-scale when we use the corresponding regularization terms.

4.1 THE BINATY CLASSIFICATION OF 1D SYNTHETIC DATASET

We create a 1D synthetic dataset with two classes using th following random process:

x = sin(t + ) +    U(0,  ) 2
  N (0, 0.12)

(21)

where t  R100 is uniformly sampled from [-2, 2]. Thus x  R100 is a 1D lattice signal. Based on Eq.(21), we generate 5000 positive samples by setting  = 0.99 and 5000 negtive samples by setting  = 1.01. We randomly select 1000 samples as training set and the rest as test set. We train neural networks with two hidden layers each of which is followed by batch normalization Ioffe & Szegedy (2015) and ReLU activation Glorot et al. (2011). We set batchszie to 20 and run 100 epoches using ADAM optimizer Kingma & Ba (2015). We run each method 5 times and report the average test errors. We summarize the results in Tab 2. VMF-shift is significantly better than the baseline.
We also show how the test values of Rshift change for different methods over training epoches in Fig.(2). The values of Rshift are consistent with the performances of methods.This suggests that Rshift is a appropriate regularization term which can reflect the generalization ability of models on our hand-created data.

6

Under review as a conference paper at ICLR 2018

1.5
negetive positive
1.0 0.5 0.0 0.5 1.0 1.50 20 40 60 80 100
(a) Samples

0.60

Baseline

0.55

AT VAT

0.50 VMT-scale

0.45

0.40

0.35

0.30

0.25

0.200 20 40 60 80 100

(b) Rshift

Figure 2: (a) shows an example pair of data with different labels. They are hard to distinguish by human-eye. (b) shows the value of Rshift for different methods over epoches.

Table 2: Test errors (%) on MNIST and synthetic dataset. Test errors in the upper panel are the ones

reported in the literature while test errors in the bottom panel are the results of our implementation.

Methods

Synthetic MNIST

Dropout Srivastava et al. (2014) AT(with L constraint) Goodfellow et al. (2015)
Baseline AT(with L2 constraint)
VAT VMF-shift(ours) VMF-rotation(ours) VMF-scaling(ours)

1.24 0.94 0.76 0.89 -

0.95 0.78 1.12 0.70 0.64 0.92 0.95 0.92

4.2 THE CLASSIFICATION OF MNIST DATASET
We tested the performance of our regularization method on the MNIST dataset, which consists of 28 by 28 pixel images of handwritten digits and their corresponding labels from 0 to 9. We split the original 60,000 training samples into 50,000 training samples and 10,000 validation samples and use validation samples for tuning the hyperparameters. After the hyperparameters are tuned, we train our models using the whole 60000 samples. For network structures, we follow the setting used in Miyato et al. (2016). Specifically, we train NNs with 4 hidden dense layers with nodes (1200, 600, 300, 150) respectively. Each hidden layer is followed by batch normalization and ReLU activation.
We apply all of the three regularization terms in Tab 2.3 and compare them with the baseline, AT and VAT. We run each method 5 times with different seeds for the weight initialization, and report the average test errors. The results are summarized in Tab 2 which show our methods are inferior than AT and VAT but are significantly better than the baseline.

Table 3: Test errors (%) and running time (s) on CIFAR10 dataset. Running time in this table means

the average training time of each epoch (including the test phase).

Methods

Test err Time

Baseline AT(with L2 constraint)
VAT VMT-shift(ours) VMT-rotation(ours) VMT-scale(ours) VMT-all(ours)

10.79 10.42 9.62 9.68 9.75 9.74 9.31

32.73 60.97 65.47 43.05 43.07 43.08 43.14

7

Under review as a conference paper at ICLR 2018

5.0

Baseline

4.5

AT VAT

VAT-all

4.0 VMT-move

3.5

3.0

2.5

2.0

1.50 10 20 30 40 50 60 70 80

(a) Rshift

2.2

Baseline

2.0

AT VAT

1.8

VAT-all VMT-rotation

1.6

1.4

1.2

1.0

0.8

0.60 10 20 30 40 50 60 70 80

(b) Rrotation

5.5

Baseline

5.0 AT

4.5

VAT VAT-all

4.0 VMT-scale

3.5

3.0

2.5

2.0

1.5

1.00 10 20 30 40 50 60 70 80

(c) Rscale

Figure 3: (a), (b) and (c) show the value of Rshift, Rrotation and Rscale respectively for different methods over epoches.

4.3 THE CLASSIFICATION OF CIFAR10 DATASET
We also conducted studies on the CIFAR-10 dataset which consists of 50000 training images and 10000 testing images in 10 classes, each image with size 32×32×3. Our focus is on the behaviors of different regularization methods, but not on pushing the state-of-the-art results, so we use a relative relatively small neural network for evaluation and comparision of those regularization methods. Specifically, we configure the neural networks as the 'conv-small' used in Salimans et al. (2016) which consists 9 convolutional layers. We train the nerual networks by SGD with momentum with 80 epoches. The learning rate is set to 0.2. Then we reduce it by factor 10 in 40th and 60th epoch. We evaluate the test errors and the average traning time of each epoch (including the test phase). VMT-all means we use all the regularization terms in Tab 2.3 and randomly weight them for each batch.
Results are summarized in Tab 3. All our regularization terms are significantly better than the baseline and AT. And they are competitive compared with VAT. When we mix Rshift, Rrotation and Rscale (we call it VMT-all), the performance is further improved by a relatively large margin. And our method is faster than AT and VAT. We show the values of the regularization terms in Fig.(3). Except for AT, these values can reflect the generalization ability of models.
5 CONCLUSIONS
In this paper, we have provided a novel thinking of regularization neural networks. We smooth the objective function of neural networks when the virtual moment field is applied to lattice data. By carefully introducing constraints into the movement field, we have derived the smoothness in closeform. We have provided three regularization terms which measure the smoothness w.r.t the transformations of shift, rotation and scale respectively. Experimental results demonstrate that our method remarkablely improves the baseline neural networks in 1D hand-created data, MNIST dataset and CIFAR-10 dataset.
The simplicity and interpretability of our method are also worth re-emphasizing. Unlike the adversarial training, the training process of each batch is completed in a single forward-backward loop. Moreover, we assume the perturbations are caused by the movement field. By control the movement field, we can understand the geometric meaning of perturbations and what kind of smoothness the regularization term is measured.
REFERENCES
Philip Bachman, Ouais Alsharif, and Doina Precup. Learning with pseudo-ensembles. neural information processing systems, pp. 3365­3373, 2014.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier neural networks. 15: 315­323, 2011.
8

Under review as a conference paper at ICLR 2018
Ian J Goodfellow, Jean Pougetabadie, Mehdi Mirza, Bing Xu, David Wardefarley, Sherjil Ozair, Aaron C Courville, and Yoshua Bengio. Generative adversarial networks. arXiv: Machine Learning, 2014.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. international conference on learning representations, 2015.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. international conference on machine learning, pp. 448­456, 2015.
Diederik P Kingma and Jimmy Lei Ba. Adam: A method for stochastic optimization. international conference on learning representations, 2015.
Diederik P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization trick. neural information processing systems, 28:2575­2583, 2015.
Yann Lecun, Yoshua Bengio, and Geoffrey E Hinton. Deep learning. Nature, 521(7553):436­444, 2015.
Takeru Miyato, Shinichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii. Distributional smoothing with virtual adversarial training. international conference on learning representations, 2016.
Tim Salimans, Ian J Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. neural information processing systems, pp. 2234­2242, 2016.
Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929­1958, 2014.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J Goodfellow, and Rob Fergus. Intriguing properties of neural networks. international conference on learning representations, 2014.
Sida I Wang and Christopher D Manning. Fast dropout training. pp. 118­126, 2013.
9

