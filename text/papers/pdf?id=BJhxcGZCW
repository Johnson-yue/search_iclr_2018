Under review as a conference paper at ICLR 2018
GENERATIVE DISCOVERY OF RELATIONAL MEDICAL ENTITY PAIRS
Anonymous authors Paper under double-blind review
ABSTRACT
Online healthcare services can provide the general public with ubiquitous access to medical knowledge and reduce the information access cost for both individuals and societies. To promote these benefits, it is desired to effectively expand the scale of high-quality yet novel relational medical entity pairs that embody rich medical knowledge in a structured form. To fulfill this goal, we introduce a generative model called Conditional Relationship Variational Autoencoder (CRVAE), which can discover meaningful and novel relational medical entity pairs without the requirement of additional external knowledge. Rather than discriminatively identifying the relationship between two given medical entities in a free-text corpus, we directly model and understand medical relationships from diversely expressed medical entity pairs. The proposed model introduces the generative modeling capacity of variational autoencoder to entity pairs, and has the ability to discover new relational medical entity pairs solely based on the existing entity pairs. Beside entity pairs, relationship-enhanced entity representations are obtained as another appealing benefit of the proposed method. Both quantitative and qualitative evaluations on real-world medical datasets demonstrate the effectiveness of the proposed method in generating relational medical entity pairs that are meaningful and novel.
1 INTRODUCTION
Increasingly, people engage in health services on the Internet (Fox & Duggan, 2013). The healthcare services can provide the general public with ubiquitous access to medical knowledge and reduce the information access cost significantly. The relational medical entity pair, which consists of two medical entities with a semantic connection between them, is an intuitive representation that distills human medical reasoning processes in a structured form. The medical relationships discussed in this paper are binary ones. For example, the Disease-C-a-u-se Symptom relationship indicates a "Cause" relationship from a disease entity to a symptom entity that is caused by this disease, such as the medical entity pairs <Synovitis, Joint Pain>. For the relationship Symptom-B-e-l-on-g-to Department, we may have a relational medical entity pair such as <Stiffness of a Joint, Orthopedics>.
The ability to understand, reason and generalize is central to human intelligence (Oaksford & Chater, 2007). However, it possesses significant challenges for machines to understand and reason about the relationships between two entities (Santoro et al., 2017). Real-world relational medical entity pairs possess certain challenging properties to deal with: First, as the medical research develops, many medical relationships among medical entities that were once neglected due to the underdeveloped medical knowledge now need to be discovered. An increasing number of relationships will be formed among a large number of medical entities. Also, various linguistic expressions can be used for the same medical entity. For example, Nose Plugged, Blocked Nose and Sinus Congestion are symptom entities that share the same meaning but expressed very differently. Moreover, one medical relationship may instantiate entity pairs with varying granularities or relationship strength. For instance, Disease-C-a-u-se Symptom may include entity pairs like <Rhinitis, Nose Plugged> as a coarse-grained entity pair, while < Acute Rhinitis, Nose Plugged>, <Chronic Rhinitis, Nose Plugged> are considered fine-grained entity pairs. As for the relationship strength, <Cold, Fatigue> has greater relationship strength than <Cold, Ear Infections> as cold rarely cause serious complications such as ear infections.
1

Under review as a conference paper at ICLR 2018
To effectively expand the scale of high-quality yet novel relational medical entity pairs, relation extraction methods (Culotta et al., 2006; Bach & Badaskar, 2007) are proposed to examine whether or not a semantic relationship exists between two given entities given a context. Although the existing relation extraction methods (Agichtein & Gravano, 2000; Baeza-Yates & Tiberi, 2007; Sahay et al., 2008; Yu & Lam, 2010; Chang et al., 2014; Wang et al., 2015) achieve decent performance in identifying the relationship for given entity pairs, those methods require contexts such as sentences retrieved from a large free-text corpus, from existing domain-specific knowledge graphs (Abacha & Zweigenbaum, 2011), or from web tables and links (Lin et al., 2010). As medical relationships in the real-world are becoming more and more complex and diversely expressed, existing relation extraction methods suffer from the data sparsity problem where it is hard to obtain additional external knowledge that covers all possible entity pairs, e.g. free-text corpus where two entities co-occur in the same sentence with a relationship between them. Therefore, it is crucial and appealing for us to discover meaningful relational medical entity pairs solely based on existing medical entity pairs, without the requirement of a well-maintained context as an additional external knowledge.
Furthermore, most relation extraction methods adopt a discriminative approach that learns to distinguish entity pairs of one relationship from the other (Zeng et al., 2014; Lin et al., 2016), or to identify meaningful entity pairs from randomly sampled negative entity pairs with no relationships (Bordes et al., 2013; Socher et al., 2013). Those methods need to iterate over the combination of all possible entity pairs and check each of them to discover new entity pairs. Such discriminative approach is tedious and labor-intensive. It is challenging yet rewarding for us to understand medical relationships intrinsically from the existing entity pairs. Specifically, in the medical domain, the diversely expressed medical entity pairs offer great advantages for us to ultimately understand medical relationships and discover high-quality relational medical entity pairs solely from existing meaningful medical entity pairs.
Problem Studied: We propose a novel research problem called RElational Medical Entity-pair DiscoverY (REMEDY), which aims at modeling relational medical entity pairs solely from the existing entity pairs. Also, it aims to discover meaningful and novel entity pairs pertaining to a certain medical relationship in a generative fashion, without sophisticated feature engineering and the requirement of external knowledge such as free-text corpora.
Proposed Model: A generative model named Conditional Relationship Variational Autoencoder (CRVAE) is introduced for relational medical entity pair discovery. It is unlikely to create meaningful, novel relational medical entity pairs without intrinsically understanding each medical relationship, more specifically, understanding the relationships between every two medical entities that instantiate a particular relationship. CRVAE fully explores the generative modeling capacity which roots in Bayesian inference while incorporating deep learning for powerful hands-free feature engineering. CRVAE is trained to encode each relational medical entity pair into a latent space conditioned on the relationship type. The encoding process addresses relationship-enhanced entity representations, interactions between entities as well as expressive latent variables. The latent variables are decoded to reconstruct entity pairs. Once the model is trained, we can sample directly from the distribution of latent variables and decode them into high-quality and novel relational medical entity pairs.
Overall, CRVAE has three notable strengths:
CRVAE models the intrinsic relations between medical entity pairs directly based on the existing meaningful relational medical entity pairs, without the requirement of additional external contexts for entity pair extraction. Existing relation extraction methods usually rely on the free-text corpus to decide whether a candidate entity pair it mentions is meaningful or not. The CRVAE only utilizes the existing entity pairs and pre-trained word vector as initial entity representations which are trained separately.
CRVAE is able to generate entity pairs for a particular relationship, even if it observes existing entity pairs only for that particular relationship. Unlike most discriminative methods which harness discrepancies among different relationships to distinguish the relationship of an entity pair from the other, or from randomly constructed negative entity pairs with no relations. The CRVAE understands the intrinsic medical relation from diversely expressed medical entity pairs and discovers meaningful, novel entity pairs of a particular relationship that we specified.
2

Under review as a conference paper at ICLR 2018

CRVAE generates novel entity pairs by a density-based sampling strategy in the generator. The generator samples directly from the latent space based on the density of hidden parameters. With the hands-free feature engineering by deep neural networks, the model is able to discover meaningful and novel entity pairs which does not exist in the training data.
The contributions of this paper can be summarized as follows:
· We study the Relational Medical Entity-pair Discovery (REMEDY) problem, which aims to expand the scale of high-quality yet novel relational medical entity pairs without maintaining large-scale context information such as the free-text corpus.
· We propose a generative model named Conditional Relationship Variational Autoencoder (CRVAE) that discovers relational medical entity pairs for a given relationship, solely from the diversely expressed entity pairs without sophisticated feature engineering.
· We obtain relationship-enhanced entity representations as an appealing benefit of the proposed model.

2 CONDITIONAL RELATIONSHIP VARIATIONAL AUTOENCODER

In this section, we introduce the Conditional Relationship Variational Autoencoder (CRVAE) model for the REMEDY problem. The proposed model consists of three modules: encoder, decoder, and generator. The encoder module takes relational medical entity pairs and a relationship indicator as the input, trained to intrinsically understand each relationship by translating and mapping the entity pair to a latent space as Q. The decoder is jointly trained to reconstruct the entity pairs as P. The generator model shares the same structure with the decoder, and it directly samples from the learned latent variable distribution to creatively generate meaningful medical relational entity pairs for a particular relationship. Figure 1 gives an overview of the proposed model.

embedh transh transht eh

transh transh t

embedh

...... µ ......

embedt transt et

......

lht r
2

z r

...... transt embedt

( )Q z embedh,embedt,r
Encoder

P

 

embedh,embedt

z,

r

 

Latent Variables

Decoder

Figure 1: An overview of Conditional Relationship Variational Autoencoder (CRVAE) for Relational Medical Entity-pair Discovery during training. The encoder module is show in green color and the decoder module is show in blue. Model inputs are in white color.

The model takes a tuple <eh, et> and a relationship indicator r as the input, where eh and et are head and tail medical entity of a relationship r. For example, eh ="Synovitis" and et="Joint Pain", while the corresponding r is an indicator for Disease-C-a-u-se Symptom.
To effectively represent medical entities, pre-trained word embeddings that embody rich semantic information can be obtained as initial entity representations for eh and et. For simplicity, Skip-gram (Mikolov et al., 2013) is adopted to obtain 200-dimensional word embeddings trained separately and unsupervisely on a publicly accessible medical corpus. After a table lookup on the pre-trained word vector matrix Wembed  RV ×DE where V is the vocabulary size (usually tens of thousands) and DE is the dimension of the initial entity representation (usually tens or hundreds), embedh  R1×DE and embedt  R1×DE are derived as the initial embedding of medical entities.
2.1 ENCODER
With the initial entity representation embedh and embedt and their relationship indicator r, the encoder first translates and then maps entity pairs to a latent space as Q(z|embedh, embedt, r).

3

Under review as a conference paper at ICLR 2018

2.1.1 TRANSLATING FOR RELATIONSHIP-ENHANCING

The initial embedding obtained from word embedding reflects semantic and categorical information. However, it is not specifically designed to model the medical relationship among medical entities (See observations in Section 3.4.3). To get entity representations that address relationship information, the encoder learns to translate each medical entity from its initial embedding to a relationshipenhanced embedding that distills relationship information. For example, a non-linear transformation can be used: translate(x) = f (x·Wtrans+btrans) where f can be an non-linear activation function such as the Exponential Linear Unit (ELU) (Clevert et al., 2015). Wtrans  RDE×DR is the weight variable and btrans  R1×DR is the bias where DR is the dimension for relationship-enhanced embeddings.

transh = translate(embed h), transt = translate(embed t) are obtained as relationship-enhanced embeddings for eh and et.

(1)

2.1.2 MAPPING TO LATENT VARIABLES

The relationship-enhanced entity representation transh and transt are concatenated transht = [transh, transt] and mapped to the latent space by multiple fully connected layers. For example, we can obtain a variable lht that addresses the relationship information, as well as entity interactions from two medical entities, by applying three consecutive non-linear fully con-
nected layers on transht. As a variational inference model, we assume a simple Gaussian distribution of Q(z|embedh, embedt, r) for the relational medical entity pair <eh, et> with a relationship r. Therefore, for each relational medical entity pair <eh, et> and a relationship indicator r, a mean vector µ and a variance vector 2 can be learned as latent variables to model Q(z|embedh, embedt, r):

µ = [lht, r] · Wµ + bµ, 2 = [lht, r] · W + b,

(2)

where a one-hot indicator r  R1×|R| is used for the medical relationship r and |R| is the number of all relationships. Wµ, W  R(Dlht +|R|)×DL are weight terms and bµ, b  R1×DL are bias terms. DL is the dimension for latent variables and Dlht is the dimension for lht. To stabilize the training, we model the variation vector 2 by its log form log 2 (to be explained in Equation 15).

2.2 DECODER

Once we obtain latent variables µ, 2 for an input tuple <eh, et> which has the relationship r, the decoder uses latent variables and the relationship indicator r to reconstruct the relational medical entity pair. The decoder implements the P(embedh, embedt|z, r).
Given µ, 2, it is intuitive to sample the latent value z from the distribution N (µ, 2) directly. However, such operator is not differentiable thus optimization methods failed to calculate its gradient. To solve this problem, a reparameterization trick is introduced in Kingma & Welling (2014) to divert the non-differentiable part out of the network. Instead of directly sampling from N (µ, 2), we sample from a standard normal distribution  N (0, I) and then convert it back to z by z = µ +  . In this way, sampling from does not depend on the network.

Similarly as the use of multiple non-linear fully connected layers for the mapping in the encoder, multiple non-linear fully connected layers are used for an inverse mapping in the decoder. After the inverse mapping we obtain transht  R1×2DR . The first DR dimensions of transht are considered as a decoded relationship-enhanced embedding for eh, while the last DR dimensions are for et:

transh = transht [: DR] , transt = transht [DR :] ,

(3)

where transh, transt  R1×DR . trans h and trans t are further inversely translated back to the initial embedding space RDE :

embedh = f (transh · Wtrans inv + btrans inv), embedt = f (transt · Wtrans inv + btrans inv), (4)
where embedh, embedt  R1×DE are considered as reconstructed representations for embedh and embedt.

4

Under review as a conference paper at ICLR 2018

2.3 TRAINING

Inspired by the loss function of the conditional variational autoencoder (CVAE) (Kingma et al., 2014; Sohn et al., 2015), the loss function of CRVAE is formulated to minimize the variational lower bound:

LCRVAE(embedh, embedt, r; , ) = - KL [Q (z|embedh, embedt, r) ||P (z|r)] + E [log (P (embedh, embedt|z, r))] ,

(5)

where Q (z|embedh, embedt, r) is a simple Gaussian distribution used to approximate the unknown true distribution P (z|embedh, embedt, r). P (z|r) describes the true latent distribution z given a certain relationship r and E [log (P (embedh, embedt|z, r))] estimates the maximum like-
lihood.

A closed-form solution for the first term can be derived as:

1 DL -
2

exp

2 l + µ2l - 1 - l2 ,

l

(6)

where µ is the mean vector and 2 is the variance vector. l in the subscript indicates the l-th dimension of the vector. Details for obtaining the closed-form solution are given in Appendix A

The second term penalizes the maximum likelihood, which is the conditional probability P(embedh, embedt|z, r) of a certain entity pair <eh, et> given the latent variable z and the relationship indicator r. The mean squared error (MSE) is adopted to calculate the difference between
<embedh, embedt> and <embedh, embedt>:

E [log (P

(embedh, embedt|z, r))]

=

1 2DE

||embedh - embedh||22 + ||embedt - embedt||22

,

(7)

where · 2 is the vector 2 norm. To minimize the LCRVAE, existing optimizers such as Adadelta (Zeiler, 2012) can be used. Furthermore, a warm-up technique introduced in Sønderby & Raiko

(2016) can let the training start with deterministic and gradually switch to variational, by multiplying

 to the first term. The final loss function used for training is formulated as:

LCRVAE

=

-

 2

DL

exp

2 l + µ2l - 1 - log l2

+

1 2DE

l

||embedh - embedh||22 + ||embedt - embedt||22 , (8)

where  is initialized as 0 and increase by 0.1 at the end of each training epoch, until it reaches 1.0

as its maximum.

2.4 GENERATOR

When we have a certain relationship r in our mind that the generated relational medical entity pairs should belong to, a density-based sampling method is introduced for the generator to sample z^ from the latent space given a certain relationship r.

Instead of using the latent variable z provided by certain µ and log 2 in the encoding process
from a certain eh, et and r, the generator tries to sample z^ directly from P(z^|r) to get the latent space value z^ for a particular relationship
r. Once z^ is obtained, the decoder structure
is used to decode the relational medical entity
pair. Figure 2 illustrates the generative process.

r

Density-based Sampling
z^

P  z^ r

r

...... ...... Generator

e^mbedh e^h
e^mbedt e^t

The denser region in the latent space P(z^|r) indicates that more densely entity pairs are lo-
cated in the manifold. Therefore, a sampling
method that considers the density distribution of P(z^|r) samples more often from the denser regions in the latent space so as to preserve the

Figure 2: The generator that generate meaningful, novel relational medical entity pairs from the latent space.

5

Under review as a conference paper at ICLR 2018

true latent space distribution of the sampled values. Specifically, for each relationship r, the densitybased sampling samples z^ directly from P(z^|r)  N (0, I), when trained properly. The resulting vectors e^mbedh and e^mbedt are mapped back to their entities in the initial embedding space R1×DE , namely e^h and e^t, by finding the nearest neighbor of the initial entity representation using Wembed. The -2 distance measure is used for the nearest neighbor search.
3 EXPERIMENTS
3.1 DATASET & TRAINING DETAILS
The dataset consists of 46.02k real-world relational medical entity pairs in Chinese from a Chinese online healthcare forum www.xywy.com. The data set covers six different types of medical relationships. Table 1 shows the collection of relational medical entity pairs used in this study. 70% data are used for training and 30% for validation.

Table 1: Sample Medical Relationships and relational medical entity pairs.

MEDICAL RELATIONSHIP Disease -C-a-u-se Body Part Disease -R-e-l-at-e-dT-o Disease Disease -N-e-ed Examine
Symptom -B-e-lo-n-g-To Department Disease -C-a-u-se Symptom
Symptom -R-e-l-at-e-dT-o Symptom

COUNT 2320 4614 4185 8595 16642 9662

RELATIONAL MEDICAL ENTITY PAIRS
< (tricuspid insufficiency), (tricuspid valve) > < (vaginal cancer), (reproductive system) > < (hydrocephaly), (head) >
< (infant hydrocephalus), (congenital hydrocephalus) > < (urethritis), (cystitis) >
< (retention of food in the stomach), (infantile indigestion) >
< (salicylates poisoning), (routine urianlysis) > < (tetralogy triad), (electrocardiogram, ECG) >
< (epididymitis) , (cremasteric reflex) >
< (anchylosis, stiffness of a joint), (orthopedics) > < (Female lower abdominal pain), (gynecology) > < (absent infant sucking reflex), (neonatology) >
< (peritonitis), (abdominal venous engorgement) > < (urethritis), (urethra itching) >
< (radial nerve palsy), (upper extremity weakness) >
< (redness and swelling around the umbilicus), (periumbilical swelling) > < (muscular contusion), (disinsertion) >
< (fingers benumbed with cold), (skin frostbite) >

We use 200-dimensional word embeddings learned with the Skip-gram algorithm in Mikolov et al. (2013), trained from 6 million text corpus on the Chinese online healthcare forum as the initial entity representation. The vocabulary covers 126,270 words. We use Xavier initialization (Glorot & Bengio, 2010) for weight variables and zeros for biases. A wide range of hyperparameter configurations are tested with the proposed model. See Appendix B for detailed hyperparameter analysis.

3.2 PERFORMANCE EVALUATION

For each medical relationship, 1000 entity pairs are generated. Three evaluation metrics are introduced to quantitatively measure the generated relational medical entity pairs: quality, support, and novelty.

Quality Since it is hard for the machine to evaluate whether a relational medical entity pair is
meaningful or not, human annotation is involved in assessing the quality of the generated relational
medical entity pairs. A human annotation task is deployed on Amazon Mechanical Turk for anno-
tation (Task shown in Appendix C). Similar as the precision metric adopted in Bach & Badaskar (2007), the quality1 is measured by:

# of entity pairs that are meaningful

quality =

.

# of all the generated entity pairs

(9)

1Note that metrics such as recall is not applicable in such generative discovery task as the total population of positive samples is unknown.

6

Under review as a conference paper at ICLR 2018

Support Besides the quality metric, a support metric is developed to quantitatively measure the degree of belongingness of a generated entity pair to a relationship. For each generated relational medical entity pair <e^h, e^t> and a candidate relationship rc, the support score is calculated by:

1

support<e^h,e^t,rc>

=

1

+

, distance(e^mbedh, e^mbedt)

(10)

where distance(e^mbedh, e^mbedt) calculates the distance between the vector e^mbedh-e^mbedt and N Nrc (e^mbedh - e^mbedt) using distance measure such as cosine distance. The N Nrc implements the nearest neighbor search over the embedh - embedt space on all the training data which has
the relationship rc. For each generated medical entity pair, the support scores for all the candidate
relationships are normalized so that they sum up to one:

norm

support<e^h,e^t,rc>

=

support<e^h,e^t,rc>
|R|

.

support<e^h,e^t,ri>
ri

(11)

The relationship having the highest score is considered as the estimated relationship for <e^h, e^t> while the relationship r given during the generating process is considered as the ground truth for
<e^h, e^t>. The final support value is based on the accuracy of the estimated relationship and the ground truth relationship.

Novelty The ability to generate novel relational medical entity pairs is one of our key contributions. Due to different scope of medical knowledge among individuals, human annotators are not able to precisely evaluate the novelty. We measure the novelty of the generation process by:

# of entity pairs that do not exist in the dataset

novelty =

.

# of all the generated entity pairs

(12)

3.3 BASELINES
Considering that no known methods are currently available for the REMEDY problem, we compare the performance of the following models:
· CRVAE-MONO: The proposed model which only takes one single type of relational medical entity pairs in both training and generation. For each type of relationship, we train a separate CRVAE only with entity pairs having that relationship.
· RVAE: The unconditional version of the model CRVAE where the relationship indicator r is not provided during model training and generation.
· CRVAE-RAND: The proposed model CRVAE with a random sampling based generator. Unlike the density-based sampling adopted in CRVAE, the generator of CRVAE-RAND samples randomly from the latent space.
· CRVAE: The proposed method where relational medical entity pairs that belong to all types of relationships are used to train the model altogether. The training is conditioned on relationships and density-based sampling is used.
· CRVAE-WA: The proposed method with the warm-up strategy introduced in Section 2.3.

3.4 EXPERIMENT RESULTS
We summarize the performance of the proposed method, along with other alternatives, in Table 2.
CRVAE-MONO demonstrates the power of generative models in terms of learning the intrinsic representation and generating new entity pairs only given one type of relationship during the training (Quality: 0.6698, Support: 0.9550, Novelty: 0.5118). For CRVAE-RAND, although it generates highly novel (0.9952) entity pairs that are not seen in the training data, the generated entity pairs are of low quality (0.2550). By comparing CRVAE and CRVAE-RAND, we can see that the densitybased sampling enables the generation of high-quality entity pairs that results in +47.58% in quality and +52.84% in support. The warm up technique adopted in CRVAE-WA is able to give CRVAE a further performance boost, where all measures improve consistently (+4.09% in quality, +2.43% in support and +5.11% in novelty).

7

Under review as a conference paper at ICLR 2018

Table 2: Performance of the proposed method with other baselines.

MODEL NAME QUALITY SUPPORT NOVELTY LOSS (TRAIN / VALID)

CRVAE-MONO CRVAE-RAND CRVAE CRVAE-WA

0.6698 0.2550 0.7308 0.7717

0.9550 0.3764 0.9048 0.9291

0.5118 0.9952 0.5682 0.6193

47.3002 / 116.6739 43.0954 / 83.6589 43.0954 / 83.6589 33.4399 / 57.9470

As a qualitative measure, we also provide relational medical entity pairs generated by the proposed model. For example, the entity pair <(dysentery), (intestine)> is generated given the medical
relationship Disease-C-a-u-se Body Part, while entity pairs such as <(amebic dysentery, (intestine)> and <(bacterial dysentery), (chest)> are found in the training data.
More entity pairs generated by the proposed method can be found in Appendix D.

3.4.1 GENERATIVE MODELING CAPABILITY
Unlike discriminative models which utilize the difference between instances of different classes to discriminate instances from one class to another, the proposed method purely learns from the existing relational medical entity pairs to generate new entity pairs. To validate such appealing property, Table 3 compares the fine-grained quality, support and novelty of entity pairs generated by CRVAE-MONO and CRVAE on each relationship.

Table 3: Quality, support and novelty metrics of the generated relational medical entity pairs by CRVAE-MONO and CRVAE.

CRVAE-MONO
Disease-C-a-u-se Body Part Disease-R-e-l-at-e-dT-o Disease Disease-N-e-ed Examine Symptom-B-e-lo-n-g-To Department Disease-C-a-u-se Symptom Symptom-R-e-l-at-e-dT-o Symptom

QUALITY
0.683 0.689 0.708 0.687 0.587 0.665

SUPPORT
1.000 0.870 1.000 1.000 0.940 0.920

NOVELTY
0.488 0.483 0.521 0.466 0.573 0.540

LOSS (TRAIN/VALID)
54.9830 / 126.7426 51.5131 / 155.0721 54.7635 / 136.4802 39.0959 / 72.5872 37.3276 / 83.8797 46.1180 / 125.2818

CRVAE
Disease-C-a-u-se Body Part Disease-R-e-l-at-e-dT-o Disease Disease-N-e-ed Examine Symptom-B-e-lo-n-g-To Department Disease-C-a-u-se Symptom Symptom-R-e-l-at-e-dT-o Symptom

0.756 0.691 0.757 0.768 0.702 0.711

0.999 0.744 0.981 0.995 0.882 0.828

0.724 0.867 0.871 0.613 0.927 0.888

43.0954 / 83.6589

As shown in Table 3, the CRVAE-MONO on each relationship achieves a reasonable performance, which shows the capability of generative models in understanding every single medical relationship individually. Furthermore, when all types of entity pairs are trained and generated altogether in CRVAE, we observe a consistent improvement in not only quality but also novelty.
3.4.2 EFFECTIVENESS OF DENSITY-BASED SAMPLING
To validate the effectiveness of the density-based sampling for the generator, we compare the proposed method with CRVAE-RAND where a random sampling strategy is adopted. From Table 2 we can see that the random sampling strategy in CRVAE-RAND tends to generate more entity pairs that are not seen in the existing dataset. However, we observe a significant reduction in the quality
8

Under review as a conference paper at ICLR 2018
and support of the generated entity pairs when compared with CRVAE which adopts a density-based sampling. The dense region in the latent space indicates that more densely entity pairs are located. Therefore, in CRVAE, the quality and support of the generated entity pairs benefit from sampling more often at denser regions in the latent space, resulting in less novel but higher quality entity pairs.
3.4.3 EFFECTIVENESS OF RELATIONSHIP-ENHANCING ENTITY ADJUSTMENT
As mentioned in Section 2.1.1, the translating layer adjusts the original embedding to get relationship-enhanced entity representations. In the experiments, we study the embedding spaces before/after translation and observe that in the original embedding space, the Skip-gram tends to put entities that share similar context (e.g. muscle strain and pull-up) in proximity. While after relationship-enhancing, entities with similar functionalities in the same medical relationship are nearby with each other (e.g. heart malformations and chromosome abnormalities). See Appendix E for details.
3.4.4 ABILITY TO INFER CONDITIONALLY
One of our key contributions is that with proper training, the proposed method can generate relational medical entity pairs given a certain relationship. That is, the ability to infer new entity pairs for a particular relationship. Besides seamlessly incorporating this idea in the model design, we also visualize latent space of CRVAE and RVAE in order to show the conditional inference ability. See Appendix F for details.
4 RELATED WORKS
Generative Models: Recent years have witnessed an increasing interests in the research topic of generative models, which aims to generate observable data values based on some hidden parameters. Various generative models have been developed, such as Generative Adversarial Networks (GANs) (Goodfellow, 2016; Radford et al., 2015) and Variational Autoencoders (VAEs) (Kingma & Welling, 2013; Kingma et al., 2014; Sohn et al., 2015; Higgins et al., 2016; Nalisnick & Smyth, 2017). Unlike GANs which generate data based on arbitrary noises, the VAE setting adopted in this paper is more expressive for our task since it tries to model the underlying probability distribution of the data by latent variables so that new data from that distribution can be sampled accordingly.
There are some generative models and applications considering data in different modalities, such as generating images (Pu et al., 2016; Gregor et al., 2015; Dilokthanakul et al., 2016) or natural language texts (Bowman et al., 2016; Marcheggiani & Titov, 2016; Hu et al., 2017; Xu et al., 2017). As far as we know, the relational medical entity pair discovery problem we studied in this paper, which suits the generative purpose, has not been studied in a generative perspective.
Relationship Extraction: There is another related research area that studies relation extraction, which usually amounts to examining whether or not a relation exists between two given entities (Culotta et al., 2006). Most relationship extraction methods require large amounts of high-quality external information, such as a large text corpus (Baeza-Yates & Tiberi, 2007; Agichtein & Gravano, 2000; Sahay et al., 2008; Yu & Lam, 2010) and knowledge graphs (Wang et al., 2015; Chang et al., 2014; Syed et al., 2010). However, it is tedious and time-consuming to check each possible pair over all combinations of entities in the entity space. Thus, we propose an effective generative method that generates meaningful and novel relational medical entity pairs directly. Also, it is time consuming to collect and prepare a large corpus that covers all the mentions of those entity pairs, which makes it difficult to apply those methods. In this work, our model does not rely on additional external corpus for entity pair discovery.
Moreover, previous discriminative models usually need negative samples for supervised training. For example, Socher et al. (2013) trains the model to distinguish entity pairs with a relationship from randomly generated entity pairs as negative samples, while our model is can understand the medical relationship only from rational relational medical entity pairs thus even works when being fed with entity pairs having the same relationship type.
9

Under review as a conference paper at ICLR 2018
5 CONCLUSION
To effectively expand the scale of high-quality relational medical entity pairs which store the medical knowledge, a novel generative model named Conditional Relationship Variational Autoencoder (CRVAE) is introduced for Relational Medical Entity-pair Discovery (REMEDY). The proposed model fully explores the generative modeling ability while incorporates deep learning for powerful hands-free feature engineering. Unlike traditional relation extraction tasks which require additional contexts for extraction and need negative samples for discriminative training, the proposed method learns to intrinsically understand the medical relations from diversely expressed medical entity pairs, without the requirement of external context information. Moreover, it is able to generate meaningful, novel entity pairs for a given type of medical relationship. The relationshipenhanced entity representations have the potential to improve other NLP tasks. The performance of the proposed method is evaluated on real-world medical data both quantitatively and qualitatively.
REFERENCES
Asma Ben Abacha and Pierre Zweigenbaum. Automatic extraction of semantic relations between medical entities: a rule based approach. Journal of biomedical semantics, 2(5):S4, 2011.
Eugene Agichtein and Luis Gravano. Snowball: Extracting relations from large plain-text collections. In Proceedings of the fifth ACM conference on Digital libraries, pp. 85­94. ACM, 2000.
Nguyen Bach and Sameer Badaskar. A review of relation extraction. Literature review for Language and Statistics II, 2, 2007.
Ricardo Baeza-Yates and Alessandro Tiberi. Extracting semantic relations from query logs. In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 76­85. ACM, 2007.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in neural information processing systems, pp. 2787­2795, 2013.
Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Bengio. Generating sentences from a continuous space. CoNLL 2016, pp. 10, 2016.
Kai-Wei Chang, Scott Wen-tau Yih, Bishan Yang, and Chris Meek. Typed tensor decomposition of knowledge bases for relation extraction. 2014.
Djork-Arne´ Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289, 2015.
Aron Culotta, Andrew McCallum, and Jonathan Betz. Integrating probabilistic extraction models and data mining to discover relations and patterns in text. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pp. 296­303. Association for Computational Linguistics, 2006.
Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with gaussian mixture variational autoencoders. arXiv preprint arXiv:1611.02648, 2016.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121­2159, 2011.
Susannah Fox and Maeve Duggan. Health online 2013. Washington, DC: Pew Internet & American Life Project, 2013.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pp. 249­256, 2010.
Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint arXiv:1701.00160, 2016.
10

Under review as a conference paper at ICLR 2018
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra. Draw: A recurrent neural network for image generation. In Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pp. 1462­1471, 2015.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. 2016.
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. Toward controlled generation of text. In International Conference on Machine Learning, pp. 1587­1596, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
Diederik P Kingma and Max Welling. Stochastic gradient vb and the variational auto-encoder. In Second International Conference on Learning Representations, ICLR, 2014.
Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised learning with deep generative models. In Advances in Neural Information Processing Systems, pp. 3581­3589, 2014.
Cindy Xide Lin, Bo Zhao, Tim Weninger, Jiawei Han, and Bing Liu. Entity relation discovery from web tables and links. In Proceedings of the 19th international conference on World wide web, pp. 1145­1146. ACM, 2010.
Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. Neural relation extraction with selective attention over instances. In ACL (1), 2016.
Diego Marcheggiani and Ivan Titov. Discrete-state variational autoencoders for joint discovery and factorization of relations. Transactions of the Association for Computational Linguistics, 4:231­ 244, 2016.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.
Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10), pp. 807­814, 2010.
Eric Nalisnick and Padhraic Smyth. Stick-breaking variational autoencoders. In ICLR, 2017.
Mike Oaksford and Nick Chater. Bayesian rationality: The probabilistic approach to human reasoning. Oxford University Press, 2007.
Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, and Lawrence Carin. Variational autoencoder for deep learning of images, labels and captions. In Advances in Neural Information Processing Systems, pp. 2352­2360, 2016.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Saurav Sahay, Sougata Mukherjea, Eugene Agichtein, Ernest V Garcia, Shamkant B Navathe, and Ashwin Ram. Discovering semantic biomedical relations utilizing the web. ACM Transactions on Knowledge Discovery from Data (TKDD), 2(1):3, 2008.
Adam Santoro, David Raposo, David GT Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. arXiv preprint arXiv:1706.01427, 2017.
Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in neural information processing systems, pp. 926­934, 2013.
11

Under review as a conference paper at ICLR 2018
Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using deep conditional generative models. In Advances in Neural Information Processing Systems, pp. 3483­3491, 2015.
Casper Kaae Sønderby and COM Tapani Raiko. How to train deep variational autoencoders and probabilistic ladder networks. In ICML, 2016.
Zareen Syed, Evelyne Viegas, and Savas Parastatidis. Automatic discovery of semantic relations using mindnet. In LREC, 2010.
Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26­ 31, 2012.
Chenguang Wang, Yangqiu Song, Dan Roth, Chi Wang, Jiawei Han, Heng Ji, and Ming Zhang. Constrained information-theoretic tripartite graph clustering to identify semantically similar relations. In IJCAI, pp. 3882­3889, 2015.
Weidi Xu, Haoze Sun, Chao Deng, and Ying Tan. Variational autoencoder for semi-supervised text classification. In AAAI, pp. 3358­3364, 2017.
Xiaofeng Yu and Wai Lam. Jointly identifying entities and extracting relations in encyclopedia text via a graphical model approach. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pp. 1399­1407. Association for Computational Linguistics, 2010.
Matthew D Zeiler. Adadelta: an adaptive learning rate method. arXiv preprint arXiv:1212.5701, 2012.
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, et al. Relation classification via convolutional deep neural network. In COLING, pp. 2335­2344, 2014.
12

Under review as a conference paper at ICLR 2018

APPENDIX

A DERIVING THE CLOSED-FORM SOLUTION

Inspired by the loss function of the conditional variational autoencoder (CVAE) Kingma et al. (2014); Sohn et al. (2015), the loss function of CRVAE is formulated to minimize the variational lower bound:

LCRV AE(embedh, embedt, r; , ) =
- KL [Q (z|embedh, embedt, r) ||P (z|embedh, embedt, r)] + log (P (embedh, embedt|r)), (13)
where the first term minimizes the KL divergence loss between the unknown true distribution P (z|embedh, embedt, r) which is hard to sample from and a simple distribution Q (z|embedh, embedt, r). The second term models the entity pairs by log (P (embedh, embedt|r)). The above equation can be reformulated as:

LCRV AE(embedh, embedt, r; , ) = - KL [Q (z|embedh, embedt, r) ||P (z|r)] + E [log (P (embedh, embedt|z, r))] ,

(14)

where P (z|r) describes the true latent distribution z given a certain relationship r and E [log (P (embedh, embedt|z, r))] estimates the maximum likelihood. Since we want to sample from P(z|r) in the generator, the first term aims to let to let Q(z|embedh, embedt, r) to be as close as possible to P(z|r) which has a simple distribution N (0, I) so that it is easy to sample from. Furthermore, if P(z|r)  N (0, I) and Q(z|embedh, embedt, r)  N (µ, 2), then a close-form
solution for the first term can be derived as:

= -1 2

-KL [Q (z|embedh, embedt, r) ||P (z|r)] = -KL [N (µ, )||N (0, I)]

tr 2 + (µ)T µ - DL - log det 2

1 DL =-
2

l2 + µ2l - 1 - log l2

,

l

(15)

where l in the subscript indicates the l-th dimension of the vector. Since it is more stable to have

exponential term than a log term, we model log 2 as 2 which results in the final closed-form of

Equation 15:

1 DL -
2

exp

2 l + µl2 - 1 - l2 .

l

(16)

B HYPERPARAMETERS

We train the proposed model with a wide range of hyperparameter configurations, which are listed
in Table 4. We vary the batch size from 64 to 256. The dimension DR for translating the initial entity embeddings is set from 64 to 2048. We try two to seven hidden layers from transht to lht and from [z, r] to transht, with different non-linear activation functions. For each hidden layer, the hidden unit number DH is set from 2 to 1024. The latent dimension DL is set from 2 to 200.

HYPERPARAMETER
Batch Size DR DH DL Activation Optimizer

Table 4: Hyperparameter configurations.
VALUE
64, 128, 256 64, 128, 256, 512, 640, 768, 1024, 1280, 1536, 1792, 2048 2, 4, 8, 16, 32, 64, 128, 256, 512, 640, 768, 1024 2, 3, 4, 5, 10, 20, 50, 100, 200 ELU (Clevert et al., 2015), ReLU (Nair & Hinton, 2010), Sigmoid, Tanh Adadelta (Zeiler, 2012), Adagrad (Duchi et al., 2011), Adam (Kingma & Ba, 2014), RMSProp Tieleman & Hinton (2012)

Table 5 shows the top five configurations ranked by their validation losses. From the combinations
of those hyperparameter configurations, we find that for fully connected hidden layers from transht to lht, a sequence of six consecutive layers: 1792×640×640×512×256×64 works the best for the

13

Under review as a conference paper at ICLR 2018

Table 5: Model performance on different hyperparameter configurations. {DH } is a set of unit numbers for hidden layers in the encoder. For the decoder, hidden layers are organized in a reverse
order.

BATCH SIZE DR {DH}

DL ACT. OPTIMIZER LOSS (TRAIN/VALID)

64 640 1792×640×640×512×256× 64 200 elu adadelta 64 640 1792×256×640×512×256×128 200 elu adadelta 64 640 1792×256×640×512×256× 64 200 elu adadelta 128 640 1792×640×768×512× 64×128 50 elu adadelta 256 640 512×768×640×256×512 50 elu adam

43.0954 / 83.6589 51.0695 / 86.9153 50.4392 / 88.6438 50.5997 / 89.0125 62.1955 / 89.2014

encoder with ELU as the activation function. For [z, r] to transht in the decoder, such layer setting is organized in a reverse order. A batch size of 64 and the Adadelta optimizer work the best for our task. DR = 640 is used. The latent dimension DL = 200 is adopted for µ and 2. Such configuration achieves a training loss of 43.0954 and a validation loss of 83.6589.
C TASK ON AMAZON MECHANICAL TURK

Figure 3: The screenshot of the human annotation task on Amazon Mechanical Turk.
D GENERATED RELATIONAL MEDICAL ENTITY PAIRS
Table 6 shows meaningful entity pairs generated by the proposed method.
E EFFECTIVENESS OF RELATIONSHIP-ENHANCING ENTITY ADJUSTMENT
To show the effectiveness of relationship-enhancement, Table 7 shows the nearest neighbors of a disease entity  (genital tract malformation) and a symptom entity  (muscle strain) in their original embedding space, as well as the space after relationship-enhancing. From these cases we can see that the original entity representations trained with Skip-gram (Mikolov et al., 2013) tend to put entities in proximity when they appear in similar contexts. In the first case, the entity (genital tract malformation) is in close proximity to  (infertility),   (acyesis). In the second case, entities that have similar context like  (pull-up) and   (amount of exercise) are found near by the entity (muscle strain).
14

Under review as a conference paper at ICLR 2018
Table 6: Rational, meaningful relational medical entity pairs generated by the proposed method.
Disease-C-a-u-se Body Part < (dysentery), (intestine)> < (brain tumor), (head) > < (leukopenia), (vascular system) >
Disease-R-e-l-at-e-dT-o Disease < (foreign body in esophagus), (bowel obstruction) > < (brain contusion), (amnesia) > < (respiratory acidosis), (pulmonary edema) >
Disease-N-e-ed Examine < (uremia), (routine urianlysis) > < (bacterial meningitis), CT (cranial CT) > < (bowel obstruction), (abdominal x-ray) >
Symptom-B-e-lo-n-g-To Department < (retained placenta), (obstetrics) > < (fluid retention), (nephrology) > < (stuffy nose), (otolaryngology) >
Disease-C-a-u-se Symptom < (otogenic brain abscess), (earache) > < (neuritis), (numbness in the hands) > < (open head injury), (loss of consciousness) >
Symptom-R-e-l-at-e-dT-o Symptom < (fatigue), (feel wobbly and rough) > < (joint pain), (limited joint mobility) > < (blurred vision), (eye discomfort) >
The translation layer adjusts the original entity representation so that they are more suitable for the Relational Medical Entity-pair Discovery task. The nearest neighbors in the adjusted space are not necessarily entities that co-occur in the same context, but more relation-wise similar with the given entity. For example,  (heart malformations) and  (chromosome abnormalities) may not be semantically similar with the given word (genital tract malformation), but they may serve similar functionalities in a Disease-C-a-u-se Symptom relationship.
F ABILITY TO INFER CONDITIONALLY
Figure 4 shows the values of validation data after being mapped into the µ space using RVAE (left) and CRVAE (right), respectively. The values are colored based on their ground truth relationship indicators. The left figure indicates that when the relationship indicator r is not given during the training/validation, RVAE is still able to map different relationships into various regions in the latent space, while a single distribution models all types of relationships. Such property is appealing for an unsupervised model, but since the relationship indicator r is not given, RVAE fails to generate entity pairs having a particular relationship, unless we manually assign a boundary for each relationship in the latent space. The right figure shows that when the relationship indicator r is incorporated during the training, CRVAE learns to let each relationship have a unified latent representation. A separate but nearly identical distribution is used to model each medical relationship. Such property enables the generator of CRVAE to sample from a relationship-independent, unified latent space for diversities regarding the generation, while the relationship indicator r given in CRVAE's generator provides categorical information on the type of relationship to generate.
15

Under review as a conference paper at ICLR 2018

Table 7: The effectiveness of relationship-enhancing adjustment on entity representations.
· (genital tract malformation) NN in the relationship-enhanced space R1×DR NN in the initial embedding space R1×DE

 (genital tract)
 (reproductive system)
 (heart malformations)  (chromosome abnormalities)  (reproductive tract tumors)  (generative organs)  (urinary system malformations)  (gastrointestinal malformations)

 (reproductive system)  (reproductive tract tumors)  (urinary system malformations)
 (infertility)  (vaginal atresia)  (genital tract)  (generative organs)
 (acyesis)

· (muscle strain) NN in the relationship-enhanced space R1×DR NN in the initial embedding space R1×DE

 (strain)  (ligament strain)  (sprain)  (foot pain)  (muscle tear)  (plantar fasciitis)  (joint sprain)  (repetitive strain injury, RSI)

 (strain)  (muscle tear)  (pull-up)
 (sprain)
 (muscle fatigue)
 (tenosynovitis)
 (tendonitis)  (amount of exercise)

Figure 4: The latent variable µ of RVAE (left) and CRVAE (right) on the validation data, presented in a two-dimensional space after dimension reduction using Primary Component Analysis.
16

