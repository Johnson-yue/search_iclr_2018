Under review as a conference paper at ICLR 2018
DEEP SENSING: ACTIVE SENSING USING MULTIDIRECTIONAL RECURRENT NEURAL NETWORKS
Anonymous authors Paper under double-blind review
ABSTRACT
For every prediction we might wish to make, we must decide what to observe (what source of information) and when to observe it. Because making observations is costly, this decision must trade off the value of information against the cost of observation. Making observations (sensing) should be an active choice. To solve the problem of active sensing we develop a novel deep learning architecture: Deep Sensing. At training time, Deep Sensing learns how to issue predictions at various cost-performance points. To do this, it creates multiple representations at various performance levels associated with different measurement rates (costs). This requires learning how to estimate the value of real measurements vs. inferred measurements, which in turn requires learning how to infer missing (unobserved) measurements. To infer missing measurements, we develop a Multi-directional Recurrent Neural Network (M-RNN). An M-RNN differs from a bi-directional RNN in that it sequentially operates across streams in addition to within streams, and because the timing of inputs into the hidden layers is both lagged and advanced. At runtime, the operator prescribes a performance level or a cost constraint, and Deep Sensing determines what measurements to take and what to infer from those measurements, and then issues predictions. To demonstrate the power of our method, we apply it to two real-world medical datasets with significantly improved performance.
1 INTRODUCTION
Making observations is costly. Hence, for every prediction we might wish to make, we must decide what to observe ­ i.e., what source of information to consult/use ­ and when to observe it. This (joint) decision involves a trade-off between the value of the information that will/might be obtained from the observation and the cost of making the observation. There is little reason to make an observation if the result of that observation can already be confidently estimated on the basis of what is already known or if the result would be of little value in any case; it would be much better to conserve the resources to make a different observation at a different time. Thus making observations (sensing) should be an active choice (Yu et al. (2009)). The problem of active sensing has many applications, from healthcare (the example we use here to illustrate our method) to neuroscience to robotics to wireless communications.
The central point of our approach is that we need to estimate the value of information. This must be learned at training time. We learn the estimated value for a specified set of measurements by first predicting on the basis of the information we have, then deleting the specified set of measurements, inferring what we have deleted on the basis of the data that remains, making a new prediction on the basis of the inferred measurements and the remaining data, and comparing the two predictions. (Part of our architecture is designed specifically for these tasks.)
To infer missing data, we develop a novel architecture called a Multi-directional Recurrent Neural Network (M-RNN). Like a bi-directional RNN (Bi-RNN) (Graves & Schmidhuber (2005)), an MRNN operates forward and backward in each data stream - in the intra-stream directions ­ and across streams ­ in the inter-stream directions. Unlike a Bi-RNN, the timing of inputs into the hidden layers of an M-RNN is lagged in the forward direction and advanced in the backward direction. (To the best of our knowledge, our architecture is the first that operates in this way). Our M-RNN executes both interpolation (intra-stream) and imputation (inter-stream) to infer missing data.
1

Under review as a conference paper at ICLR 2018

Because we need to trade off performance against cost, our neural network must learn ­ at training time ­ how to issue predictions at various cost-performance points. To do this, it creates multiple representations (neural network parameters) at various performance levels associated with different measurement rates (costs). Each representation is learned on the basis of a particular set of missing data; these sets are constructed recursively and adaptively.
An important aspect of our solution to the active sensing problem is that there are important differences between the operation at training time and runtime. At training time we can use data at the current time to infer missing data at an earlier time; i.e. we can operate non-causally. We cannot do so ­ and do not do so ­ at runtime. However, after a new sample is received at runtime, we can and do go back to improve the previous inferences (interpolations and imputations) which will in turn improve both current and future predictions.
To demonstrate the power of our method, we apply it to two real-world medical datasets. We show that our method yields significantly greater predictive power (measured as the Area Under the ROC Curve (AUC)) per unit cost in comparison to other state-of-the-art methods. Because our inference methods are of interest in themselves, we compare the root mean squared error (RMSE) and corresponding AUC for our method to that of state-of-the-art imputation methods in statistics such as White et al. (2011); Rehfeld et al. (2011); Garc´ia-Laencina et al. (2010), RNN-based imputation methods such as Choi et al. (2015); Lipton et al. (2016); Che et al. (2016), and interpolation methods such as Kreindler & Lumsden (2012); Mondal & Percival (2010). In all cases, we demonstrate large and significant improvements.

2 DEEP SENSING

2.1 DATA

The training set consists of N arrays of data. It is convenient to use the language of healthcare and to speak of the array n as the information of patient n, so that there are N patients in the training set. For each patient n, we have a multivariate time-series data stream of length T (the length T and the other components may depend on the patient n but for the moment we suppress the dependence on n) that consists of three components: measurements X , labels Y and time stamps S.

Because measurements are not necessarily made at regular intervals, we distinguish between time
stamps and actual times. The time stamp t = 1, 2, . . . simply indexes the sequence of times at which
measurements were taken; st is the actual time at which the measurements xt were taken and the label yt was realized. For convenience we normalize so that s1 = 0; we assume actual times are strictly increasing: st+1 > st for 0 < t  T - 1.

The label yt represents the outcome realized for patient n at time stamp t (actual time st). Labels may be discrete or continuous. In the former case we are considering a classification problem (e.g.
prediction of an event, such as discharge, clinical deterioration, death); in the latter case, we are
considering a regression problem (e.g. prediction of value or family of values). If we are interested explicitly in the estimation of missing data for its own sake, then yt would represent the actual observed data at time stamp t. Y is the vector of outcomes for this patient. We normalize so that labels and predictions lie in [0, 1].

There are D streams of measurements; each measurement is a real number, but not all measurements
may be observed at each time stamp. Hence we view the set of possible measurements at time stamp t as R = R  {}. We interpret xtd =  to mean that the stream d was not measured at time stamp t; otherwise xtd  R is the measurement of stream d at time stamp t. X is the array of measurements of all streams at all time stamps for the patient under consideration.

It is convenient to introduce some notation to keep track of what is measured/not measured (observed/not observed). For each time stamp t and stream d, write mtd = 0 if xtd =  (not measured) and mdt = 1 if xdt  R (measured). Let td be the actual amount of time that has elapsed since the stream d was measured last. td can be defined recursively as follows:

td =

st - st-1 + td-1 st - st-1

if t > 1, mtd-1 = 0. if t > 1, mdt-1 = 1

where 1d = 0. Write t for the vector of elapsed times at time stamp t and  = {1, 2, ..., T }.

2

Under review as a conference paper at ICLR 2018

The information available for patient n is the triple (Xn, Yn, Sn) The entire training set therefore is the sets of triples D = {(Xn, Yn, Sn)}Nn=1. We use functional notation to identify information about each patient, so xdt (n) is the measurement of stream d at time stamp t for patient n, etc.

2.2 ACTIVE SENSING

At time stamp T , we have an array of measurements (which may or may not include the current label yT ); we must decide the next time sT +1 at which to take new measurements and what measurements to conduct at that time. We measure the information provided by new samples by the effect on the label yT +1, so we define the predictive loss from not sampling as the increase in uncertainty of our prediction of yT +1 and the predictive gain as the decrease in uncertainty of our prediction of yT +1. Our approach is to find the first actual time  at which the (estimated) predictive gain provided
by new samples exceeds the cost of sampling (keeping in mind that the cost of sampling may be different for different streams), and to make the set of measurements at time  that maximizes the
(estimated) predictive gain minus the cost.

The actual error in sampling stream d at sT +1 =  is the difference between the estimated values and the actual measurement edT +1 = |x^dT +1 - xTd +1|. We don't know the actual error so we must construct an estimated error e^Td +1. The confidence intervals in the measurement of xTd +1 are of the form CIx = (x^Td +1 - e^dT +1, x^Td +1 + e^Td +1); e.g.  = 1.96 for the 95% confidence level with normality assumption. Note that the confidence intervals depend only on the estimates and not the true values (which are of course unknown). Each vector of estimates (x^Td +1) of measurements, together with previous data (measured and inferred), can be used to produce a prediction y^Td +1 (see below). The confidence intervals for the stream measurements translate immediately into lower and
upper confidence estimates y^Td,+l 1, y^Td,+u1 (respectively) for the label prediction:

y^Td,+l 1

=

min
x^dT +1CIx

y^d(x^Td +1, XT ,

ST )

y^Td,+u1

=

max
x^dT +1CIx

y^d(x^dT +1,

XT ,

ST )

where XT and ST are previous measurements and measurement times until time stamp T . The (estimated) predictive gain in stream d is therefore the difference y^Td,+u1 - y^Td,+l 1.

Formally, we set sT +1 to be the first actual time at which there is some set of measurements for

which the (estimated) predictive gain exceeds the cost of sampling. At time sT +1, we seek to find

the subset CT +1  M of measurements that maximizes predictive gain minus cost. If we write

predictive gain minus cost as F (CT +1, XT , ST ), then the formal optimization problem is:

CT +1

=

arg

max F (CT +1,
CT +1M

XT ,

ST

)

(1)

= arg max
CT +1M dCT +1

y^Td,+u1(XT , ST ) - y^Td,+l 1(XT , ST ) - cd

where cd is the cost of sampling from stream d.

Predicting Labels: Given data (measured and inferred) until any time stamp T , we generate a prediction y^T . The prediction rule can be learned from training data by any of various machine learning algorithms; we use a standard GRU-based RNN (Chung et al. (2014)). (See Prediction in Section 4.)

Estimating the Values of New Measurements: We view the problem of estimating new measurements as a special case of estimating missing measurements, so we begin by discussing our novel methods for this problem.

Fix data D through time stamp T . Assume that xdt = . There are two standard methods to form an estimate x^td: interpolation and imputation. Interpolation uses only the measurements xdt of the fixed data stream d for other time stamps t (perhaps both before and after t). Interpolation ignores
the correlation with other data streams. Imputation uses only the measurements xtd at the fixed time t for other data streams d . Imputation ignores the correlation with other times.

In principle, we could try to form the estimate x^dt by using all the information in D. However, this would require learning a vast number of parameters and hence a vast number of training instances,
so this is impractical. Instead, we propose an efficient hierarchical learning framework using a novel
RNN architecture that allows us to capture the correlations both within streams and across streams.

3

Under review as a conference paper at ICLR 2018

Blood Pressure

Heart rate

Measured Imputed
 

Interpolation & Imputation Block

 
Time 

Mortality Risk

Risk Prediction
 
Prediction Block

Heart rate

Blood Pressure

Active Sensing
  +  Estimate without sensing
  + 
Active Sensing Block
Time  + 

Figure 1: Deep Sensing Paradigm
2.3 ILLUSTRATION
Deep Sensing consists of three main components: an Interpolation & Imputation block, a Prediction block, and an Active Sensing block. The operations of each block are illustrated in Fig. 1. In the above Figure, we consider two data streams: Blood Pressure and Heart Rate. The Interpolation & Imputation block estimates missing measurements using the observed measurements until the current time. The Prediction block uses the observed and estimated missing measurements to make a (mortality) prediction. At the next time, the Active Sensing block selects a stream (in this case, Blood Pressure) from which to take a measurement (on the basis that the information provided by this new measurement exceeds the cost of sampling). In this illustration the other stream (Heart Rate) is not measured at this next time, but rather is estimated in the Interpolation & Imputation block.
3 RELATED WORKS
Previous works related to Deep Sensing fall into four areas: Active sensing, Inference of missing values, Bayesian optimization, and RNN methods for timely prediction with missing values.
Active sensing1: As discussed in the Introduction, the focus of active sensing (Yu et al. (2009); Alaa & Van Der Schaar (2016)) and of screening policies (Ahuja et al. (2017)) is to determine what and when to measure; this is an important question whenever acquiring measurements is costly. Yu et al. (2009) studies the problem of active sensing using a Bayesian approach with Gaussian processes. This work models the D data streams as Gaussian processes, so the number of parameters is of order D2 and estimation accuracy decreases dramatically as D grows. Moreover, this work creates only a single representation for the entire data set and hence does not effectively trade off predictive gain against measurement cost, and cannot deal with a setting in which there are different costs to sample different variables. Alaa & Van Der Schaar (2016) addresses the problem of active sensing for a single data stream. That work assumes a specific stochastic process to learn the optimal time to sample the next measurement, given the characteristics of the specific stochastic process. Because this work treats only a single data stream and imposes a particular model of the data, this approach cannot be applied to a general data stream and is ineffective in active sensing across multiple data streams. Ahuja et al. (2017) proposes a methodology for personalized screening in the medical domain but the procedure for learning representations is independent of the screening policy.
Missing value inference: There are two standard methods to deal with missing information in timeseries data streams: interpolation and imputation. Interpolation methods (Kreindler & Lumsden (2012); Mondal & Percival (2010)) attempt to capture the temporal relationships within each data stream but not the relationships across streams. Imputation methods (White et al. (2011); Rehfeld et al. (2011); Garc´ia-Laencina et al. (2010)) attempt to capture the synchronous relationships across data streams but not the temporal relationships within streams. (Most of this work assumes a specific
1The problem of active sensing should not be confused with the problem of active learning (e.g. MacKay (1992); Seung et al. (1992)) which focuses on the costly acquisition of labels ­ not measurements.
4

Under review as a conference paper at ICLR 2018
model of the data, rather than learning a representation from the data, as Deep Sensing does.) We are not aware of any previous work that attempts to capture both the relationships within stream and the relationships across streams. .
Bayesian optimization: The problem of costly measurements has been studied in other areas as well. Bayesian optimization (Pelikan et al. (1999); Snoek et al. (2012)) uses a Gaussian process regression (GPR) to approximate the loss function for a given optimization problem (Seo et al. (2000)). This approximation is then used to sequentially evaluate the true loss function at points where the expected decrease in loss is the greatest. When function evaluations are computationally costly (e.g. for hyper-parameter optimization in complex problems), this approach is a way of identifying good minima given constraints on time.
There are significant differences between Bayesian optimization and Deep Sensing. Firstly, in Bayesian optimization, "cost" is usually taken to be computation time, and optimization is performed subject to a cost constraint ­ a maximum number of permissible evaluations. In traditional settings, this cost is essentially treated as constant, and not explicitly considered in selecting points during the optimization procedure. Deep Sensing, on the other hand, trades off cost against (predictive) gain. Secondly, in the active sensing setting we consider, measurements can be taken only forwards in time; in the setting of Bayesian optimization, no restrictions are placed on the location of function evaluations. Active sensing thus captures the problems in the healthcare setting, in which causal predictions are needed to inform the actions of practitioners in a timely fashion. Finally, Bayesian optimization uses GPR to approximate loss functions, which places limitations on the types of functions which it can mimic. Because neural networks are "universal approximators" (Hornik et al. (1989)), the RNNs used in Deep Sensing allow it to model a richer set of functions (and give rise to more complicated and interesting dynamics).
RNN methods with missing values: RNNs have been used successfully for prediction on the basis of time-series data with missing data and irregular sampling. The approach of Gingras & Bengio (1996) is to first replace all the missing information with a mean value and use the feedback loop from the hidden states to update the imputed value while learning the classification problem using a standard RNN. Tresp & Briegel (1998) uses the Expectation-Maximization (EM) algorithm to impute the missing values and uses the reconstructed data streams as inputs to a standard RNN for prediction. As with standard imputation methods, the imputation depends only on the synchronous relationships across data streams and not on the temporal relationships within streams. Parveen & Green (2002) use a linear model to estimate missing values from the latest measurement and the hidden state of each stream. As with standard interpolation methods, the estimate depends only on the temporal relationships within each stream and not on the relationships across streams.
More recent works address both missing values and irregularly sampled time-series data streams (Choi et al. (2015); Lipton et al. (2016); Che et al. (2016); Kim et al. (2017)). These papers use the sampling times to capture the informative missingness and time interval information to deal with irregular sampling. They do this by concatenating the measurements, sampling information and time intervals and using the concatenation as the input of an RNN. These papers differ in the replacements they use for missing values. Choi et al. (2015); Lipton et al. (2016); Kim et al. (2017) replace the missing values with 0, mean values or latest measurements ­ all of which are independent of either the intra-stream or inter-stream relationships or both. Therefore, those methods cannot be extended to our active sensing algorithm. Che et al. (2016) imputes the missing values using only the latest measurements, the mean value of each stream, and the time interval. It is not bi-directional and so cannot use information available at a given time to update estimates of information that is missing at an earlier time.
4 DEEP SENSING: ALGORITHM
In this section, we describe the training and runtime stages of the Deep Sensing algorithm. Fig. 2 shows block diagrams of the two stages.
4.1 TRAINING STAGE
The training stage of Fig. 2 shows the block diagram of the entire 5 blocks of the training stage. The first 4 blocks train Interpolation block (), Imputation block (), Error Estimation block (), Pre-
5

Under review as a conference paper at ICLR 2018

Original data ( )
Data ( )
Training Stage Runtime Stage

Inference (M-RNN)

Interpolation ( ) (Bi-RNN)

Imputation ( ) (FC Layer)

Newly sampled dataset (

Prediction ( ) (RNN)
Error Estimation ( ) (M-RNN)
)

Trained functions  = { ,  ,  ,  }

Acceptable Performance level

Select  based on the acceptable performance level

:

Multiple Representation ( )
Adaptive Sampling

New Instance

Interpolation ( )

Imputation ( )

Error Estimation ( )

Prediction ( )

When / Which measurements should be sensed

Active Sensing

Figure 2: Block diagram of Deep Sensing

diction block (). The Adaptive Sampling block creates multiple representations based on different sets of missing data (The importance of this will be explained).

Loss function: The objective of the interpolation and imputation blocks is to minimize the error
that would be made in estimating missing measurements. Evidently, we cannot estimate the error of
a measurement that is truly missing in the dataset. Instead we fix a measurement that was actually
made, remove that measurement, form an estimate for the measurement, and then compute the error between the estimate and the actual measurement (that was deleted) using only the data set D - xdt (i.e. the data set with xtd removed). If xdt is an actual measurement and x^td is the estimate formed when xtd is removed then the loss can be defined as the mean squared error (MSE) l(x^dt , xdt ) = (x^td - xdt )2. The loss for the entire dataset D is defined as

N
L({x^dt , xdt }) =
n=1

Tn t=1

D d=1

mdt

(n)

×

(x^dt

(n)

-

xdt

(n))2

Tn t=1

D d=1

mtd(n)

.

Interpolation: The objective of the interpolation block is to construct an interpolation function
 that operates within a stream. To emphasize that the estimate for xdt depends on the data with xtd removed, we abuse notation and write x~td = (D - xdt ). However, keep in mind that we are actually only using the data from stream d, not the data from other streams. We construct

the estimation function  using a bi-directional recurrent neural network (Bi-RNN) with a Gated

Recurrent Unit (GRU). However, unlike a conventional Bi-RNN (Graves & Schmidhuber (2005)),

the timing of inputs into the hidden layer is lagged in the forward direction and advanced in the

backward direction: at time t, inputs of forward hidden states come from t-1 and inputs of backward

hidden states come from t + 1. Mathematically, we have:

-- --

ot = W h t + W h t + co,

- ht

=

(1

-

-z t)

- h t-1

+

-z t

- h^ t,

-z t

=

- (W zxt-1

+

- - U z h t-1

+

- V zt-1

+

-c z),

- ht

=

(1

-

-z t)

- h t+1

+

-z t

- h^ t,

-z t

=

- (W zxt+1

+

- - U z h t+1

+

- V zt+1

+

-c z),

- h^ t

=

- (W hxt-1

+

- Uh

(-r t

- h^ t

=

- (W hxt+1

+

U-h(-r t

- h t-1)

+

- Vh

t-1

+

-c h),

- h t+1

)

+

- V ht+1

+

-c h),

-r t

=

- (W rxt-1

+

- - U r h t-1

+

- V rt-1

+

-c r),

-r t

=

- (W rxt+1

+

- - U r h t+1

+

- V rt+1

+

-c r)

where is element-wise multiplication,  is the sigmoid function,  is tanh function, and arrows indicate forward/backward direction. The output ot is the interpolated value x~t. In this interpolation

6

Under review as a conference paper at ICLR 2018

Imputation

Outputs -1

+1

FC Layers

FC Layers

FC Layers

Outputs

Outputs -1

+1

Imputation

Imputation

Interpolation

Interpolation

Interpolation

BiRNN

BiRNN

BiRNN

-1 Inputs
()

+1

Inputs
()

-1
Inputs
()

+1

Figure 3: Diagram of the neural networks for M-RNN

block, we are only using/capturing the temporal correlation within each stream. As a consequence, the matrices U, V, W are block-diagonal. Hence the total number of parameters that must be learned is linear in the number of streams D (on the other hand, in standard Bi-RNN, the number of parameters to be learned will be on the order of D2). This avoids overfitting and leads to significant performance improvements as compared to standard Bi-RNN. See the Interpolation part of Fig. 3.
Imputation: The objective of the imputation block is to construct an imputation function  that operates across streams. Again, we abuse notation and write xdt = (D - xtd). Keep in mind that now we are using only data at time stamp t, not data from other time stamps. We construct the function  to be independent of the time stamp t; so we construct it using fully connected layers (FC); see Imputation part of Fig 3:
ot = W ht + co, ht = U xt + V x~t + Qmt + ch
where ot = x^t and the block-diagonal entries of U are zero because we do not use xdt to estimate x^dt . We use multiple deeply stacked FC layers using linear activation functions.
We jointly learn the functions  and  using the stacked networks of Bi-RNN and FC layers.

,  = arg min
,

L({

{xdt , 

{xtd, mtd, td}t=1:T

, mdt }d=1:D

, xtd})

We refer to the entire structure as a Multi-directional Recurrent Neural Network (M-RNN); see Fig.3.

Prediction: Now that we have a procedure to reconstruct (interpolate/impute) missing data, we

use the reconstructed data to predict the labels. We accomplish this in the prediction block. Once

again, we construct the function to minimize the prediction error when we predict an observed label.

The loss function is defined as L({y^t, yt})

=

1 N

optimizes the function:

N n=1

Tn t=1

(y^t

(n)-yt

(n))2

Tn

The prediction block

 = arg min


L({y^t, yt})

= arg min


L({ {xtd, x^td, td}t=1:T,d=1:D

, yt})

Note that we use the time intervals td as inputs to the prediction function in order to deal with the fact that the data streams are irregularly sampled. This optimization problem is a standard problem
for timely prediction so we can use a standard GRU-based RNN (Chung et al. (2014)) to solve it.

7

Under review as a conference paper at ICLR 2018

Error Estimation: At runtime, we have to decide when/what to sample in the active sensing block.
We make this decision on the basis of predictive gain which is determined by the difference between
our estimate of a measurement and what the actual value of the measurement would be; the actual error edt = |x^dt - xtd|. Of course, we do not know what this will be because we do not know what the actual value of the measurement would be. Hence we need an estimate e^dt of the actual error. As before, we construct this estimate on the basis of the actual training data that we have. For
tractability, we posit that this estimate depends on the pattern of missing data and on time intervals
of the measurements but not on actual measurements. We use the same mean square loss function:

N
L({e^t, et}) =

Tn t=1

n=1

Hence we need to solve for the function

D d=1

mtd(n) × (e^td(n) -

Tn t=1

D d=1

mtd(n)

etd(n))2

.

 = arg min


L({e^dt , etd})

= arg min


L({ {md }d=1:D, {td, mtd}t=1:T

, edt }) .

Because this involves both inter-stream and intra-stream variables, we again use our M-RNN structure. However, the inputs and outputs are different: for the interpolation and imputation blocks, the inputs are the measurements {xd }, sensing information {md} and the time intervals {td} and the output is the estimated measurement x^dt . For the error estimation block, the inputs are the sensing information {md} and the time intervals {td} and the output is the estimation error e^dt .
Adaptive Sampling: As pointed out in Section 2, the decision of what/when to sense arises from trading off the cost of measurement against the predictive gain of measurement. To this point, we have constructed a procedure that achieves a certain performance ­ predictive gain ­ at a prescribed cost. If we are willing to settle for a lower level of performance, we can do so at lower cost by sampling less. To know how much less to sample we need to know how much information would be lost if we sampled less, which we can determine by carrying out the previous procedure to produce multiple representations based on different patterns of missing data. For each representation we need to train the functions , , ,  on the appropriate training set, which is smaller than the original training set.

To construct these representations, we begin with the original training set and remove additional measurements. We should not do this at random, but rather using the informational criteria we use to decide on active sensing at runtime: remove measurements whose predictive gain is below a given threshold. We call this adaptive sampling. This will yield a decreasing sequence of data sets D0, D1, ..., DR (where D0 = D, the original dataset).
Fix thresholds u1, . . . , uR > 0. (In practice, these would be specified by the user.) We begin with D0. For each measurement xtd(n)  D0 we use the current functions  = 0,  = 0,  = 0,  = 0 to compute the predictive gain from that measurement in the current dataset. We sequentially delete all the measurements whose predictive gain is below the prescribed threshold u1; this yields a reduced data set D1. We now retrain on D1 to obtain new functions 1, 1, 1, 1 and repeat the same procedure: for each measurement xtd(n)  D1, we compute the predictive gain from that measurement in the current dataset and sequentially delete those measurements whose predictive gain is below threshold u2, etc. In retraining to obtain the functions r, r, r, r, we initialize the parameters of each block to be the optimal parameters from the previous dataset Dr-1; this leads to fast convergence. (For the original dataset, we use the Xavier initialization method.)

Note that if we increase the threshold ur, we delete more data and retain fewer samples, so the expenditure on sampling is smaller. However because we have trained on fewer samples, our pre-
dictions will be less accurate. This creates the cost-performance trade-off.

4.2 RUNTIME
The runtime stage of Fig. 2 shows the block diagram in real-time. At runtime, the user prescribes an acceptable level of performance (required predictive gain and a confidence level ). We then choose the largest r for which the representation r = (r, r, r, r) achieves at least the prescribed level of performance and use r to make the sampling decision. As described in Section 2, this means that at time sT we choose sT +1 to be the first time at which the predictive gain (estimated by using r, r and the prescribed confidence level) is above the given cost.

8

Under review as a conference paper at ICLR 2018
At current time t, Deep Sensing estimates the measurements at time t + 1 using only measurements until the current time t, setting all other measurements to their initialization value. Then, it computes the predictive gain of each stream and senses the streams whose predictive gain is larger than the threshold ur. After sampling measurements at time t + 1, these newly sampled measurements are used to re-estimate the measurements that were missing before t + 1 (using the backward M-RNN architecture). Then, using all the newly imputed measurements through time t + 1, Deep Sensing makes its prediction at t + 1. (If at time t + 1 there are no streams for which the predictive gain is larger than the threshold, Deep Sensing moves to time t + 2, etc. Notice that Deep Sensing is only required to issue a prediction at each time stamp; i.e. at each time at which a measurement is actually made). Figure 5 in the Appendix details the operation of Deep Sensing in runtime. Deep Sensing is also computationally efficient. For instance, on the MIMIC-III dataset (23,200 samples, 40 dimensions, 25 time stamps), Deep Sensing takes less than one hour on a machine with i7-6900K CPU (3.2GHz x 16) and 64GB RAM.
5 EXPERIMENTS
In this section, we evaluate the performance of Deep Sensing using two real-world medical datasets. Our experimental results present three sets of comparisons: active sensing, prediction, and missing value inference. The first comparison shows the performance gain of Deep Sensing (in comparison with benchmarks) in sensing the critical measurements for prediction. The second and third comparisons show the performance gain of M-RNN algorithm in estimating missing values and the effect on prediction accuracy. We describe all configurations of the various algorithms in the Appendix.
5.1 DATA DESCRIPTION
We conducted our experiments on the two real-world medical datasets. First, we used MIMIC-III (Johnson et al. (2016)) which monitored the patients in the intensive care units (ICU) to timely estimate the mortality risk. We used 22,803 patients who were monitored for 20 vital signs (e.g. heart rate, respiratory rate) and 20 lab tests (e.g. creatinine, chloride). So there are 40 physiological data streams in all. The sampling times of vital signs and lab tests are around 1 hour and 24 hours, respectively. Second, we used a dataset (that we call Wards) that was assembled and described by Alaa et al. (2017) and which the authors were kind enough to share with us. This dataset monitored patients in hospital wards in order to make timely predictions of clinical deterioration. This dataset has data for 6,094 patients with 37 physiological data streams including both vital signs and lab tests. The sampling times of vital signs and lab tests are approximately 4 hours and 24 hours, respectively.
5.2 SIMULATION SETUP
We randomly divided the dataset into a mutually exclusive training set (80%) and testing set (20%). We conducted 10 independent experiments with different combinations of training/testing sets; we report the mean and variance of the performance in the 10 experiments. (For details, see the Appendix.) In our experiments we are trying to predict which patients will experience an adverse event within 24 hours from the current time, so we assigned the label 1 to patients who experienced the relevant adverse event (death or clinical deterioration) within 24 hours; for other patients we assigned the label 0. (Formally: yt = 1 for st > ST - 24 and yt = 0 for st  ST - 24 where ST is the time that the adverse event occurred.)
Active sensing: To evaluate the performance of Deep Sensing, we graph cost (proxied here as the observation rate) versus predictive accuracy (area under the ROC curve (AUC)) for Deep Sensing (with multiple representations), Deep Sensing (with a single representation ­ using only the original dataset to train), Deep Sensing (with random sampling) and two benchmarks based on the method of Che et al. (2016) for prediction with missing data (sampling either using the method of Deep Sensing or randomly). We take the cost for lab tests to be 5 times the cost for taking vital signs.
Prediction: We also evaluate prediction given only the available observations. The prediction we consider is the adverse events (death or clinical deterioration); we use AUC as the performance metric. We compare the performance of Deep Sensing with three state-of-the-art RNN timely-prediction models and a GRU-based RNN method using conventional estimation methods for interpolation and imputation. To make the comparison fair, we use GRU-based RNNs for each benchmark. Deep
9

Under review as a conference paper at ICLR 2018

AUC

0.85
0.8
0.75
0.7 Deep Sensing (Multiple Representation) Deep Sensing (One Representation) Deep Sensing (Random Sampling)
0.65 Che et al. [2016] (Sampling by Deep Sensing) Che et al. [2016] (Random Sampling)
50 55 60 65 70 75 80 85 90 95 100 Cost = Observation Rate (%)
Figure 4: Active Sensing: AUC vs Cost for Different Solutions with MIMIC-III dataset (Lab test cost = 5× Vital sign cost)

Table 1: AUC for Deep Sensing and Benchmarks with MIMIC-III dataset (See the text for descriptions of Settings A, B). *: p-value < 0.05

AUC (Mean ± Std (Gain %))

MIMIC-III (Setting A) MIMIC-III (Setting B)

Proposed Model Deep Sensing

0.8019 ± 0.0112 (-)

0.8019 ± 0.0112 (-)

RNN based

Choi et al. (2015) 0.7112 ± 0.0134 (31.4 %) 0.7598 ± 0.0110 (17.5 %) Lipton et al. (2016) 0.7072 ± 0.0108 (32.3 %) 0.7551 ± 0.0115 (19.1 %)
Che et al. (2016) 0.7133 ± 0.0111 (30.9%) 0.7593 ± 0.0123 (17.7 %)

Interpolation + RNN

Spline Cubic

0.7045 ± 0.0137 (33.0 %) 0.7542 ± 0.0108 (19.4 %) 0.7012 ± 0.0129 (33.7 %) 0.7569 ± 0.0112 (18.5 %)

Imputation + RNN

MICE Kernel
EM

0.7093 ± 0.0132 (31.9 %) 0.7571 ± 0.0121 (18.4 %) 0.7002 ± 0.0119 (33.9 %) 0.7534 ± 0.0139 (19.7 %) 0.7019 ± 0.0098 (33.5 %) 0.7531 ± 0.0107 (19.8 %)

Sensing is compared with the benchmarks in two settings. In setting A, we sampled 60% of the measurements; for Deep Sensing, we used the Deep Sensing algorithm, for the benchmarks, we use random sampling. In setting B we sampled 60% of the measurements, using the Deep Sensing algorithm everywhere.
Estimation of missing values: To evaluate the performance of the M-RNN algorithm (the combination of interpolation and imputation block) in estimating missing values, we compare with other standard methods: interpolations (Spline and Cubic Kreindler & Lumsden (2012)), imputations (MICE (White et al. (2011)), Kernel (Rehfeld et al. (2011)) and EM (Garc´ia-Laencina et al. (2010))). We randomly remove 30% of the observations and treat them as missing. We then estimate the missing observations values using our M-RNN algorithm and benchmarks. We use the root mean square error (RMSE) between estimated values and actual observed values as the performance metric.
5.3 SIMULATION RESULTS AND DISCUSSION
Active Sensing: As Fig. 4 illustrates, Deep Sensing predicts best for every specification of cost; equivalently, Deep Sensing expends the least cost for every specified prediction accuracy. Fig. 4 also shows that the performance gains achieved by Deep Sensing come both from active sampling and from better inference. As seen in Figure 4, if the observation rate were 100% (so there would be no gain from active sensing), the AUC improvement would be limited. However, as the observation rate decreases the AUC gain increases because Deep Sensing actively decides what to sample and when to sample, thereby providing results that are much superior to random sampling.
Prediction: Table 1 and 2 provide the mean, standard deviation, and performance gain (%) (in terms of AUC) from Deep Sensing in comparison to the benchmarks for two real-world medical datasets. Table 1 and 2 show that Deep Sensing provides significant gains of the prediction accuracy for both datasets (around 30% in Setting A and 20% in Setting B for all the benchmarks). The
10

Under review as a conference paper at ICLR 2018

Table 2: AUC for Deep Sensing and Benchmarks with Wards dataset (See the text for descriptions of Settings A, B). *: p-value < 0.05

AUC (Mean ± Std (Gain %))

Wards (Setting A)

Wards (Setting B)

Proposed Model Deep Sensing

0.8348 ± 0.0201 (-)

0.8348 ± 0.0201 (-)

RNN based

Choi et al. (2015) 0.7739 ± 0.0264 (26.9 %) 0.8028 ± 0.0184 (16.2 %) Lipton et al. (2016) 0.7893 ± 0.0237 (21.6 %) 0.8107 ± 0.0191 (12.7%)
Che et al. (2016) 0.7905 ± 0.0143 (21.1 %) 0.8159 ± 0.0160 (10.3%)

Interpolation + RNN

Spline Cubic

0.7829 ± 0.0085 (23.9 %) 0.8023 ± 0.0187 (16.4 %) 0.7712 ± 0.0084 (27.8 %) 0.7993 ± 0.0137 (17.7%)

Imputation + RNN

MICE Kernel
EM

0.7499 ± 0.0096 (33.9%) 0.7877 ± 0.0149 (22.2 %) 0.7397 ± 0.0155 (36.5 %) 0.7728 ± 0.0187 (27.3 %) 0.7593 ± 0.0168 (31.4%) 0.7784 ± 0.0163 (25.5%)

significant gains for prediction come from the combination of accurate missing value inference and active sensing as seen in Figure 4.
Estimation of missing values: Table 3 shows the mean and standard deviation of the RMSE for M-RNN and benchmarks for both the MIMIC-III and the Wards dataset. The RMSE of M-RNN is less than half that of the best benchmark in MIMIC-III dataset and less than 70% that of the best benchmark in Wards dataset. All the improvements are statistically significant (p-value < 0.05).

Table 3: RMSE of Missing information for M-RNN and Benchmarks with MIMIC-III and Wards datasets. *: p-value < 0.05

Datasets

Interpolation

Imputation

MIMIC-III

Metrics RMSE - Mean RMSE - Std

M-RNN 0.0137 0.0013

Spline 0.0735 0.0012

Cubic 0.0279 0.0013

MICE 0.0611 0.0011

Kernel 0.0556 0.0011

EM 0.0467 0.0014

Wards

RMSE - Mean 0.0169 0.0314 0.0211 0.0554 0.0627 0.0761 RMSE - Std 0.0019 0.0011 0.0021 0.0013 0.0014 0.0017

6 CONCLUSION
The problem of active sensing is a very important one but has not been thoroughly treated in the literature. We present here a solution based on a novel deep learning architecture. As part of the solution, we provide a new method for reconstructing missing data that exploits joint interpolation within data streams and imputation across data streams. We demonstrate that Deep Sensing makes large and statistically significant improvements in comparison with state-of-the-art benchmarks in two real-world datasets.

11

Under review as a conference paper at ICLR 2018
REFERENCES
Kartik Ahuja, William R Zame, and Mihaela van der Schaar. Dpscreen: Dynamic personalized screening. In Advances in Neural Information Processing Systems, 2017.
Ahmed M Alaa and Mihaela Van Der Schaar. Balancing suspense and surprise: Timely decision making with endogenous information acquisition. In Advances in Neural Information Processing Systems, pp. 2910­2918, 2016.
Ahmed M Alaa, Jinsung Yoon, Scott Hu, and Mihaela van der Schaar. Personalized risk scoring for critical care prognosis using mixtures of gaussian processes. IEEE Transactions on Biomedical Engineering, 2017.
Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neural networks for multivariate time series with missing values. arXiv preprint arXiv:1606.01865, 2016.
Edward Choi, Mohammad Taha Bahadori, and Jimeng Sun. Doctor ai: Predicting clinical events via recurrent neural networks. arXiv preprint arXiv:1511.05942, 2015.
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014.
Pedro J Garc´ia-Laencina, Jose´-Luis Sancho-Go´mez, and An´ibal R Figueiras-Vidal. Pattern classification with missing data: a review. Neural Computing and Applications, 19(2):263­282, 2010.
Francois Gingras and Y Bengio. Recurrent neural networks for missing or asynchronous data. In Proc NIPS, volume 8, 1996.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Aistats, volume 9, pp. 249­256, 2010.
Alex Graves and Ju¨rgen Schmidhuber. Framewise phoneme classification with bidirectional lstm and other neural network architectures. Neural Networks, 18(5):602­610, 2005.
Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are universal approximators. Neural networks, 2(5):359­366, 1989.
Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-iii, a freely accessible critical care database. Scientific data, 3, 2016.
Han-Gyu Kim, Gil-Jin Jang, Ho-Jin Choi, Minho Kim, Young-Won Kim, and Jaehun Choi. Recurrent neural networks with missing information imputation for medical examination data prediction. In Big Data and Smart Computing (BigComp), 2017 IEEE International Conference on, pp. 317­323. IEEE, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.
David M Kreindler and Charles J Lumsden. The effects of the irregular sample and missing data in time series analysis. Nonlinear Dynamical Systems Analysis for the Behavioral Sciences Using Real Data, pp. 135, 2012.
Zachary C Lipton, David C Kale, and Randall Wetzel. Directly modeling missing data in sequences with rnns: Improved classification of clinical time series. arXiv preprint arXiv:1606.04130, 2016.
David JC MacKay. Information-based objective functions for active data selection. Neural computation, 4(4):590­604, 1992.
Debashis Mondal and Donald B Percival. Wavelet variance analysis for gappy time series. Annals of the Institute of Statistical Mathematics, 62(5):943­966, 2010.
Shahla Parveen and Phil Green. Speech recognition with missing data using recurrent neural nets. In Advances in Neural Information Processing Systems, pp. 1189­1195, 2002.
12

Under review as a conference paper at ICLR 2018
Martin Pelikan, David E Goldberg, and Erick Cantu´-Paz. Boa: The bayesian optimization algorithm. In Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-Volume 1, pp. 525­532. Morgan Kaufmann Publishers Inc., 1999.
Kira Rehfeld, Norbert Marwan, Jobst Heitzig, and Ju¨rgen Kurths. Comparison of correlation analysis techniques for irregularly sampled time series. Nonlinear Processes in Geophysics, 18(3): 389­404, 2011.
Sambu Seo, Marko Wallat, Thore Graepel, and Klaus Obermayer. Gaussian process regression: Active data selection and test point rejection. In Neural Networks, 2000. IJCNN 2000, Proceedings of the IEEE-INNS-ENNS International Joint Conference on, volume 3, pp. 241­246. IEEE, 2000.
H Sebastian Seung, Manfred Opper, and Haim Sompolinsky. Query by committee. In Proceedings of the fifth annual workshop on Computational learning theory, pp. 287­294. ACM, 1992.
Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, pp. 2951­2959, 2012.
Volker Tresp and Thomas Briegel. A solution for missing data in recurrent neural networks with an application to blood glucose prediction. Advances in Neural Information Processing Systems, pp. 971­977, 1998.
Ian R White, Patrick Royston, and Angela M Wood. Multiple imputation using chained equations: issues and guidance for practice. Statistics in medicine, 30(4):377­399, 2011.
Shipeng Yu, Balaji Krishnapuram, Romer Rosales, and R. Bharat Rao. Active sensin. In Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics, pp. 639­646, 2009.
13

Under review as a conference paper at ICLR 2018

APPENDIX
THE DETAIL PROCEDURES IN RUNTIME OF DEEP SENSING

Runtime

Data until T

Inference

Streams

Stream 1

x

xx

Inference x

Stream D

xx

Sampled x Infered

T

Time

x T+1 Error
Estimation

Active Sensing
Uncertainty Prediction

Prediction CI at T+1

Sensing by Active Sensing

Re-Inference

Prediction

x x xx

xx

x Re-Infered

T T+1

Stream Error Estimation
Stream 1 Stream 2 Stream 3

Zoom in

Imputation

Stream Importance

Prediction ( ) Medium Low High

Uncertainty Estimation Prediction
Removing by Adaptive Sampling Sensing by Active Sensing

Measurements (95% CI) at T+1

Prediction (95% CI) at T+1

Figure 5: The detail procedures in runtime of Deep Sensing

14

Under review as a conference paper at ICLR 2018

CONFIGURATIONS OF THE EXPERIMENTS
We used 'interp1' package in MATLAB for interpolation algorithms, and 'mice' and 'amelia' packages in R for imputation algorithms. Table 4 illustrates the details of the prediction algorithm.

Table 4: Configurations of the Experiments

Blocks

Categories

Configurations

Interpolation

Model Initialization Optimization Batch size and iterations Depth Constraints

Modified Bi-RNN with GRU Xavier Initialization (Glorot & Bengio (2010)) Adam Optimization (Kingma & Ba (2014)) (learning rate = 0.05) Batch size = 100, Iterations = 1000 5 The matrix parameters are block-diagonals

Imputation

Model Initialization Optimization Batch size and iterations Depth Constraints

Fully Connected Layers Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 10 (Activate function: Linear) The block-diagonal part of the matrix is zero.

Error Estimation

Model Initialization Optimization Batch size and iterations Depth Constraints

Multi-directional RNN (M-RNN) with GRU Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 5 for Bi-RNN, 10 for FC with linear activation function Block-diagonal matrix parameters for Bi-RNN

Model

Initialization

Prediction

Optimization Batch size and iterations

Depth

Constraints

Adam: Adaptive Moment Estimation

RNN with GRU Xavier Initialization Adam Optimization (learning rate = 0.05) Batch size = 100, Iterations = 1000 10 None

15

