Under review as a conference paper at ICLR 2018
GANITE: ESTIMATION OF INDIVIDUALIZED TREATMENT EFFECTS USING GENERATIVE ADVERSARIAL NETS
Anonymous authors Paper under double-blind review
ABSTRACT
Estimating individualized treatment effects (ITE) is a challenging task due to the need for an individual's potential outcomes to be learned from biased data and without having access to the counterfactuals. We propose a novel method for inferring ITE based on the Generative Adversarial Nets (GANs) framework. Our method, termed Generative Adversarial Nets for inference of Individualized Treatment Effects (GANITE), is motivated by the possibility that we can capture the uncertainty in the counterfactual distributions by attempting to learn them using a GAN. We generate proxies of the counterfactual outcomes using a counterfactual generator, G, and then pass these proxies to an ITE generator, I, in order to train it. By modeling both of these using the GAN framework, we are able to infer based on the factual data, while still accounting for the unseen counterfactuals. We test our method on three real-world datasets (with both binary and multiple treatments) and show that GANITE outperforms state-of-the-art methods.
1 INTRODUCTION
Individualized treatment effects (ITE) estimation using observational data is a fundamental problem that is applicable in a wide variety of domains. For instance, (1) in understanding the heterogeneous effects of drugs (Shalit et al. (2016); Alaa & van der Schaar (2017); Alaa et al. (2017)); (2) in evaluating the effect of a policy on unemployment rates (LaLonde (1986); Smith & Todd (2005)); (3) in verifying which factor causes a certain disease (Ho¨fler (2005)) and (4) estimating the effects of pollution on the weather (Hannart et al. (2016)).
As explained in Spirtes (2009), the problem of ITE estimation differs from the standard supervised learning problem. First, among the potential outcomes, only the factual outcome is actually observed (revealed), counterfactual outcomes are not observed and so the entire vector of potential outcomes can never be obtained. Second, unlike randomized controlled trials (RCT), observational studies are prone to treatment selection bias. For instance, left ventricular assist device (LVAD) treatment is mostly applied to high-risk patients with severe cardiovascular diseases before heart transplantation, the distribution of features among these patients will be significantly different to the distribution among non-LVAD treated patients (Kirklin et al. (2010)). The sample distribution can vary drastically across different choices of treatments and therefore, if we were to apply a supervised learning framework for each treatment separately, the learned models would not generalize well to the entire population.
Classical works in this domain solved the problem of estimating the average treatment effects from observational data (Dehejia & Wahba (2002b); Lunceford & Davidian (2004)). These works account for the selection bias using propensity scores (the estimated probability of receiving a treatment) to create unbiased estimators of the average treatment effect. Dehejia & Wahba (2002b) used a one-toone matching methodology to pair treated and control patients with similar features while Lunceford & Davidian (2004) used propensity scoring weighing to account for the selection bias. More recent works focus on individualized treatment effects (Chipman et al. (2010); Wager & Athey (2017); Athey & Imbens (2016); Lu et al. (2017); Alaa & van der Schaar (2017); Porter et al. (2011); Johansson et al. (2016); Alaa et al. (2017); Louizos et al. (2017); Shalit et al. (2016)). Detailed qualitative
1

Under review as a conference paper at ICLR 2018
comparisons to these works will be discussed in the next subsection and numerical comparisons can be found in Section 5.
In this paper, we propose a novel approach that attempts to not only fit a model to the observed factual data, but also account for the unseen counterfactual outcomes. We view the factual outcome as an observed label and consider the counterfactual outcomes to be missing labels. Missing labels are generated by the well-known Generative Adversarial Nets (GAN) framework (Goodfellow et al. (2014)). More specifically, the counterfactual generator of GANITE attempts to generate counterfactual outcomes in such a way that when given the combined vector of factual and generated counterfactual outcomes the discriminator of GANITE cannot determine which of the components is the factual outcome. With the complete labels (combined factual and estimated counterfactual outcomes), the ITE estimation function can then be trained for inferring the potential outcomes of the individual based on the feature information in a supervised way. By also modelling this ITE estimation function using a GAN framework, we are able not only to predict the expected outcomes but also provide confidence intervals for the predictions, which is very important in, for example, the medical setting.
Unlike many other state-of-the-art methods, our method naturally extends to - and in fact is defined in the first place for - any number of treatments. We conduct experiments with three real-world observational datasets (with both binary and multiple treatments), and GANITE outperforms stateof-the-art methods.
1.1 RELATED WORKS
Previous works on ITE estimation can be divided into three categories. In the first, a separate model is learned for each treatment; this approach does not account for selection bias and so each model learned will be biased toward the distribution of that treatment's population. In the second, the treatment is considered a feature, with one model learned for everything, and the mismatch between the entire sample distribution and treated and control distributions is adjusted in order to account for selection bias. For instance, Chipman et al. (2010); Wager & Athey (2017); Athey & Imbens (2016); Lu et al. (2017) used tree-based models, Porter et al. (2011) used doubly-robust methods, Dehejia & Wahba (2002b); Lunceford & Davidian (2004), k-nearest neighbor (kNN) Crump et al. (2008) used propensity and matching based methods, and Johansson et al. (2016); Louizos et al. (2017) used deep learning approaches to solve the ITE problem under this one model methodology. In the third category, Alaa & van der Schaar (2017); Alaa et al. (2017) used a multi-task model approach. Alaa et al. (2017) used multi-task neural nets to estimate (1) the selection bias, (2) the controlled outcome and (3) the treated outcome with shared layers across these three tasks. Alaa & van der Schaar (2017) used a Gaussian Process approach in the multi-task model setting. Our work is perhaps most similar to Alaa & van der Schaar (2017) since there, too, they attempted to account for the counterfactuals and were similarly able to provide confidence in their estimates using credible intervals. They were able to access counterfactuals through a posterior distribution which was then accounted for in the learning of their model.
2 PROBLEM FORMULATION: ESTIMATION OF INDIVIDUALIZED TREATMENT EFFECTS
Let X denote the s-dimensional feature space and Y the set of possible outcomes. Consider a joint distribution, µ, on X × {0, 1}k × Yk where k is the number of possible treatments. Suppose that (X, T, Y)  µ. We call X  X the (s-dimensional) feature vector, T  (T1, ..., Tk)  {0, 1}k the treatment vector and Y  (Y1, ..., YT )  Yk the vector of potential outcomes (or the Individualized Treatment Effects (ITE)). We assume that (with probability 1), there is precisely one non-zero component of T and we denote by  the index of this component. Denote by µX the marginal distribution of X and by µY(x) the conditional distribution of Y given X = x, for x  X (marginalized over T). This setting is known as the Rubin-Neyman causal model (Rubin (2005)).
We introduce two1 assumptions about the distribution µ in the Rubin-Neyman causal model.
1All works cited in the Related Works section make this assumption.
2

Under review as a conference paper at ICLR 2018

Assumption 1. (Overlap) For all x  X , for all i  {1, ..., k}, 0 < P(Ti = 1|X = x) < 1.

This assumption ensures that at every point in the feature space, there is a non-zero probability of being given treatment i for every i.
Assumption 2. (Unconfoundedness) Conditional on X, the potential outcomes, Y, are independent of T,
Y T|X.

|=

This assumption is also referred to as no unmeasured confounding and requires that all joint influ-
ences on Y and T are measured. Note that this assumption means that µY(x) no longer needs to be marginalized over T, since, under this assumption, they are independent.

Assume now that we observe samples of (X, T, Y) (whose joint distribution we denote by µf ), so that our dataset, D, is given by D = (x(n), t(n), y(n)(n))Nn=1. Importantly, we only observe the component of the potential outcome vector that corresponds to the assigned treatment, we call this
the factual outcome, and refer to unobserved potential outcomes as counterfactual outcomes or just
counterfactuals. We denote by yf (n) and ycf (n) the factual outcome and (vector of) counterfactual outcome(s), respectively. From this point forward, we omit the dependence on n for ease of notation.

In this setting, we wish to be able to draw samples from µY(x) for any x  X . We measure the performance of the generator, I(x), using two different metrics depending on whether k = 2 (i.e.
binary treatments) or k > 2 (i.e. multiple treatments).

For k = 2 we use the expected Precision in Estimation of Heterogeneous Effects, P EHE, introduced in Hill (2011), given by:

P EHE = ExµX EyµY(x)[y1 - y0] - Ey^I(x)[y^1 - y^0] 2 .

(1)

For k > 2 we use the expected mean squared error:

MSE = ExµX ||EyµY(x) y - Ey^I(x)[y^]||22

(2)

where || · ||2 is the standard 2-norm in Rk.
In order to achieve this goal, we separate the problem into two parts. First, we attempt to generate proxies for the unobserved counterfactual outcomes using a counterfactual generator (G) to create a complete dataset. Then, using this proxy dataset, we learn the ITE generator, I.

3 GANITE: GENERATIVE ADVERSARIAL NETS FOR INFERENCE OF INDIVIDUALIZED TREATMENT EFFECT ESTIMATION
3.1 OVERVIEW
The objective of GANITE is to generate potential outcomes for a given feature vector x. However, due to the lack of counterfactual outcomes we are unable to learn the distribution of potential outcomes directly. To account for these counterfactuals, we first attempt to generate samples, y~cf , using a counterfactual generator, G, from the distribution µYcf (x, t, yf ) (the conditional distribution of the counterfactual outcomes, Ycf given that X = x, T = t and Y = yf ) for each sample in our dataset. We can then combine these proxy counterfactuals with the original dataset to obtain a complete dataset D~ = {x(n), t(n), y~(n)}Nn=1 where y~ is the combination of yf and y~cf (with y~ = yf ). The ITE generator, I, can then be optimized using D~.
We follow a conditional GAN framework similar to the one set out in Mirza & Osindero (2014) to model the latter of these generators. For the former, we have to use a different discriminator in order to capture the same idea. More specifically, GANITE consists of two blocks: a counterfactual imputation block and an ITE block, each of which consists of a generator and a discriminator. We describe each of these blocks and their components in more detail in the following subsection.

3

Under review as a conference paper at ICLR 2018

Captions
Inputs Outputs
 Feature vector  Treatment vector  Potential outcome vector  Factual outcome  Counterfactual outcome vector  Randomness vector
Back propagation Supervised loss inputs Component I/O

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 

  



Counterfactual Discriminator ()

GAN loss ( )

 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )



  



ITE Discriminator ()

GAN loss ( )

Figure 1: Block Diagram of GANITE (y¯ is sampled from G after G has been fully trained). G, DG, DI are only operating during training, whereas I operates both during training and at runtime.

3.2 A DETAILED BREAKDOWN

Counterfactual generator (G): The counterfactual generator, G, uses the feature vector, x, the
treatment vector, t, and the factual outcome, yf , to generate a potential outcome vector, y~. We let g be a function g : X × {0, 1}k × Y × [-1, 1]k-1  Yk and zG  U ((-1, 1)k-1). We then define the random variable G(x, t, yf ) as

G(x, t, yf ) = g(x, t, yf , zG)

(3)

The goal now is to find a function, g, such that G(x, t, yf )  µY(x, t, yf ). We write y~ to denote a sample of G and y¯ to denote the vector obtained by replacing y~ with yf . Observe that the th component of a sample from µY(x, t, yf ) will be yf , since we are sampling Y conditional on Y = yf .

Counterfactual discriminator (DG): We introduce a discriminator, DG, which maps pairs (x, y¯) to vectors in [0, 1]k with the i-th component, written DG(x, y~)i, representing the probability that the i-th component of y~ is the factual outcome, equivalently the probability that  = i. This is in contrast to the standard GAN framework in which the discriminator is given a single sample from one of two distributions and it attempts to determine which distribution it came from. Here the discriminator is given a sample consisting of components from two different distributions and attempts to determine which components came from which distribution.

We train DG to maximize the probability of correctly identifying . We then train G to maximize the probability of DG incorrectly identifying  (equivalently we try to minimize the probability of a correct identification - this is the adversarial method of learning between G and DG).

Following the framework in Goodfellow et al. (2014), we note that this formulation is captured by a minimax problem given by

min
G

max
DG

E(x,t,yf

)µf

EzGU ((-1,1)k)

tT log DG(x, y~) + (1 - t)T log(1 - DG(x, y~))

(4)

where log is performed element-wise and T denotes the transpose operator.

After training the counterfactual generator, we use it to generate the dataset D~ and pass this dataset to the ITE block.

ITE generator (I): The ITE generator, I, uses only the feature vector, x, to generate a potential outcome vector, y^. Similar to our approach with G, let h be a function h : X × [-1, 1]k  Yk and zI  U ((-1, 1)k). We define the random variable I(x) as

I(x) = h(x, zI)

(5)

4

Under review as a conference paper at ICLR 2018

and similarly, the goal is to find a function, h, such that I(x)  µY(x). We write y^ to denote a sample from I(x).

ITE discriminator (DI): Again, we introduce a discriminator, DI, but this time, since we have access to a complete dataset D~ , we can use a standard conditional GAN discriminator - it takes a pair (x, y) and returns a scalar corresponding to the probability that y was from the data D~ (rather
than drawn from I). Again, we train the generator and discriminator in an adversarial fashion using
the following minimax criteria

min
I

max
DI

ExµX

EyµY (x) [log DI(x, y)] + EyI(x) [log(1 - DI(x, y))]

(6)

where again log is taken element-wise.

4 GANITE: OPTIMIZATION

In this section, we describe the empirical loss functions that are used to optimize each component of GANITE. The Pseudo-code is summarized in the Appendix.

Counterfactual block (G, DG): Based on equation 4, the empirical objective of the minimax problem for G and DG can be defined by

VCF (x(n), t(n), y¯(n)) = t(n)T log(DG(x(n), y¯(n))) + (1 - t(n))T log(1 - DG(x(n), y¯(n))).

We also introduce the following `supervised' loss in order to enforce the restriction that g should

be equal to yf .

LSG(yf (n), y~(n)(n)) = (yf (n) - y~(n)(n))2

With the above two objective functions, G and DG are iteratively optimized with kG minibatches

as follows:

kG
min - VCF (x(n), t(n), ¯y(n))
DG n=1

kG

min
G

VCF (x(n), t(n), ¯y(n)) + LSG(yf (n), y~(n)(n))

n=1

where   0 is a hyper-parameter.

ITE block (I, DI): After training the counterfactual block (G, DG), GANITE optimizes the ITE block (I, DI). Based on equation 6, the empirical objective of the minimax problem for I and DI can be defined by

VIT E(x(n), y¯(n), ^y(n)) = log(DI(x(n), y¯(n))) + log(1 - DI(x(n), y^(n))).

Furthermore, in order to optimize the performance with respect to equations 1 and 2, we additionally introduce supervised losses (for the respective cases of k = 2 (binary treatments) and k > 2 (multiple treatments)) that are defined as follows:

(k = 2) : LIS(y¯(n), y^(n)) = ((y¯1(n) - y¯0(n)) - (y^1(n) - y^0(n)))2 (k > 2) : LIS(y¯(n), y^(n)) = ||y¯(n) - y^(n)||22.

I and DI are then iteratively optimized with kI minibatches as follows:

kI
min - VIT E(x(n), y¯(n), y^(n))
DI n=1

kG

min
I

VIT E(x(n), y¯(n), y^(n)) + LIS(y¯(n), y^(n))

n=1

where   0 is a hyper-parameter.

Justification for the inclusion of all the above losses can be found in Section 5.3 where we empirically explore the effect of training with and without each of the losses. We demonstrate there that using a combination of both (for both G and I) gives the best performance.

5

Under review as a conference paper at ICLR 2018

5 EXPERIMENTS

5.1 DATASETS
Due to the nature of the problem, it is very difficult to evaluate the performance of the algorithm on real-world datasets - we never have access to the ground truth. Previous works, such as Shalit et al. (2016); Louizos et al. (2017), use both semi-synthetic datasets (either the treatments or the potential outcomes are synthesized) and datasets collected from randomized controlled trials (RCT) to evaluate the ITE generator. We use two semi-synthetic datasets, IHDP and Twins, and one realworld dataset, Jobs, to evaluate the performance of GANITE with various state-of-the-art methods. These datasets are the same as the ones used in Shalit et al. (2016); Louizos et al. (2017). Below, we give a detailed explanation of Twins. The details of IHDP and Jobs are well described in Shalit et al. (2016); Hill (2011); Dehejia & Wahba (2002a) and the Appendix.
Twins: This dataset is derived from all births in the USA between 1989-1991 (Almond et al. (2005)). Among these births, we only focus on the twins. We define the treatment t = 1 as being the heavier twin (and t = 0 as being the lighter twin). The outcome is defined as the 1-year mortality. For each twin-pair we obtained 30 features relating to the parents, the pregnancy and the birth: marital status; race; residence; number of previous births; pregnancy risk factors; quality of care during pregnancy; and number of gestation weeks prior to birth. We only chose twins weighing less than 2kg and without missing features (list-wise deletion). This creates a complete dataset (without missing data). The final cohort is 11,400 pairs of twins whose mortality rate for the lighter twin is 17.7%, and for the heavier 16.1%. In this setting, for each twin pair we observed both the case t = 0 (lighter twin) and t = 1 (heavier twin); thus, the ground truth of individualized treatment effect is known in this dataset. In order to simulate an observational study, we selectively observe one of the two twins using the feature information (creating selection bias) as follows: t|x  Bern(Sigmoid(wT x + n)) where wT  U ((-0.1, 0.1)30×1) and n  N (0, 0.1).

5.2 PERFORMANCE METRICS AND SETTINGS

We use four different performance metrics: expected Precision in Estimation of Heterogeneous Effect (PEHE), average treatment effect (ATE) (Hill (2011)), policy risk (Rpol()), and average treatment effect on the treated (ATT) (Shalit et al. (2016)). In this subsection, we only provide definitions for PEHE and Rpol(). ATE and ATT are explained (and reported) in the Appendix.

If both factual and counterfactual outcomes are generated from a known distribution (so that we are able to compute the expectations of the outcomes, like in the IHDP dataset), and the treatment is binary, the empirical PEHE ( P EHE) can be defined as follows:

1N

2

PEHE = N

E(y1(n),y0(n))µY(x(n))[y1(n) - y0(n)] - [y^1(n) - y^0(n)]

n=1

where y1(n), y0(n) are treated and controlled outcomes drawn from the ground truth (µY(x)) and y^1(n), y^0(n) are their estimations.

If both factual and counterfactual outcomes are observed but the underlying distribution is unknown (like in the Twins dataset), ^P EHE can be defined as follows:

1N ^P EHE = N

2
[y1(n) - y0(n)] - [y^1(n) - y^0(n)]

n=1

If only factual outcomes are available but the testing set comes from a randomized controlled trial (RCT), such as in the Jobs dataset, Policy risk (Rpol()) can be defined as follows (Shalit et al. (2016)):

1N Rpol() = N

1-

n=1

k i=1

|i



1 Ti



E|

x(n)i Ti E

yi(n)

×

|i  E| |E|

where i = {x(n) : i = arg max y^}, Ti = {x(n) : ti(n) = 1}, and E is the subset of RCT.

6

Under review as a conference paper at ICLR 2018

0PEHE

1.2 GANITE
BART 1 CFR
WASS
CMGP 0.8

0.6

0.4

0.2 0

100 200 300 400 500 600

Figure 2: Performance comparison between GANITE and state-of-the-art methods as the selection bias is varied (Kullback-Leibler divergence between treated and controlled distributions)

Each dataset is divided 56/24/20% into training/validation/testing sets. Hyper-parameters such as the number of hidden layers  and  are chosen using Random Search (Bergstra & Bengio (2012)). Details about the hyper-parameters are discussed in the Appendix. We run each algorithm 100 times with new training/validation/testing splits and report the mean and standard deviation of the performances.

5.3 EXPERIMENTAL RESULTS

In our first simulation we focus on demonstrating the effect that including each of the losses introduced in Section 4 has on the performance of the algorithm. As is demonstrated below, inclusion of all four losses gives the best results.

We generate a synthetic dataset as follows: we draw 10,000 10-dimensional feature vectors x 

N (010×1, 0.5×(+T )) where   U ((-1, 1)10×10). The treatment assignment is then generated

as t|x  potential

Bern(Sigmoid(wtT x + outcome vector is then

nt)) where wtT  U ((-0.1, 0.1)10×1) and nt generated as y|x  (wyT x + ny)) where wyT

 

N (0, 0.1). The U ((-1, 1)10×2)

and ny  N (02×1, 0.1 × I2×2). We use 8,000 instances for training and 2,000 instances for testing.

We repeat this 100 times and report the average P EHE on the testing set.

G

PEHE

S loss only

GAN loss only

S and GAN loss

S loss only .397 ± .011 (15.6%) .610 ± .017 (45.1%) .352 ± .012 (4.8%) I GAN loss only .607 ± .044 (44.8%) .513 ± .029 (34.7%) .463 ± .015 (27.6%)

S and GAN loss .362 ± .011 (7.5%) .491 ± .030 (31.8%) .335 ± .011 (-)

Table 1: Performance with various combinations of GANITE (G: Counterfactual generator, I: ITE generator, S loss: Supervised loss). Details of each cell are illustrated in the Appendix as Figures

Table 1 shows the performance of the GANITE architecture using different combinations of the four losses in Section 4. For each generator component, we can use 3 different combinations of loss: (1) Supervised loss (S loss) only (this reduces the corresponding component to a standard neural network), (2) GAN loss only, (3) both S loss and GAN loss. The top-left most entry corresponds to simply using a standard neural network to first impute the counterfactuals and then using another standard neural network to learn an ITE estimator from the imputed dataset. As can be seen, this already performs well, but by adding the GAN losses for both the imputation step and the estimation step, a significant gain is shown (15.6%) (the bottom-right entry).
In Fig. 2 we show that GANITE is robust to an increased selection bias. We generate 10,000 10-dimensional treated samples from x1  N (µ1, 0.5 × ( + T )) and controlled samples from

7

Under review as a conference paper at ICLR 2018

x0  N (µ0, 0.5 × ( + T )) where   U ((-1, 1)10×10). Fixing µ0 and varying µ1, we generate various datasets with different Kullback-Leibler divergence (KL divergence) between these two distributions. A higher KL divergence indicates a higher selection bias (a larger mismatch) between treated and controlled distributions. As seen in Fig. 2, GANITE robustly outperforms state-of-theart methods such as Shalit et al. (2016); Alaa & van der Schaar (2017) across the entire range of tested divergences.

Methods
GANITE
OLS/LR1 OLS/LR2
BLR k-NN
BART R Forest C Forest
BNN TARNET CFRW ASS
CMGP

 IHDP ( P EHE )

In-sample Out-sample

2.1 ± .3 2.5 ± .3

5.8 ± .3 2.4 ± .1 5.8 ± .3 2.1 ± .1

5.8 ± .3 2.5 ± .1 5.8 ± .3 4.1 ± .2

2.1 ± .1 4.2 ± .2 3.8 ± .2

2.3 ± .1 6.6 ± .3 3.8 ± .2

2.2 ± .1 .88 ± .02 .71 ± .02 .65 ± .44

2.1 ± .1 .95 ± .02 .76 ± .02 .77 ± .11

Datasets (Mean ± Std) 
Twins ( ^P EHE)

In-sample Out-sample

.289 ± .005 .297 ± .016

.319 ± .001 .320 ± .002 .312 ± .003 .333 ± .001

.318 ± .007 .320 ± .003 .323 ± .018 .345 ± .007

.347 ± .009 .338 ± .016 .306 ± .002 .321 ± .005 .366 ± .003 .316 ± .011

.325 ± .003 .317 ± .005 .315 ± .007 .320 ± .002

.321 ± .018 .315 ± .003 .313 ± .008 .319 ± .008

Jobs (Rpol())

In-sample Out-sample

.13 ± .01 .14 ± .01

.22 ± .00 .21 ± .00 .22 ± .01 .02 ± .00

.23 ± .02 .24 ± .01 .25 ± .02 .26 ± .02

.23 ± .00 .23 ± .01 .19 ± .00

.25 ± .02 .28 ± .02 .20 ± .02

.20 ± .01 .17 ± .01 .17 ± .01 .22 ± .03

.24 ± .02 .21 ± .01 .21 ± .01 .24 ± .05

Table 2: Performance of ITE estimation with three real-world datasets

Binary treatments: In this section, we evaluate GANITE for estimating individualized treatment effects for binary treatments. We use three datasets and report the P EHE both in-sample and outof-sample (for ATE and ATT see the appendix). We compare GANITE with least squares regression using treatment as a feature (OLS/LR1), separate least squares regressions for each treatment (OLS/LR2), balancing linear regression (BLR) (Johansson et al. (2016)), k-nearest neighbor (k-NN) (Crump et al. (2008)), Bayesian additive regression trees (BART) (Chipman et al. (2010)), random forests (RForest) (Breiman (2001)), causal forests (C Forest) (Wager & Athey (2017)), balancing neural network (BNN) (Johansson et al. (2016)), treatment-agnostic representation network (TARNET) (Shalit et al. (2016)), counterfactual regression with Wasserstein distance (CFRW ASS) (Shalit et al. (2016)), and multi-task gaussian process (CMGP) (Alaa & van der Schaar (2017)). We evaluate both in-sample and out-of-sample performance in Table 2.
As can be seen in Table 2, GANITE achieves significant performance gains on the Twins and Jobs datasets in comparison with state-of-the-art methods. GANITE achieves a much higher gain for individualized treatment effect estimations (such as ^P EHE and Rpol()) than average treatment effect estimations (such as ^AT E and AT T ). On IHDP, GANITE is competitive with BART and BNN but is outperformed by TARNET, CFRW ASS and CMGP. We believe this is due to the fact that GANITE has a large number of parameters to be optimized and IHDP is a relatively small dataset (747 samples). This belief is backed up by our significant gains over these methods in both Twins and Jobs, where the number of samples is much larger, (11400 and 3212 samples, respectively).
As seen in Table. 2, the performances of counterfactual estimation (in-sample) and treatment effect estimation (out-of-sample) are both competitive with state-of-the-art methods - using GANITE, we can accurately estimate both the counterfactuals (with G) and individual treatment effects (with I).
Multiple treatments: GANITE is naturally defined for estimating multiple treatment effects. In this subsection, we further preprocess the Twins data to create a dataset containing multiple treatments. The multiple treatments are determined as follows: (1) t = 1: lower weight, female sex, (2) t = 2: lower weight, male sex, (3) t = 3: higher weight, female sex, (4) t = 4: higher weight, male sex. Therefore, we have 4 possible treatments for each sample.
8

Under review as a conference paper at ICLR 2018

Methods
GANITE
OLS/LR1 OLS/LR2
BLR KNN
BART R Forest C Forest
BNN TARNET CFRW ASS
CMGP

In Sample
.0427 ± .0161
.0855 ± .0096 .0857 ± .0099 .0996 ± .0081 .0930 ± .0101
.1097 ± .0084 .0442 ± .0069 .1607 ± .0014
.0602 ± .0102 .0854 ± .0091 .0896 ± .0036 .0844 ± .0073

Metric: MSEy

Gain (%) Out Sample

(-) .0723 ± .0183

50.1% 50.2% 57.1% 54.1%

.0871 ± .0142 .0883 ± .0147 .1017 ± .0127 .1008 ± .0236

61.1% 3.4% 73.4%

.1037 ± .0283 .0927 ± .0138 .1665 ± .0035

29.1% 50.0% 52.3% 49.4%

.1031 ± .0145 .0879 ± .0030 .0894 ± .0057 .0793 ± .0191

Gain (%)
(-)
17.0% 18.1% 28.9% 28.3%
30.3% 22.0% 56.6%
29.9% 17.7% 19.1% 8.3%

Table 3: Performance of multiple treatment effects estimations using Twins data

We use the mean-squared error:

1N

2

MSEy = N × |Ti| i=1 tTi yt(xi) - y^t(xi)

as the performance metric to evaluate the multiple treatment effects (other metrics, such as PEHE, do not have a natural extension to the multiple treatments setting). For comparison with state-of-the-art methods, we naively extend BLR, C Forest, BNN, TARNET, CFRW ASS, and CMGP for multiple treatments: one of the four treatments is selected as a control treatment and then the remaining three create three separate binary ITE estimation problems (all against the same chosen control treatment).

As can be seen in Table 3 compared with Table 2 GANITE significantly outperforms other state-ofthe-art methods such as TARNET and CFRW ASS (17.7% and 19.1% gains in terms of out sample MSE, respectively). This is because, GANITE is designed for multiple treatments; the model is jointly trained for all treatments. On the other hand, other methods are designed for binary treatments and only naively extend to multiple treatments by training pairs of the available treatments.

6 DISCUSSION
In this paper we introduced a novel method for dealing with the ITE estimation problem. We have shown empirically that our method is more robust to large selection biases and performs better on standard benchmark datasets than other state-of-the-art methods. Our method also achieves significant performance gains over state-of-the-art when estimating ITE for multiple treatments because it is able to jointly estimate the representations across the multiple treatments.

9

Under review as a conference paper at ICLR 2018
REFERENCES
Ahmed M Alaa and Mihaela van der Schaar. Bayesian inference of individualized treatment effects using multi-task gaussian processes. NIPS, 2017.
Ahmed M Alaa, Michael Weisz, and Mihaela van der Schaar. Deep counterfactual networks with propensity-dropout. ICML Workshop on Principled Approaches to Deep Learning, 2017.
Douglas Almond, Kenneth Y Chay, and David S Lee. The costs of low birth weight. The Quarterly Journal of Economics, 120(3):1031­1083, 2005.
Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. Proceedings of the National Academy of Sciences, 113(27):7353­7360, 2016.
James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb):281­305, 2012.
Leo Breiman. Random forests. Machine learning, 45(1):5­32, 2001.
Hugh A Chipman, Edward I George, Robert E McCulloch, et al. Bart: Bayesian additive regression trees. The Annals of Applied Statistics, 4(1):266­298, 2010.
Richard K Crump, V Joseph Hotz, Guido W Imbens, and Oscar A Mitnik. Nonparametric tests for treatment effect heterogeneity. The Review of Economics and Statistics, 90(3):389­405, 2008.
Rajeev H Dehejia and Sadek Wahba. Propensity score-matching methods for nonexperimental causal studies. The review of economics and statistics, 84(1):151­161, 2002a.
Rajeev H Dehejia and Sadek Wahba. Propensity score-matching methods for nonexperimental causal studies. The review of economics and statistics, 84(1):151­161, 2002b.
Vincent Dorie. Npci: Non-parametrics for causal inference, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural information processing systems, pp. 2672­2680, 2014.
A Hannart, J Pearl, FEL Otto, P Naveau, and M Ghil. Causal counterfactual theory for the attribution of weather and climate-related events. Bulletin of the American Meteorological Society, 97(1): 99­110, 2016.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics, 20(1):217­240, 2011.
M Ho¨fler. Causal inference based on counterfactuals. BMC medical research methodology, 5(1):28, 2005.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual inference. In International Conference on Machine Learning, pp. 3020­3029, 2016.
James K Kirklin, David C Naftel, Robert L Kormos, Lynne W Stevenson, Francis D Pagani, Marissa A Miller, Karen L Ulisney, J Timothy Baldwin, and James B Young. Second intermacs annual report: more than 1000 primary lvad implants. The Journal of heart and lung transplantation: the official publication of the International Society for Heart Transplantation, 29(1):1, 2010.
Robert J LaLonde. Evaluating the econometric evaluations of training programs with experimental data. The American economic review, pp. 604­620, 1986.
Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, and Max Welling. Causal effect inference with deep latent-variable models. arXiv preprint arXiv:1705.08821, 2017.
Min Lu, Saad Sadiq, Daniel J Feaster, and Hemant Ishwaran. Estimating individual treatment effect in observational data using random forest methods. arXiv preprint arXiv:1701.05306, 2017.
10

Under review as a conference paper at ICLR 2018
Jared K Lunceford and Marie Davidian. Stratification and weighting via the propensity score in estimation of causal treatment effects: a comparative study. Statistics in medicine, 23(19):2937­ 2960, 2004.
Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784, 2014.
Kristin E Porter, Susan Gruber, Mark J Van Der Laan, and Jasjeet S Sekhon. The relative performance of targeted maximum likelihood estimators. The International Journal of Biostatistics, 7 (1):1­34, 2011.
Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal of the American Statistical Association, 100(469):322­331, 2005.
Uri Shalit, Fredrik Johansson, and David Sontag. Estimating individual treatment effect: generalization bounds and algorithms. arXiv preprint arXiv:1606.03976, 2016.
Jeffrey A Smith and Petra E Todd. Does matching overcome lalonde's critique of nonexperimental estimators? Journal of econometrics, 125(1):305­353, 2005.
Peter Spirtes. A tutorial on causal inference. 2009. Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using
random forests. Journal of the American Statistical Association, (just-accepted), 2017.
11

Under review as a conference paper at ICLR 2018

APPENDIX
PSEUDO-CODE OF GANITE

Algorithm 1 Pseudo-code of GANITE
while convergence of training loss of G and DG do (1) Counterfactual block optimization Use kC minibatches, iteratively optimize G, DG by stochastic gradient descent (SGD)

kG
min - VCF (x(n), t(n), y~(n))
DG n=1

kG

min
G

VCF (x(n), t(n), y~(n)) + LSG(yf (n), y~(n)(n))

n=1

while convergence of training loss of I and DI do (2) ITE block optimization
Use kI minibatches, update I, DI by SGD

kI
min - VIT E(x(n), y~(n), y^(n))
DI n=1

kG

min
I

VIT E(x(n), y~(n), ^y(n)) + LSI (y~(n), y^(n))

n=1

DETAILED DESCRIPTION OF THE DATASETS
IHDP
Hill (2011) provided a dataset for ITE estimation with the Infant Health and Development Program (IHDP). The dataset consists of 747 children (t = 1: 139, t = 0 608) with 25 features. We generated potential outcomes from setting A in the NPCI package Dorie (2016).
JOBS
Jobs data studied in LaLonde (1986) is composed of randomized data based on the National Supported Work program and non-randomized data from observational studies. We use a (random) subset of the randomized data to evaluate the algorithms based on Rpol() and AT T . The dataset consists of 722 randomized samples (t = 1: 297, t = 0: 425) and 2490 non-randomized samples (t = 1: 0, t = 0: 2490), all with 7 features.

SUMMARY OF THE DATASETS

Data

Condition F CF Distribution RT-test

T

Property Ns

IHDP

Known

Binary 747 25

Jobs X Unknown

Binary 3212 7

Twins-Binary

Unknown

Binary 11400 30

Twins-Multiple

X Unknown

Multiple 11400 30

Table 4: Summary of the datasets (N is the number of samples, s is the feature-dimension)

12

Under review as a conference paper at ICLR 2018

Methods
GANITE
OLS/LR1 OLS/LR2
BLR k-NN
BART R Forest C Forest
BNN TARNET CFRW ASS
CMGP

IHDP ( AT E)

In-sample Out-sample

.45 ± .03 .53 ± .05

.73 ± .04 .14 ± .01 .72 ± .04 .14 ± .01

.94 ± .06 .31 ± .02 .93 ± .05 .90 ± .05

.23 ± .01 .73 ± .05 .18 ± .01

.34 ± .02 .96 ± .06 .40 ± .03

.37 ± .03 .26 ± .01 .25 ± .01 .11 ± .10

.42 ± .03 .28 ± .01 .27 ± .01 .13 ± .12

Datasets (Mean ± Std)

Twins (^AT E)

In-sample

Out-sample

.0058 ± .0017 .0089± 0.0075

.0038 ± .0025 .0039 ± .0025 .0057 ± .0036 .0028 ± .0021

.0069 ± .0056 .0070 ± .0059 .0334 ± .0092 .0051 ± .0039

.1206 ± .0236 .1265 ± .0234 .0049 ± .0034 .0080 ± .0051 .0286 ± .0035 .0335 ± .0083

.0056 ± .0032 .0108 ± .0017 .0112 ± .0016 .0124 ± .0051

.0203 ± .0071 .0151 ± .0018 .0284 ± .0032 .0143 ± .0116

Jobs ( AT T )

In-sample Out-sample

.01 ± .01 .06 ± .03

.01 ± .00 .01 ± .01 .01 ± .01 .21 ± .01

.08 ± .04 .08 ± .03 .08 ± .03 .13 ± .05

.02 ± .00 .03 ± .01 .03 ± .01

.08 ± .03 .09 ± .04 .07 ± .03

.04 ± .01 .05 ± .02 .04 ± .01 .06 ± .06

.09 ± .04 .11 ± .04 .09 ± .03 .09 ± .07

Table 5: Performance of average treatment effect estimation

PERFORMANCE METRICS AND THE RESULTS OF AVERAGE TREATMENT EFFECT ESTIMATION

In this subsection, we use two different performance metrics for average treatment effect (ATE) estimation: average treatment effect (ATE) (Hill (2011)), and average treatment effect on the treated (ATT) (Shalit et al. (2016)).

If both factual and counterfactual outcomes are generated from a known distribution (and so we are able to compute the expected value, such as in IHDP), the error of ATE ( AT E) is defined as:

AT E

=

|| 1 N

N

Ey(n)µY (x(n)) [y(n)]

-

1 N

n
y^(n)||22

n=1

i=1

where y^ is the estimated potential outcome.

If both factual and counterfactual outcomes are observed but the underlying distribution is unknown (like in Twins), A^T E is defined as:

^AT E

=

|| 1 N

N

y(n) - 1 N

N

y^(n)||22

n=1

n=1

If only factual outcomes are available (such as in Jobs), treatment is binary, and the testing set comes from a randomized controlled trial (RCT), the true average treatment effect on the treated (ATT) is defined as follows (Shalit et al. (2016)):

11

AT T

=

|T1

 E|

Y1(xi) -
xi T1 E

|T0  E|

Y0(xi)
xi C E

AT T

= |AT T

-

1 |T1  E|

Y^1(xi) - Y^0(xi)|
xi T1 E

where T1 is the subset corresponding to treated samples, T0 is the subset corresponding to controlled samples, and E is the subset corresponding to the randomized controlled trials.

Table. 5 shows the performance of the various algorithms with respect to these metrics.

13

Under review as a conference paper at ICLR 2018

HYPER-PARAMETER OPTIMIZATION

Blocks

Table 6: Hyper-parameters of GANITE Sets of Hyper-parameters

Initialization

Xavier Initialization for Weight matrix, Zero initialization for bias vector.

Optimization

Adam Moment Optimization

Batch size (kG, kI ) Depth of layers

{32, 64, 128, 256} {1, 3, 5, 7, 9}

Hidden state dimension {s, int(s/2), int(s/3), int(s/4), int(s/5)}

,  {0, 0.1, 0.5, 1, 2, 5, 10}

TOY EXAMPLE

Potential outcomes (Y)

0.35 0.3
0.25 0.2
0.15 0.1
0.05 0
0.4

Underlying potential outcome distributions

E(Y )
0
E(Y )
1

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
(a) Feature space (X)
Underlying P(T|X) with selection bias

1

0.3

0.2

0.1 T=0
T=1
0 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
(b) Feature space (X)

Generated outcomes by I

Facture outcomes (Yf)

0.3 0.25
0.2 0.15
0.1 0
0.3 0.25
0.2 0.15
0.1 0

P(T|X)

Given samples with factual outcomes
T=0 T=1

0.2 0.4 0.6
(c) Feature space (X)

0.8

Generated potential outcomes by I

T=0 T=1
0.2 0.4 0.6
(d) Feature space (X)

0.8

1 1

Figure 3: (a) Underlying distribution of potential outcomes (Y), (b) Underlying distribution of treatment assignments P(T |X), (c) Training data (factual outcomes) sampled from distributions explained in (a) and (b), (d) Potential outcomes sampled from trained ITE generator (I).

14

Under review as a conference paper at ICLR 2018

ADDITIONAL FIGURES FOR TABLE 1
Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 

 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )



 
(a) G: S loss only, I: S loss only

Counterfactual block     Counterfactual Generator ()
 
  

 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )







Counterfactual Discriminator ()

GAN loss ( )

(b) G: GAN loss only, I: S loss only

15

Under review as a conference paper at ICLR 2018

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 

  

 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )







Counterfactual Discriminator ()

GAN loss ( )

(c) G: S and GAN loss, I: S loss only

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 



 = ,  ,  = , 

ITE block  
ITE Generator ()

  



ITE Discriminator ()

GAN loss ( )
(d) G: S loss only, I: GAN loss only

16

Under review as a conference paper at ICLR 2018

Counterfactual block     Counterfactual Generator ()
 
  

 = ,  ,  = , 

ITE block  
ITE Generator ()

  



Counterfactual Discriminator ()



ITE Discriminator ()

GAN loss ( )

GAN loss ( )

(e) G: GAN loss only, I: GAN loss only

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 

  

 = ,  ,  = , 

ITE block  
ITE Generator ()

  



Counterfactual Discriminator ()



ITE Discriminator ()

GAN loss ( )

GAN loss ( )

(f) G: S and GAN loss, I: GAN loss only

17

Under review as a conference paper at ICLR 2018

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 



 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )



  



ITE Discriminator ()

GAN loss ( )
(g) G: S loss only, I: S and GAN loss

Counterfactual block     Counterfactual Generator ()
 
  

 = ,  ,  = , 

ITE block

 
ITE Generator ()

Supervised loss ( )



  



Counterfactual Discriminator ()



ITE Discriminator ()

GAN loss ( )

GAN loss ( )

(h) G: GAN loss only, I: S and GAN loss

18

Under review as a conference paper at ICLR 2018

Counterfactual block
   
Counterfactual Generator ()

Supervised loss ( )

 

  

 = ,  ,  = , 

ITE block

 

ITE Generator ()

Supervised loss ( )



  



Counterfactual Discriminator ()



ITE Discriminator ()

GAN loss ( )

GAN loss ( )

(i) G: S and GAN loss, I: S and GAN loss

19

