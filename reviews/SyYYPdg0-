{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222618668,"tcdate":1511830381181,"number":3,"cdate":1511830381181,"id":"HJSdXVqxG","invitation":"ICLR.cc/2018/Conference/-/Paper311/Official_Review","forum":"SyYYPdg0-","replyto":"SyYYPdg0-","signatures":["ICLR.cc/2018/Conference/Paper311/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Unclear why it works the way it is advertised","rating":"4: Ok but not good enough - rejection","review":"This paper creates a layered representation in order to better learn segmentation from unlabeled images. It is well motivated, as Fig. 1 clearly shows the idea that if the segmentation was removed properly, the result would still be a natural image. However, the method itself as described in the paper leaves many questions about whether they can achieve the proposed goal.\n\nI cannot see from the formulation why would this model work as it is advertised. The formulation (3-4) looks like a standard GAN, with some twist about measuring the GAN loss in the z space (this has been used in e.g. PPGN and CVAE-GAN). I don't see any term that would guarantee:\n\n1) Each layer is a natural image. This was advertised in the paper, but the loss function is only on the final product G_K. The way it is written in the paper, the result of each layer does not need to go through a discriminator. Nothing seems to have been done to ensure that each layer outputs a natural image.\n\n2) None of the layers is degenerate. There does not seem to be any constraint either regularizing the content in each layer, or preventing any layer to be non-degenerate.\n\n3) The mask being contiguous. I don't see any term ensuring the mask being contiguous, I imagine normally without such terms doing such kinds of optimization would lead to a lot of fragmented small areas being considered as the mask.\n\nThe claim that this paper is for unsupervised semantic segmentation is overblown. A major problem is that when conducting experiments, all the images seem to be taken from a single category, this implicitly uses the label information of the category. In that regard, this cannot be viewed as an unsupervised algorithm.\n\nEven with that, the results definitely looked too good to be true. I have a really difficult time believing why such a standard GAN optimization would not generate any of the aforementioned artifacts and would perform exactly as the authors advertised. Even if it does work as advertised, the utilization of implicit labels would make it subject to comparisons with a lot of weakly-supervised learning papers with far better results than shown in this paper. Hence I am pretty sure that this is not up to the standards of ICLR.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Counterfactual Image Networks","abstract":"We capitalize on the natural compositional structure of images in order to learn object segmentation with unlabeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation better than baselines.","pdf":"/pdf/8ee6d90fcd5bbf526c71d8d4354e409102ade334.pdf","TL;DR":"Unsupervised image segmentation using compositional structure of images and generative models.","paperhash":"anonymous|counterfactual_image_networks","_bibtex":"@article{\n  anonymous2018counterfactual,\n  title={Counterfactual Image Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyYYPdg0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper311/Authors"],"keywords":["computer vision","image segmentation","generative models","adversarial networks","unsupervised learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222618706,"tcdate":1511814209396,"number":2,"cdate":1511814209396,"id":"rkFHVe5lf","invitation":"ICLR.cc/2018/Conference/-/Paper311/Official_Review","forum":"SyYYPdg0-","replyto":"SyYYPdg0-","signatures":["ICLR.cc/2018/Conference/Paper311/AnonReviewer2"],"readers":["everyone"],"content":{"title":"review: experiments insufficient","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a neural network architecture around the idea of layered scene composition.  Training is cast in the generative adversarial framework; a subnetwork is reused to generate and compose (via an output mask) multiple image layers; the resulting image is fed to a discriminator.  An encoder is later trained to map real images into the space of latent codes for the generator, allowing the system to be applied to real image segmentation tasks.\n\nThe idea is interesting and different from established approaches to segmentation.  Visualization of learned layers for several scene types (Figures 3, 7) shows that the network does learn a reasonable compositional scene model.\n\nExperiments evaluate the ability to port the model learned in an unsupervised manner to semantic segmentation tasks, using a limited amount of supervision for the end task.  However, the included experiments are not nearly sufficient to establish the effectiveness of the proposed method.  Only two scene types (bedroom, kitchen) and four object classes (bed, window, appliance, counter) are used for evaluation.  This is far below the norm for semantic segmentation work in computer vision.  How does the method work on established semantic segmentation datasets with many classes, such as PASCAL?  Even the ADE20K dataset, from which this paper samples, is substantially larger and has an established benchmarking methodology (see http://placeschallenge.csail.mit.edu/).\n\nAn additional problem is that performance is not compared to any external prior work.  Only simple baselines (eg autoencoder, kmeans) implemented by this paper are included.  The range of prior work on semantic segmentation is extensive.  How well does the approach compare to supervised CNNs on an established segmentation task?  Note that the proposed method need not necessarily outperform supervised approaches, but the reader should be provided with some idea of the size of the gap between this unsupervised method and the state-of-the-art supervised approach.\n\nIn summary, the proposed method may be promising, but far more experiments are needed.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Counterfactual Image Networks","abstract":"We capitalize on the natural compositional structure of images in order to learn object segmentation with unlabeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation better than baselines.","pdf":"/pdf/8ee6d90fcd5bbf526c71d8d4354e409102ade334.pdf","TL;DR":"Unsupervised image segmentation using compositional structure of images and generative models.","paperhash":"anonymous|counterfactual_image_networks","_bibtex":"@article{\n  anonymous2018counterfactual,\n  title={Counterfactual Image Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyYYPdg0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper311/Authors"],"keywords":["computer vision","image segmentation","generative models","adversarial networks","unsupervised learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222618743,"tcdate":1511486274379,"number":1,"cdate":1511486274379,"id":"SyqB7xHlz","invitation":"ICLR.cc/2018/Conference/-/Paper311/Official_Review","forum":"SyYYPdg0-","replyto":"SyYYPdg0-","signatures":["ICLR.cc/2018/Conference/Paper311/AnonReviewer3"],"readers":["everyone"],"content":{"title":"interesting idea and results, more experiments are needed","rating":"7: Good paper, accept","review":"Paper summary: The paper proposes a generative model that decomposes images into multiple layers. The proposed approach is GAN-based, where the objective of the GAN is to distinguish real images from images formed by combining the layers. Some of the layers correspond to objects that are common in specific scene categories. The method has been tested on kitchen and bedroom scenes.\n\nPaper Strengths:\n+ The idea of the paper is interesting.\n+ The learned masks for objects are neat.\n+ The proposed method outperforms a number of simple baselines.\n\nPaper Weaknesses:\n\n- The evaluation of the model is not great: (1) It would be interesting to combine bedroom and kitchen images and train jointly to see what it learns. (2) It would be good to see how the performance changes for different number of layers. (3) Regarding the fine-tuning baselines, the comparison is a bit unfair since the proposed method performs pooling over images, while the baseline (average mask) is not translation invariant.\n\n- It is unclear why \"contiguous\" masks are generated (e.g., in figure 4). Is there any constraint in the optimization? This should be explained in the rebuttal. \n\n- The method should not be called \"unsupervised\" since it knows the label for the scene category. Also, it should not be called \"semantic segmentation\" since there is no semantics associated to the object. It is just a binary foreground/background mask.\n\n- The plots in Figure 5 are a bit strange. The precision increases uniformly as the recall goes up, which is weird. It should be explained in the rebuttal why that happens.\n\n- Similar to most GAN-based models, the generated images are not that appealing.\n\n- The claim about object removal should be toned down. The method is not able to remove any object from a scene. Only, the learned layers can be removed.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Counterfactual Image Networks","abstract":"We capitalize on the natural compositional structure of images in order to learn object segmentation with unlabeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation better than baselines.","pdf":"/pdf/8ee6d90fcd5bbf526c71d8d4354e409102ade334.pdf","TL;DR":"Unsupervised image segmentation using compositional structure of images and generative models.","paperhash":"anonymous|counterfactual_image_networks","_bibtex":"@article{\n  anonymous2018counterfactual,\n  title={Counterfactual Image Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyYYPdg0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper311/Authors"],"keywords":["computer vision","image segmentation","generative models","adversarial networks","unsupervised learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739371483,"tcdate":1509095297117,"number":311,"cdate":1509739368822,"id":"SyYYPdg0-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SyYYPdg0-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Counterfactual Image Networks","abstract":"We capitalize on the natural compositional structure of images in order to learn object segmentation with unlabeled images. The intuition behind our approach is that removing objects from images will yield natural images, however removing random patches will yield unnatural images. We leverage this signal to develop a generative model that decomposes an image into layers, and when all layers are combined, it reconstructs the input image. However, when a layer is removed, the model learns to produce a different image that still looks natural to an adversary, which is possible by removing objects. Experiments and visualizations suggest that this model automatically learns object segmentation better than baselines.","pdf":"/pdf/8ee6d90fcd5bbf526c71d8d4354e409102ade334.pdf","TL;DR":"Unsupervised image segmentation using compositional structure of images and generative models.","paperhash":"anonymous|counterfactual_image_networks","_bibtex":"@article{\n  anonymous2018counterfactual,\n  title={Counterfactual Image Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SyYYPdg0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper311/Authors"],"keywords":["computer vision","image segmentation","generative models","adversarial networks","unsupervised learning"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}