{"notes":[{"tddate":null,"ddate":null,"tmdate":1512238910894,"tcdate":1512238910894,"number":1,"cdate":1512238910894,"id":"SJDry_x-G","invitation":"ICLR.cc/2018/Conference/-/Paper155/Public_Comment","forum":"H1Yp-j1Cb","replyto":"H1Yp-j1Cb","signatures":["~Naveen_Kodali1"],"readers":["everyone"],"writers":["~Naveen_Kodali1"],"content":{"title":"Similarities to DRAGAN paper ","comment":"Our paper listed below (published May 2017) also argues for viewing GAN training process through the lens of online learning and has quite a few similarities to this work. It would be helpful to cite and compare your work to ours.\n\nhttps://arxiv.org/abs/1705.07215"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"An Online Learning Approach to Generative Adversarial Networks","abstract":"We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN. On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one-layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures.\nOn several real-world tasks our approach exhibits improved stability and performance compared to standard GAN training.","pdf":"/pdf/59fe8ddc9c5fc8d589729f085ce868559cf4f1b4.pdf","paperhash":"anonymous|an_online_learning_approach_to_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Online Learning Approach to Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Yp-j1Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper155/Authors"],"keywords":["Generative Adversarial Networks","GANs","online learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222577883,"tcdate":1512100037182,"number":2,"cdate":1512100037182,"id":"HJ66g8RgM","invitation":"ICLR.cc/2018/Conference/-/Paper155/Official_Review","forum":"H1Yp-j1Cb","replyto":"H1Yp-j1Cb","signatures":["ICLR.cc/2018/Conference/Paper155/AnonReviewer2"],"readers":["everyone"],"content":{"title":"borderline paper","rating":"5: Marginally below acceptance threshold","review":"It is well known that the original GAN (Goodfellow et al.) suffers from instability and mode collapsing. Indeed, existing work has pointed out that the standard GAN training process may not converge if we insist on obtaining pure strategies (for the minmax game). The present paper proposes to obtain mixed strategy through an online learning approach. Online learning (no regret) algorithms have been used in finding an equilibrium for zero sum game. However, most theoretical convergence results are known for convex-concave loss. One interesting theoretical contribution of the paper is to show that convergence result can be proved if one player is a shallow network (and concave in M).In particular, the concave player plays the FTRL algorithm with standard L2 regularization term. The regret of concave player can be bounded using existing result for FTRL. The regret for the other player is more interesting: it uses the fact the adversary's strategy doesn't change too drastically. Then a lemma by Kalai and Vempala can be used. The theory part of the paper is reasonable and quite well written. \n\nBased on the theory developed, the paper presents a practical algorithm. Compared to the standard GAN training, the new algorithm returns mixed strategy and examine several previous models (instead of the latest) in each iteration. The paper claims that this may help to prevent model collapsing.\n\nHowever, the experimental part is less satisfying. From figure 2, I don't see much advantage of Checkhov GAN. In other experiments, I don't see much improvement neither (CIFAR10 and CELEBA).The paper didn't really compare other popular GAN models, especially WGAN and its improved version, which is already quite popular by now and should be compared with.\n\nOverall, I think it is a borderline paper.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"An Online Learning Approach to Generative Adversarial Networks","abstract":"We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN. On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one-layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures.\nOn several real-world tasks our approach exhibits improved stability and performance compared to standard GAN training.","pdf":"/pdf/59fe8ddc9c5fc8d589729f085ce868559cf4f1b4.pdf","paperhash":"anonymous|an_online_learning_approach_to_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Online Learning Approach to Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Yp-j1Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper155/Authors"],"keywords":["Generative Adversarial Networks","GANs","online learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222577924,"tcdate":1511845226958,"number":1,"cdate":1511845226958,"id":"HkQupw5gf","invitation":"ICLR.cc/2018/Conference/-/Paper155/Official_Review","forum":"H1Yp-j1Cb","replyto":"H1Yp-j1Cb","signatures":["ICLR.cc/2018/Conference/Paper155/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Powerful theory tools applied naturally to GAN dynamics","rating":"8: Top 50% of accepted papers, clear accept","review":"This is an interesting paper, exploring GAN dynamics using ideas from online learning, in particular the pioneering \"sparring\" follow-the-regularized leader analysis of Freund and Schapire (using what is listed here as Lemma 4). By restricting the discriminator to be a single layer, the maximum player plays over a concave (parameter) space which stabilizes the full sequence of losses so that Lemma 3 can be proved, allowing proof of the dynamics' convergence to a Nash equilibrium. The analysis suggests a practical (heuristic) algorithm incorporating two features which emerge from the theory: L2 regularization and keeping a history of past models. A very simple queue for the latter is shown to do quite competitively in practice.\n\nThis paper merits acceptance on theoretical merits alone, because the FTRL analysis for convex-concave games is a very robust tool from theory (see also the more recent sequel [Syrgkanis et al. 2016 \"Fast convergence of regularized learning in games\"]) that is natural to employ to gain insight on the much more brittle GAN case. The practical aspects are also interesting, because the incorporation of added randomness into the mixed generation strategy is an area where theoretical justifications do motivate practical performance gains; these ideas could clearly be developed in future work.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"An Online Learning Approach to Generative Adversarial Networks","abstract":"We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN. On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one-layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures.\nOn several real-world tasks our approach exhibits improved stability and performance compared to standard GAN training.","pdf":"/pdf/59fe8ddc9c5fc8d589729f085ce868559cf4f1b4.pdf","paperhash":"anonymous|an_online_learning_approach_to_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Online Learning Approach to Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Yp-j1Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper155/Authors"],"keywords":["Generative Adversarial Networks","GANs","online learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739454821,"tcdate":1509040576932,"number":155,"cdate":1509739452169,"id":"H1Yp-j1Cb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1Yp-j1Cb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"An Online Learning Approach to Generative Adversarial Networks","abstract":"We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN. On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one-layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures.\nOn several real-world tasks our approach exhibits improved stability and performance compared to standard GAN training.","pdf":"/pdf/59fe8ddc9c5fc8d589729f085ce868559cf4f1b4.pdf","paperhash":"anonymous|an_online_learning_approach_to_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018an,\n  title={An Online Learning Approach to Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1Yp-j1Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper155/Authors"],"keywords":["Generative Adversarial Networks","GANs","online learning"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}