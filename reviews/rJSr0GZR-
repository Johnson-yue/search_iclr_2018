{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222544407,"tcdate":1511849283178,"number":3,"cdate":1511849283178,"id":"ByjrTO5ef","invitation":"ICLR.cc/2018/Conference/-/Paper1047/Official_Review","forum":"rJSr0GZR-","replyto":"rJSr0GZR-","signatures":["ICLR.cc/2018/Conference/Paper1047/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A simple idea to improve adversarial autoencoders by learning priors","rating":"6: Marginally above acceptance threshold","review":"Recently some interesting work on a role of prior in deep generative models has been presented. The choice of prior may have an impact on the expressiveness of the model [Hoffman and Johnson, 2016]. A few existing work presents methods for learning priors from data for variational autoencoders [Goyal et al., 2017][Tomczak and Welling, 2017].  The work, \"VAE with a VampPrior,\" [Tomczak and Welling, 2017] is missing in references.\n\nThe current work focuses on adversarial autoencoder (AAE) and introduces a code generator network to transform a simple prior into one that together with the generator can better fit the data distribution. Adversarial loss is used to train the code generator network, allowing the output of the network could be any distribution. I think the method is quite simple but interesting approach to improve AAEs without hurting the reconstruction. The paper is well written and is easy to read. The method is well described. However, what is missing in this paper is an analysis of learned priors, which help us to better understand its behavior. \n\nThe model is evaluated qualitatively only. What about quantitative evaluation? \n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Priors for Adversarial Autoencoders","abstract":"Most deep latent factors choose simple priors for simplicity, tractability or not\nknowing what prior to use. Recent studies show that the choice of the prior may\nhave a profound effect on the expressiveness of the model, especially when the\ngeneration network has limited capacity. In this paper, we propose to learn a\nproper prior from data for AAE. We introduce the notion of code generators to\ntransform manually selected simple priors into one that can better fit the data distribution.\nExperimental results show that the proposed model can generate better\nimage quality and learn better disentangled representations than AAE in both\nsupervised and unsupervised settings. Lastly, we present its ability to do cross domain\ntranslation in a text-to-image synthesis task.","pdf":"/pdf/b65574c440d08f49236650a0ff404fad91f0d3bf.pdf","TL;DR":"Learning Priors for Adversarial Autoencoders","paperhash":"anonymous|learning_priors_for_adversarial_autoencoders","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Priors for Adversarial Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJSr0GZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1047/Authors"],"keywords":["deep learning","computer vision","generative adversarial networks"]}},{"tddate":null,"ddate":null,"tmdate":1512222544448,"tcdate":1511846958833,"number":2,"cdate":1511846958833,"id":"BkD44d9gM","invitation":"ICLR.cc/2018/Conference/-/Paper1047/Official_Review","forum":"rJSr0GZR-","replyto":"rJSr0GZR-","signatures":["ICLR.cc/2018/Conference/Paper1047/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Improving AAE by warping the Gaussian prior using deep networks","rating":"5: Marginally below acceptance threshold","review":"This paper propose a simple extension of the adversarial auto-encoders for (conditional) image generation. The general idea is that instead of using Gaussian prior, the propose algorithm uses a \"code generator\" network  to warp the gaussian distribution, such that the internal prior of the latent encoding space is more expressive and complicated. \n\nPros:\n- The proposed idea is simple and easy to implement\n- The results show improvement in terms of visual quality\n\nCons:\n- I agree that the proposed prior should better capture the data distribution. However, incorporating a generic prior over the latent space plays a vital role as regularisation, this helps avoid model collapse. Adding a complicated code generation network brings too much flexibility for the prior part. This makes the prior and posterior learnable, which makes it easier to fool the regularisation discriminator (think about the latent code and prior code collapsed to two different points). As a result, this weakens the regularisation over the latent encoder space.  \n- The above mentioned could be verified through qualitative results. As shown in Fig. 5. I believe this is a result due to the fact that the adversarial loss in the regularisation phase does not a significant influence there. \n- I have some doubts over why AAE works so poorly when the latent dimension is 2000. How to make sure it's not a problem of implementation or the model wasn't trapped into a bad local optima / saddle points. Could you justify this?\n- Contributions; this paper propose an improvement over a existing model. However, neither the idea/insights it brought can be applied onto other generative models, nor the improvement bring a significant improvement over the-state-of-the-arts. I am wondering what the community will learn from this paper, or what the author would like to claim as significant contributions. ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Priors for Adversarial Autoencoders","abstract":"Most deep latent factors choose simple priors for simplicity, tractability or not\nknowing what prior to use. Recent studies show that the choice of the prior may\nhave a profound effect on the expressiveness of the model, especially when the\ngeneration network has limited capacity. In this paper, we propose to learn a\nproper prior from data for AAE. We introduce the notion of code generators to\ntransform manually selected simple priors into one that can better fit the data distribution.\nExperimental results show that the proposed model can generate better\nimage quality and learn better disentangled representations than AAE in both\nsupervised and unsupervised settings. Lastly, we present its ability to do cross domain\ntranslation in a text-to-image synthesis task.","pdf":"/pdf/b65574c440d08f49236650a0ff404fad91f0d3bf.pdf","TL;DR":"Learning Priors for Adversarial Autoencoders","paperhash":"anonymous|learning_priors_for_adversarial_autoencoders","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Priors for Adversarial Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJSr0GZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1047/Authors"],"keywords":["deep learning","computer vision","generative adversarial networks"]}},{"tddate":null,"ddate":null,"tmdate":1512222544491,"tcdate":1511745882321,"number":1,"cdate":1511745882321,"id":"ByzPtktlM","invitation":"ICLR.cc/2018/Conference/-/Paper1047/Official_Review","forum":"rJSr0GZR-","replyto":"rJSr0GZR-","signatures":["ICLR.cc/2018/Conference/Paper1047/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting idea, but more thorough analysis is needed.","rating":"6: Marginally above acceptance threshold","review":"This paper proposes an interesting idea--to learn a flexible prior from data by maximizing data likelihood.\n\nIt seems that in the prior improvement stage, what you do is training a GAN with CG+dec as the generator while D_I as the discriminator (since you also update dec at the prior improvement stage). So it can also be regarded as GAN trained with an additional enc and D_c, and additional objective. In my opinion, this may explain why your model can generate sharper images.\n\nThe experiments do demonstrate the power of their model compared to AAE. However, only the qualitative analysis may not persuade me and more thorough analysis is needed.\n\n1. About the latent space for z. The motivation in AAE is to impose aggregated posterior regularization $D(q(z),p(z))$ where $p(z)$ is chosen as a simple one, e.g., Gaussian. I'm curious how the geometry of the latent space will be, when the code generator is introduced. Maybe some visualization like t-sne will be helpful.\n2. Any quantitative analysis? Doing a likelihood analysis like that in the AAE paper will be very informative. \n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Priors for Adversarial Autoencoders","abstract":"Most deep latent factors choose simple priors for simplicity, tractability or not\nknowing what prior to use. Recent studies show that the choice of the prior may\nhave a profound effect on the expressiveness of the model, especially when the\ngeneration network has limited capacity. In this paper, we propose to learn a\nproper prior from data for AAE. We introduce the notion of code generators to\ntransform manually selected simple priors into one that can better fit the data distribution.\nExperimental results show that the proposed model can generate better\nimage quality and learn better disentangled representations than AAE in both\nsupervised and unsupervised settings. Lastly, we present its ability to do cross domain\ntranslation in a text-to-image synthesis task.","pdf":"/pdf/b65574c440d08f49236650a0ff404fad91f0d3bf.pdf","TL;DR":"Learning Priors for Adversarial Autoencoders","paperhash":"anonymous|learning_priors_for_adversarial_autoencoders","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Priors for Adversarial Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJSr0GZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1047/Authors"],"keywords":["deep learning","computer vision","generative adversarial networks"]}},{"tddate":null,"ddate":null,"tmdate":1509666534384,"tcdate":1509666534384,"number":1,"cdate":1509666534384,"id":"SkCykNYCb","invitation":"ICLR.cc/2018/Conference/-/Paper1047/Public_Comment","forum":"rJSr0GZR-","replyto":"rJSr0GZR-","signatures":["~Thanh_Tung_Hoang1"],"readers":["everyone"],"writers":["~Thanh_Tung_Hoang1"],"content":{"title":"Wasserstein GAN could improve the mode collapse problem","comment":"AAE with code generator can produce much better images but suffer from mode collapse. It seems that the improvement in the image quality is due to the fact that the network has remembered some of the input. In other words, the mode collapse problem makes generated images look better. I would love to see the result without mode collapse problem. For example, you could try Wasserstein GAN which suffer less from mode collapse problem. I am also interested in the learned prior distribution. If you could provide some analysis on the learned prior then your paper could be much better."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Priors for Adversarial Autoencoders","abstract":"Most deep latent factors choose simple priors for simplicity, tractability or not\nknowing what prior to use. Recent studies show that the choice of the prior may\nhave a profound effect on the expressiveness of the model, especially when the\ngeneration network has limited capacity. In this paper, we propose to learn a\nproper prior from data for AAE. We introduce the notion of code generators to\ntransform manually selected simple priors into one that can better fit the data distribution.\nExperimental results show that the proposed model can generate better\nimage quality and learn better disentangled representations than AAE in both\nsupervised and unsupervised settings. Lastly, we present its ability to do cross domain\ntranslation in a text-to-image synthesis task.","pdf":"/pdf/b65574c440d08f49236650a0ff404fad91f0d3bf.pdf","TL;DR":"Learning Priors for Adversarial Autoencoders","paperhash":"anonymous|learning_priors_for_adversarial_autoencoders","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Priors for Adversarial Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJSr0GZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1047/Authors"],"keywords":["deep learning","computer vision","generative adversarial networks"]}},{"tddate":null,"ddate":null,"tmdate":1510092381727,"tcdate":1509138011404,"number":1047,"cdate":1510092360392,"id":"rJSr0GZR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rJSr0GZR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Priors for Adversarial Autoencoders","abstract":"Most deep latent factors choose simple priors for simplicity, tractability or not\nknowing what prior to use. Recent studies show that the choice of the prior may\nhave a profound effect on the expressiveness of the model, especially when the\ngeneration network has limited capacity. In this paper, we propose to learn a\nproper prior from data for AAE. We introduce the notion of code generators to\ntransform manually selected simple priors into one that can better fit the data distribution.\nExperimental results show that the proposed model can generate better\nimage quality and learn better disentangled representations than AAE in both\nsupervised and unsupervised settings. Lastly, we present its ability to do cross domain\ntranslation in a text-to-image synthesis task.","pdf":"/pdf/b65574c440d08f49236650a0ff404fad91f0d3bf.pdf","TL;DR":"Learning Priors for Adversarial Autoencoders","paperhash":"anonymous|learning_priors_for_adversarial_autoencoders","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Priors for Adversarial Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJSr0GZR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1047/Authors"],"keywords":["deep learning","computer vision","generative adversarial networks"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}