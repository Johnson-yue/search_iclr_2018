{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222801902,"tcdate":1512057257421,"number":3,"cdate":1512057257421,"id":"H1-nFopxM","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Review","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["ICLR.cc/2018/Conference/Paper879/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Review ","rating":"5: Marginally below acceptance threshold","review":"The paper proposes a new approach (Minerva) to perform query answering on knowledge bases via reinforcement learning. The method is intended to answer queries of the form (e,r,?) on knowledge graphs consisting of dyadic relations. Minerva is evaluated on a number of different datasets such as WN18, NELL-995, and WikiMovies.\n\nThe paper proposes interesting ideas to attack a challenging problem, i.e., how to perform query answering on incomplete knowledge bases. While RL methods for KG completion have been proposed recently (e.g., DeepPath), Minerva improves over these approaches by not requiring the target entity. This property can be indeed be important to perform query answering efficiently. The proposed model seems technically reasonable and the paper is generally written well and good to understand. However, important parts of the paper seem currently unfinished and would benefit from a more detailed discussion and analysis.\n\nMost importantly, I'm currently missing a better motivation and especially a more thorough evaluation on how Minerva improves over non-RL methods. For instance, the authors mention multi-hop methods such as (Neelakantan, 2015; Guu, 2015) in the introduction. Since these methods are closely related, it would be important to compare to them experimentally (unfortunately, DeepPath doesn't do this comparison either). For instance, eliminating the need to pre-compute paths might be irrelevant when it doesn't improve actual performance. Similarly, the paper mentions improved inference time, which indeed is a nice feature. However, I'm wondering, what is the training time and how does it compare to standard methods like ComplEx. Also, how robust is training using REINFORCE?\n\nWith regard to the experimental results: The  improvements over DeepPath on NELL and on WikiMovies are indeed promising. I found the later results the most convincing, as the setting is closest to the actual task of query answering. However, what is worrying is that Minerva doesn't do well on WN18 and FB15k-237 (for which the results are, unfortunately, only reported in the appendix). On FB15k-237 (which is harder than WN18 and arguably more relevant for real-world scenarios since it is a subset of a real-world knowledge graph), it is actually outperformed by the relatively simple DistMult method. From these results, I find it hard to justify that \"MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods\", as stated in the abstract.\n\nFurther comments:\n- How are non-existing relations handled, i.e., queries (e,r,x) where there is no valid x? Does Minerva assume there is always a valid answer?\n- Comparison to DeepPath: Did you evaluate Minerva with fixed embeddings? Since the experiments in DeepPath used fixed embeddings, it would be important to know how much of the improvements can be attributed to this difference. \n- The experimental section covers quite a lot of different tasks and datasets (Countries, UMLS, Nations, NELL, WN18RR, Gridworld, WikiMovies) all with different combinations of methods. For instance, countries is evaluated against ComplEx,NeuralLP and NTP; NELL against DeepPath; WN18RR against ConvE, ComplEx, and DistMult; WikiMovies against MemoryNetworks, QA and NeuralLP. A more focused evaluation with a consistent set of methods could make the experiments more insightful.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1512222801940,"tcdate":1512002043542,"number":2,"cdate":1512002043542,"id":"SymbMC2xf","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Review","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["ICLR.cc/2018/Conference/Paper879/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Simple RL approach for reasoning on Knowledge bases, good performance on variety of datasets but need to be slightly more thorough in their comparisons with prior work","rating":"6: Marginally above acceptance threshold","review":"The paper present a RL based approach to walk on a knowledge graph to answer queries. The idea is novel, the paper is clear in its exposition, and the authors provide a number of experimental comparisons with prior work on a variety of datasets . \n\nPros:\n1. The approach is simple (no pre-training, no reward shaping, just RL from scratch with terminal reward, uses LSTM for keeping track of past state), computationally efficient (no computation over the full graph), and performs well in most of the experiments reported in the paper. \n2. It scales well to longer path lengths, and also outperforms other methods for partially structured queries.\n\nCons:\n1. You should elaborate more on the negative results on FB15K and why this performance would not transfer to other KB datasets that exist. This seems especially important since it's a large scale dataset, while the datasets a)-c) reported in the paper are small scale. \n2. It would also be good to see if your method also performed well on the Nations dataset where the baselines performed well. That said, if its a small scale dataset, it would be preferable to focus on strengthening the experimental analysis on larger datasets.\n3. In Section 4.2, why have you only compared to NeuralLP and not compared with the other methods? \n\nSuggestions/Questions:\n1. In the datatset statistics, can you also add the average degree of the knowledge graphs, to get a rough sense of the difficulty of each task.\n2. The explanation of the knowledge graph and notation could be made cleaner. It would be easier to introduce the vertices as the entities, and edges as normal edges with a labelled relation on top. A quick example to explain the action space would also help.\n3. Did you try a model where instead of using A_t directly as the weight vector for the softmax, you use it as an extra input? Using it as the weight matrix directly might be over regularizing/constraining your model.  \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1512222802021,"tcdate":1511951680374,"number":1,"cdate":1511951680374,"id":"SJdS6W2ef","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Review","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["ICLR.cc/2018/Conference/Paper879/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review","rating":"6: Marginally above acceptance threshold","review":"The paper proposes an approach for query answering/link prediction in KBs that uses RL to navigate the KB graph between a query entity and a potential answer entity. The main originality is that, unlike random walk models, the proposed approach learns to navigate the graph while being conditioned on the query relation type.\n\nI find the method sound and efficient and the proposed experiments are solid and convincing; for what they test for.\n\nIndeed, for each relation type that one wants to be testing on, this type of approach needs many training examples of pairs of entities (say e_1, e_2) connected both by this relation type (e_1 R e_2) and by alternative paths (e_1 R' R'' R''' e_2). Because the model needs to discover and learn that R <=> R ' R'' R''' .\n\nThe proposed model seems to be able to do that well when the number of relation types remains low (< 50). But things get interesting in KBs when the number of relation types gets pretty large (hundreds / thousands). Learning the kind of patterns described above gets much trickier then. The results on FB15k are a bit worrying in that respect. Maybe this is a matter of the dataset FB15k itself but then having experiments on another dataset with hundreds of relation types could be important. \n\nNELL has indeed 200 relations but if I'm not mistaken, the NELL dataset is used for fact prediction and not query answering. And as noted in the paper, fact prediction is much easier.\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1511735932028,"tcdate":1511735932028,"number":4,"cdate":1511735932028,"id":"HkEYGpulf","invitation":"ICLR.cc/2018/Conference/-/Paper879/Public_Comment","forum":"Syg-YfWCW","replyto":"H1tRWqdgf","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"The community's perspective to negative results","comment":"Quoting a paragraph of the author response:\n\n\"Lastly, we would like to emphasize that the community should be more welcoming to negative results and analysis. Comments such as this only discourages young researchers to not report negative results leading to bad science.\"\n\nIt is a great point to be brought up that *every* researcher should not be obstructed by negative results and the community should be more welcome to them. However, I think this is the point of the main comment, not vice versa. The comment made it clear that it is demanding negative results to be included in the main body of a paper and interesting discussion and analysis to be done and presented, not demanding to \"not submit a paper with negative results\". It is advocating for legit presentation of negative results instead of presenting them in supplementary, separated from positive ones."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1511723473468,"tcdate":1511723473468,"number":4,"cdate":1511723473468,"id":"H1tRWqdgf","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Comment","forum":"Syg-YfWCW","replyto":"Hkcn5-Dyz","signatures":["ICLR.cc/2018/Conference/Paper879/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper879/Authors"],"content":{"title":"Re: ","comment":"We agree that reporting negative results on a particular dataset is important and that's why we chose to include them in our submission. \ni) There has been a high variance of scores reported for FB15k-237 among many recent papers (ranging from low 40 hits@10 to ~53 hits@10). In fact, the results we currently get is comparable to state-of-the-art results reported in some recent papers. However, instead, we chose to compare to a very high score which our in-house implementation achieved.\nii) We politely disagree that FB15k-237 is a great dataset for comparing query answering performance. The presence of many 1-to-Many query relations, low clustering coefficient (Holland & Leinhardt, 1971; Watts & Strogatz, 1998) and low occurrence of various path types makes it less amenable for path based models and less interesting for query answering. We will update the next version of the paper with more detailed analysis.\niii) The 7 datasets where MINERVA achieves excellent results are i) Countries ii) UMLS  iii) Kinship iv) WN18RR v) NELL-995 vi) WikiMovies vii) Grid World (important experiment since we test how MINERVA works for long paths)\n\nLastly, we would like to emphasize that the community should be more welcoming to negative results and analysis. Comments such as this only discourages young researchers to not report negative results leading to bad science.\n\nPaul W Holland and Samuel Leinhardt. Transitivity in structural models of small groups. Comparative Group Studies, 1971.\nDuncan J Watts and Steven H Strogatz. Collective dynamics of small-worldnetworks. nature, 1998."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1510686731582,"tcdate":1510686707893,"number":3,"cdate":1510686707893,"id":"rJ3lxa_1M","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Comment","forum":"Syg-YfWCW","replyto":"SJCU15BJf","signatures":["ICLR.cc/2018/Conference/Paper879/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper879/Authors"],"content":{"title":"Re: Supervised Approach","comment":"Thank you for the comment. Since we are doing query answering, during test time, we do not have the information about target entities. That would mean enumerating all paths starting from a source entity and training a classifier to choose one of the target entities that these paths end on. This seemed like a reasonable first step, but the main bottleneck is the huge number of paths that need to be considered. For instance, the avg. number of length 3 paths starting from an entity in the validation set of Fb15k-237 is 1,800,759 (1.8M). That means during inference, we need to gather around 1.8M paths for each query, compute features and choose from one of the end entities. Sub-sampling paths is another approach, but it is difficult to come up with a non-heuristic way of subsampling. Another drawback of this approach that we would like to point out, is that only a few paths are ‘predictive’ of a query relation and subsampling might easily lose them.\n\nYet another way of training using supervised approach would be to sample one path which leads to the target entity and another path which doesn’t and do a gradient update to favor the path which does reach. During inference time, we just sample from the model (RNN for example) a path and return the endpoint as the answer. This approach differs from our RL based approach in that during training we depend on the current model to sample the next path. This has the advantage of utilizing the information that the model has acquired by exploring the graphs till now. For example, it might have learned that a particular kind of path isn’t good for a query relation, even though it might lead to the target entity for this particular query. The RL approach will use that information and not select that path and would instead try to search a path which would generalize more. \n\nIn general, it is a good idea to explore around where the model is, instead of doing uniform sampling and has been well studied in contextual bandit settings (Dudik et al., 2011, Agarwal et al., 2014). While the proposal is not doing uniform exploration since it samples any correct path to the target, even this kind of \"uniform\" sampling can hurt generalization performance since it does not use the current model to help identify which good paths are representable. Thanks again!\n\nEfficient Optimal Learning for Contextual Bandits - Dudik et al., 2011\nTaming the Monster: A Fast and Simple Algorithm for Contextual Bandits - Agarwal et al., 2014"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1510574913525,"tcdate":1510574769913,"number":3,"cdate":1510574769913,"id":"Hkcn5-Dyz","invitation":"ICLR.cc/2018/Conference/-/Paper879/Public_Comment","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Biased Results Presentation - negative results should be included in result section instead of appendix","comment":"I liked the idea of the paper but would like to emphasize that negative results on a particular dataset should be included in the main paper instead of the appendix. In this paper, the negative results on FB15K-237 were reported only in the appendix and no experiment results on FB15K-237 were reported in the main paper. FB15K-237 was listed in Table 1, \"Statistics of various datasets used in experiments\", therefore excluding it from the result session makes the results incomplete, and many interesting discussion and analysis that should have been done and presented were omitted as a result. It also makes the last sentence in the abstract \"MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods\" a severe overclaim.\n\nMore importantly, FB15K-237 is a challenging knowledge graph modeling testbed curated by (Toutanova and Chen, 2015), which is more at-scale and more wildly studied than a few of the datasets the paper used (COUNTRIES, KINSHIP, UMLS). Inferior performance on this dataset could indicate serious flaws of the proposed model when applied on open-domain KGs.\n\nMany readers pay attention to the appendix only when necessary. The paper should include pointers to the appendix for contradictory results to this degree. Leaving the results in appendix without making additional claims creates a bias for reviewers and other readers, and should be strictly discouraged.\n\n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1511668172750,"tcdate":1510555667859,"number":2,"cdate":1510555667859,"id":"BJhGlT8JM","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Comment","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["ICLR.cc/2018/Conference/Paper879/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper879/Authors"],"content":{"title":"Minor clarifications","comment":"We wanted to address/clarify few minor mistakes which we found in the text of the paper which could possibly confuse the reviewers. We will definitely fix these in the next version of the paper.\n\n1. Introduction: We suggest that PRA (Lao et al., 2011) use the same set of collected path to answer diverse query types. PRA, given a query, keeps paths which are supported by at least a fraction of the training queries and are also bounded by a maximum length. Additionally, they are constrained to end at one of the target entities in the training set. These constraints make them query dependent but are heuristic in nature which is in contrast to MINERVA which learns to use the query relation to make decisions at every step.\n2. Sec 2.1 - Our environment is a finite horizon deterministic Markov decision model -> This should be finite horizon, deterministic and partially observed Markov decision process. \n3. Sec 2.1 - From the KB, a knowledge graph G can be constructed where the entities s,t are represented as the nodes -> the identifiers 's' and 't' should be 'e1' and 'e2’.\n4. Section 5 (Effectiveness of Remembering Path History) - We replaced the LSTM with a simple 2 layer MLP -> ‘replace’ might be confusing. In this ablation study, the policy network (2 layer MLP) makes decision based on only the local information (current entity, query). It does not have access to the entire history of decisions encoded by the LSTM.\n5. Figure 3 - Caption - The figure in the right -> The figure at the bottom. Also for consistency, the top figure (left) should have LSU grayed and figure (right) should have NBA grayed.\n6. Figure 1 - The edge from nodes USA to CA is wrongly labeled as 'has_city'. It should be instead labeled as 'has_state'.\n7.  Figure 4 - This plot shows the frequency of occurrence of various unique paths (types) of length 3 which occur more than 'x' times in various datasets. Intuitively, a predictive path which generalizes across queries will occur many number of times in the graph. As we can see, the characteristics of FB15k-237 is quite different from other datasets. Path types do not repeat that often, making it hard for MINERVA to learn paths which generalizes.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1510477654161,"tcdate":1510477654161,"number":2,"cdate":1510477654161,"id":"SJCU15BJf","invitation":"ICLR.cc/2018/Conference/-/Paper879/Public_Comment","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Supervised approach","comment":"A simple solution for this problem is supervised approach, i.e., treating the path from the source node to target node as *sequences* and training a RNN on these *sequences*. I am wondering how would the proposed approaches compare with the supervised version.\n\nIntuitively, the reinforced version over supervised version is its efficiency in getting positive rewards. But for this problem, enumerating the paths from the source nodes to target nodes sounds like a more efficient way. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1510102046223,"tcdate":1510102046223,"number":1,"cdate":1510102046223,"id":"H18mNA1kz","invitation":"ICLR.cc/2018/Conference/-/Paper879/Official_Comment","forum":"Syg-YfWCW","replyto":"rkFp3JaC-","signatures":["ICLR.cc/2018/Conference/Paper879/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper879/Authors"],"content":{"title":"Re: Negative results on FB15k-237","comment":"Thank you for the comment. The performance of DistMult on FB15k-237 (56.8 HITS@10) are scores that we got with our own in-house implementation. To the best of our knowledge, it is better than all of the published scores for DistMult on this dataset (closest being 52.93 by Jain et al (2017) https://arxiv.org/pdf/1706.00637.pdf and 52.3 by Toutanova et al. (2015) http://cs.stanford.edu/~danqi/papers/emnlp2015.pdf). The results of ConvE and ComplEx models were taken from Dettmers et al. (2017) https://arxiv.org/pdf/1707.01476.pdf). We are aware of the high variance in scores reported for the DistMult model on FB15k-237 by many other papers, but we decided to report the results that we got for it. We will make this clear in the next version of the paper. Thanks again!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1509911744739,"tcdate":1509911744739,"number":1,"cdate":1509911744739,"id":"rkFp3JaC-","invitation":"ICLR.cc/2018/Conference/-/Paper879/Public_Comment","forum":"Syg-YfWCW","replyto":"Syg-YfWCW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Negative results on FB15k-237","comment":"Kudos for reporting negative results. Quick question: the results for the other methods on FB15k-237 are obtained by running code or copying results from previous work? I’m skeptical of/surprised by the 56.8 hits@10 for DistMult. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]}},{"tddate":null,"ddate":null,"tmdate":1509739051191,"tcdate":1509136632367,"number":879,"cdate":1509739048532,"id":"Syg-YfWCW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Syg-YfWCW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning","abstract":"Knowledge bases (KB), both automatically and manually constructed, are often incomplete --- many valid facts can be inferred from the KB by synthesizing existing information. We propose a new algorithm, MINERVA, that infers facts represented implicitly in a KB to solve a practical query answering task involving predicting which entity is the answer to a question. MINERVA is based on neural reinforcement learning and learns how to navigate the graph to find predictive paths. Empirically, MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods.","pdf":"/pdf/f4a51e16d80de24a14656f9a0e31df63a6bccaf6.pdf","TL;DR":"We present a RL agent \\textsc{minerva} which learns to walk on a knowledge graph and answer queries","paperhash":"anonymous|go_for_a_walk_and_arrive_at_the_answer_reasoning_over_paths_in_knowledge_bases_using_reinforcement_learning","_bibtex":"@article{\n  anonymous2018go,\n  title={Go for a Walk and Arrive at the Answer: Reasoning Over Paths in Knowledge Bases using Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Syg-YfWCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper879/Authors"],"keywords":["Knowledge Graphs","Reinforcement Learning","Query Answering"]},"nonreaders":[],"replyCount":11,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}