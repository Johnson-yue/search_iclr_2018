{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222680021,"tcdate":1512140806035,"number":3,"cdate":1512140806035,"id":"BkC-glk-M","invitation":"ICLR.cc/2018/Conference/-/Paper526/Official_Review","forum":"B1p461b0W","replyto":"B1p461b0W","signatures":["ICLR.cc/2018/Conference/Paper526/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The paper talks about how various kinds of noise types and levels hurt various deepnets on different problems. Furthermore, the authors give some empirical analysis on how the learning parameters specifically batch size and learning rate should be tweaked i nthe presence of noise.","rating":"5: Marginally below acceptance threshold","review":"The problem the authors are tackling is extremely relevant to the research community. The paper is well written with considerable number of experiments. While a few conclusions are made in the paper a few things are missing to make even broader conclusions. I think adding those experiments will make the paper stronger! \n\n1. Annotation noise is one of the biggest bottleneck while collecting fully supervised datasets. This noise is mainly driven by lack of clear definitions for each concept (fine-grained, large label dictionary etc.). It would be good to add such type of noise to the datasets and see how the networks perform.\n2. While it is interesting to see large capacity networks more resilient to noise I think the paper spends more effort and time on small datasets and smaller models even in the convolutional space. It would be great to add more experiments on the state of the art residual networks and large datasets like ImageNet.\n3. Because the analysis is very empirical and authors have a hypothesis that the batch size is effectively smaller when there are large batches with noisy examples it would be good to add some analysis on the gradients to throw more light and make it less empirical.  Batch size and learning rate analysis was very informative but should be done on ResNets and larger datasets to make the paper strong and provide value to the research community.\n\nOverall, with these key things missing the paper falls a bit short making it more suitable for a re submission with further experiments.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]}},{"tddate":null,"ddate":null,"tmdate":1512222680060,"tcdate":1511828036649,"number":2,"cdate":1511828036649,"id":"HJTr9mqgM","invitation":"ICLR.cc/2018/Conference/-/Paper526/Official_Review","forum":"B1p461b0W","replyto":"B1p461b0W","signatures":["ICLR.cc/2018/Conference/Paper526/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Learning with Noisy data.","rating":"4: Ok but not good enough - rejection","review":"The authors study the effect of label noise on classification tasks. They perform experiments of label noise in a uniform setting, structured setting as well provide some heuristics to mitigate the effect of label noise such as changing learning rate or batch size. \n\nAlthough, the observations are interesting, especially the one on MNIST where the network performs well even with correct labels slightly above chance, the overall contributions are incremental. Most of the observations of label noise such as training with structured noise, importance of larger datasets have already been archived in prior work such as in Sukhbataar et.al. (2014) and Van Horn et. al (2015). Agreed that the authors do a more detailed study on simple MNIST classification, but these insights are not transferable to more challenging domains. \n\nThe main limitation of the paper is proposing a principled way to mitigate noise as done in Sukhbataar et.al. (2014), or an actionable trade-off between data acquisition and training schedules. \n\nThe authors contend that the way they deal with noise (keeping number of training samples constant) is different from previous setting which use label flips. However, the previous settings can be reinterpreted in the authors setting. I found the formulation of the \\alpha to be non-intuitive and confusing at times. The graphs plot number of noisy labels per clean label so a alpha of 100 would imply 1 right label and 100 noisy labels for total 101 labels. In fact, this depends on the task at hand (for MNIST it is 11 clean labels for 101 labels). This can be improved to help readers understand better. \n\nThere are several unanswered questions as to how this observation transfers to a semi-supervised or unsupervised setting, and also devise architectures depending on the level of expected noise in the labels. \n\nOverall, I feel the paper is not up to mark and suggest the authors devote using these insights in a more actionable setting. \nMissing citation: \"Training Deep Neural Networks on Noisy Labels with Bootstrapping\", Reed et al.\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]}},{"tddate":null,"ddate":null,"tmdate":1512222680099,"tcdate":1510401980906,"number":1,"cdate":1510401980906,"id":"B1STvPVyG","invitation":"ICLR.cc/2018/Conference/-/Paper526/Official_Review","forum":"B1p461b0W","replyto":"B1p461b0W","signatures":["ICLR.cc/2018/Conference/Paper526/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Bold claims, but in contrast to observations with large-scale real-world data. ","rating":"5: Marginally below acceptance threshold","review":"The paper makes a bold claim, that deep neural networks are robust to arbitrary level of noise. It also implies that this would be true for any type of noise, and support this later claim using experiments on CIFAR and MNIST with three noise types: (1) uniform label noise (2) non-uniform but image-independent label noise, which is named \"structured noise\", and (3) Samples from out-of-dataset classes. The experiments show robustness to these types of noise. \n\nReview: \nThe claim made by the paper is overly general, and in my own experience incorrect when considering real-world-noise. This is supported by the literature on \"data cleaning\" (partially by the authors), a procedure which is widely acknowledged as critical for good object recognition.  While it is true that some image-independent label noise can be alleviated in some datasets, incorrect labels in real world datasets can substantially harm classification accuracy.\n\nIt would be interesting to understand the source of the difference between the results in this paper and the more common results (where label noise damages recognition quality). The paper did not get a chance to test these differences, and I can only raise a few hypotheses. First, real-world noise depends on the image and classes in a more structured way. For instance, raters may confuse one bird species from a similar one, when the bird is photographed from a particular angle. This could be tested experimentally, for example by adding incorrect labels for close species using the CUB data for fine-grained bird species recognition.  Another possible reason is that classes in MNIST and CIFAR10 are already very distinctive, so are more robust to noise. Once again, it would be interesting for the paper to study why they achieve robustness to noise while the effect does not hold in general. \n\nWithout such an analysis, I feel the paper should not be accepted to ICLR because the way it states its claim may mislead readers. \n\nOther specific comments: \n-- Section 3.4 the experimental setup, should clearly state details of the optimization, architecture and hyper parameter search. For example, for Conv4, how many channels at each layer? how was the net initialized? which hyper parameters were tuned and with which values? were hyper parameters tuned on a separate validation set? How was the train/val/test split done, etc. These details are useful for judging technical correctness.\n-- Section 4, importance of large datasets. The recent paper by Chen et al (2017) would be relevant here.\n-- Figure 8 failed to show for me. \n-- Figure 9,10, need to specify which noise model was used.\n\n\n\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]}},{"tddate":null,"ddate":null,"tmdate":1510263733596,"tcdate":1510263733596,"number":1,"cdate":1510263733596,"id":"ByRhoHM1G","invitation":"ICLR.cc/2018/Conference/-/Paper526/Official_Comment","forum":"B1p461b0W","replyto":"H1pqnCHCZ","signatures":["ICLR.cc/2018/Conference/Paper526/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper526/Authors"],"content":{"title":"Response re comparison of results","comment":"Thank you for bringing this up.  Indeed, the difference between ResNets and CaffeNet likely makes a difference in the observed results. Further, in the referred paper, as in other prior work, an increase in noise comes at the expense of a smaller number of clean training examples. As we show in Section 4, this likely causes lower training performance than could be achieved over a large training set with the same level of noise."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]}},{"tddate":null,"ddate":null,"tmdate":1509448853174,"tcdate":1509448853174,"number":1,"cdate":1509448853174,"id":"H1pqnCHCZ","invitation":"ICLR.cc/2018/Conference/-/Paper526/Public_Comment","forum":"B1p461b0W","replyto":"B1p461b0W","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Good results, better than in literature","comment":"Here https://arxiv.org/abs/1606.02228 accuracy drops 27%, with 1:1 noisy/clean labels, which is much more than in the paper. Although, may be ResNets are much more robust than CaffeNet. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]}},{"tddate":null,"ddate":null,"tmdate":1509739254601,"tcdate":1509125428538,"number":526,"cdate":1509739251904,"id":"B1p461b0W","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1p461b0W","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Deep Learning is Robust to Massive Label Noise","abstract":"Deep neural networks trained on large supervised datasets have led to impressive results in recent years. However, since well-annotated datasets can be prohibitively expensive and time-consuming to collect, recent work has explored the use of larger but noisy datasets that can be more easily obtained. In this paper, we investigate the behavior of deep neural networks on training sets with massively noisy labels. We show on multiple datasets such as MINST, CIFAR-10 and ImageNet that successful learning is possible even with an essentially arbitrary amount of noise. For example, on MNIST we find that accuracy of above 90 percent is still attainable even when the dataset has been diluted with 100 noisy examples for each clean example. Such behavior holds across multiple patterns of label noise, even when noisy labels are biased towards confusing classes. Further, we show how the required dataset size for successful training increases with higher label noise. Finally, we present simple actionable techniques for improving learning in the regime of high label noise.","pdf":"/pdf/cc32910daa6421501516c5147058865e62bd999a.pdf","TL;DR":"We show that deep neural networks are able to learn from data that has been diluted by an arbitrary amount of noise.","paperhash":"anonymous|deep_learning_is_robust_to_massive_label_noise","_bibtex":"@article{\n  anonymous2018deep,\n  title={Deep Learning is Robust to Massive Label Noise},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1p461b0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper526/Authors"],"keywords":["label noise","weakly supervised learning","robustness of neural networks","deep learning","large datasets"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}