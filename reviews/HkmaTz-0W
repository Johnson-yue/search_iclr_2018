{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222543540,"tcdate":1511990576338,"number":3,"cdate":1511990576338,"id":"S1O4Hinlf","invitation":"ICLR.cc/2018/Conference/-/Paper1032/Official_Review","forum":"HkmaTz-0W","replyto":"HkmaTz-0W","signatures":["ICLR.cc/2018/Conference/Paper1032/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Throughout visualisation, this paper investigates the \"flat vs sharp dilemma\", the non convexity of the loss surface and the so-called optimisation paths. Nice plots but I would have appreciated a deeper treatment of observations.","rating":"5: Marginally below acceptance threshold","review":"\n* In the \"flat vs sharp\" dilemma, the experiments display that the dilemma, if any, is subtle. Table 1 does not necessarily contradict this view. It would be a good idea to put the test results directly on Fig. 4 as it does not ease reading currently (and postpone ResNet-56 in the appendix).\n\nHow was Figure 5 computed ? It is said that *a* random direction was used from each minimiser to plot the loss, so how the 2D directions obtained ?\n\n* On the convexity vs non-convexity (Sec. 6), it is interesting to see how pushing the Id through the net changes the look of the loss for deep nets. The difference VGG - ResNets is also interesting, but it would have been interesting to see how this affects the current state of the art in understanding deep learning, something that was done for the \"flat vs sharp\" dilemma, but is lacking here. For example, does this observation that the local curvature of the loss around minima is different for ResNets and VGG allows to interpret the difference in their performances ?\n\n* On optimisation paths, the choice of PCA directions is wise compared to random projections, and results are nice as plotted. There is however a phenomenon I would have liked to be discussed, the fact that the leading eigenvector captures so much variability, which perhaps signals that optimisation happens in a very low dimensional subspace for the experiments carried, and could be useful for optimisation algorithms (you trade dimension d for a much smaller \"effective\" d', you only have to figure out a generating system for this subspace and carry out optimisation inside). Can this be related to the \"flat vs sharp\" dilemma ? I would suppose that flatness tends to increase the variability captured by leading eigenvectors ?\n\n\nTypoes:\n\nLegend of Figure 2: red lines are error -> red lines are accuracy\nTable 1: test accuracy -> test error\nBefore 6.2: architecture effects -> architecture affects","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Visualizing the Loss Landscape of Neural Nets","abstract":"As the effectiveness of deep neural networks continues to improve, there remain significant questions about how choices in network architecture, batch size, and parameter initialization impact the network’s trainability and effectiveness. Theoreticians\nhave made significant discoveries, but it is often difficult to translate the assumptions required by theoretical results into meaningful statements about the differences between the neural nets used in practice. Another approach to understanding neural nets is to use visualizations to explore the empirical behavior of loss functions. However, without great care, these visualizations can produce distorted or misleading results.\n\nIn this paper, we describe a simple approach to visualizing neural network loss functions that provides new insights into the trainability and generalization of neural nets. The technique is used to explore the effect of network architecture, choice of optimizer, and algorithm parameters on loss function minima.","pdf":"/pdf/2f8378bb7e7e0c243165ab91d87eae4eaea8698f.pdf","paperhash":"anonymous|visualizing_the_loss_landscape_of_neural_nets","_bibtex":"@article{\n  anonymous2018visualizing,\n  title={Visualizing the Loss Landscape of Neural Nets},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkmaTz-0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1032/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222543578,"tcdate":1511868057963,"number":2,"cdate":1511868057963,"id":"ByfiU65gf","invitation":"ICLR.cc/2018/Conference/-/Paper1032/Official_Review","forum":"HkmaTz-0W","replyto":"HkmaTz-0W","signatures":["ICLR.cc/2018/Conference/Paper1032/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The submission considers the problem of visualizing loss functions of NNs and provides some interesting insights on the trainability and the generalization of NNs. However, it seems its novelty is quite limited.","rating":"4: Ok but not good enough - rejection","review":"The main concern of this submission is the novelty. Proposed method to visualize the loss function sounds too incremental from existing works. One of the main distinctions is using filter-wise normalization, but it is somehow trivial. In experiments, no comparisons against existing works is performed (at least on toy/controlled environments). Some findings in this submission indeed look interesting, but it is not clear if those results are something difficult to find with other existing standard ways, or even how reliable they are since the effectiveness has not been evaluated. \n\nMinor comments: \nIn introduction, parameter with zero training error doesn't mean it's a global minimizer\nIn section 2, it is not clear that visualizing loss function is helpful in see the reasons of generalization given minima. \nIn figure 2, why do we have solutions at 0 for small batch size and 1 for large batch size case? (why should they be different?)\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Visualizing the Loss Landscape of Neural Nets","abstract":"As the effectiveness of deep neural networks continues to improve, there remain significant questions about how choices in network architecture, batch size, and parameter initialization impact the network’s trainability and effectiveness. Theoreticians\nhave made significant discoveries, but it is often difficult to translate the assumptions required by theoretical results into meaningful statements about the differences between the neural nets used in practice. Another approach to understanding neural nets is to use visualizations to explore the empirical behavior of loss functions. However, without great care, these visualizations can produce distorted or misleading results.\n\nIn this paper, we describe a simple approach to visualizing neural network loss functions that provides new insights into the trainability and generalization of neural nets. The technique is used to explore the effect of network architecture, choice of optimizer, and algorithm parameters on loss function minima.","pdf":"/pdf/2f8378bb7e7e0c243165ab91d87eae4eaea8698f.pdf","paperhash":"anonymous|visualizing_the_loss_landscape_of_neural_nets","_bibtex":"@article{\n  anonymous2018visualizing,\n  title={Visualizing the Loss Landscape of Neural Nets},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkmaTz-0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1032/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222543617,"tcdate":1511759069090,"number":1,"cdate":1511759069090,"id":"SkB16fKxf","invitation":"ICLR.cc/2018/Conference/-/Paper1032/Official_Review","forum":"HkmaTz-0W","replyto":"HkmaTz-0W","signatures":["ICLR.cc/2018/Conference/Paper1032/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Nice visualizations but conclusions are unclear","rating":"5: Marginally below acceptance threshold","review":"This paper provides visualizations of different deep network loss surfaces using 2D contour plots, both at minima and along optimization trajectories. They mention some subtle details that must be taken into account, such as scaling the plot axes by the filter magnitudes, in order to obtain correctly scaled plots. \n\nOverall, I think there is potential with this work but it feels preliminary. The visualizations are interesting and provide some general intuition, but they don't yield any clear novel insights that could be used in practice. Also, several parts of the paper spend too much time on describing other work or on implementation details which could be moved to the appendix.\n\nGeneral Comments:\n- I think Sections 2, 3, 4 are too long, we only start getting to the results section at the end of page 4. I suggest shortening Section 2, and it should be possible to combine Sections 3 and 4 into a page at most. 1D interpolations and 2D contour plots can be described in a few sentences each.  \n- I think Section 5 can be put in the Appendix - it's essentially an illustration of why the weight scaling is important. Once these details are done correctly, the experiments support the relatively well-accepted hypothesis that flat minima generalize better. \n- The plots in Section 6 are interesting, it would be nice if the authors had an explanation of why the loss surface changes the way it does when skip connections are added. \n- In Section 7, it's less useful to spend time describing what happens when the visualization is done wrong (i.e. projecting along random directions rather than PCA vectors) -  this can be put in the Appendix. I would suggest just including the visualizations of the optimization trajectories which are done correctly and focus on deriving interesting/useful conclusions from them. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Visualizing the Loss Landscape of Neural Nets","abstract":"As the effectiveness of deep neural networks continues to improve, there remain significant questions about how choices in network architecture, batch size, and parameter initialization impact the network’s trainability and effectiveness. Theoreticians\nhave made significant discoveries, but it is often difficult to translate the assumptions required by theoretical results into meaningful statements about the differences between the neural nets used in practice. Another approach to understanding neural nets is to use visualizations to explore the empirical behavior of loss functions. However, without great care, these visualizations can produce distorted or misleading results.\n\nIn this paper, we describe a simple approach to visualizing neural network loss functions that provides new insights into the trainability and generalization of neural nets. The technique is used to explore the effect of network architecture, choice of optimizer, and algorithm parameters on loss function minima.","pdf":"/pdf/2f8378bb7e7e0c243165ab91d87eae4eaea8698f.pdf","paperhash":"anonymous|visualizing_the_loss_landscape_of_neural_nets","_bibtex":"@article{\n  anonymous2018visualizing,\n  title={Visualizing the Loss Landscape of Neural Nets},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkmaTz-0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1032/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510092382248,"tcdate":1509137873376,"number":1032,"cdate":1510092360587,"id":"HkmaTz-0W","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkmaTz-0W","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Visualizing the Loss Landscape of Neural Nets","abstract":"As the effectiveness of deep neural networks continues to improve, there remain significant questions about how choices in network architecture, batch size, and parameter initialization impact the network’s trainability and effectiveness. Theoreticians\nhave made significant discoveries, but it is often difficult to translate the assumptions required by theoretical results into meaningful statements about the differences between the neural nets used in practice. Another approach to understanding neural nets is to use visualizations to explore the empirical behavior of loss functions. However, without great care, these visualizations can produce distorted or misleading results.\n\nIn this paper, we describe a simple approach to visualizing neural network loss functions that provides new insights into the trainability and generalization of neural nets. The technique is used to explore the effect of network architecture, choice of optimizer, and algorithm parameters on loss function minima.","pdf":"/pdf/2f8378bb7e7e0c243165ab91d87eae4eaea8698f.pdf","paperhash":"anonymous|visualizing_the_loss_landscape_of_neural_nets","_bibtex":"@article{\n  anonymous2018visualizing,\n  title={Visualizing the Loss Landscape of Neural Nets},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkmaTz-0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1032/Authors"],"keywords":[]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}