{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222823368,"tcdate":1511901690663,"number":3,"cdate":1511901690663,"id":"H1QWqHsgz","invitation":"ICLR.cc/2018/Conference/-/Paper938/Official_Review","forum":"r1NYjfbR-","replyto":"r1NYjfbR-","signatures":["ICLR.cc/2018/Conference/Paper938/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Review","rating":"6: Marginally above acceptance threshold","review":"\nThe paper proposes a generative model for images that does no require to learn a discriminator (as in GAN’s) or learned embedding. The proposed generator is obtained by learning an inverse operator for a scattering transform.\n\nThe paper is well written and clear. The main contribution of the work is to show that one can design an embedding with some desirable properties and recover, to a good degree, most of the interesting aspects of generative models. However, the model doesn’t seem to be able to produce high quality samples. In my view, having a learned pseudo-inverse for scattering coefficients is interesting on its own right. The authors should show more clearly the generalization capabilities to test samples. Is the network able to invert images that follow the train distribution but are not in the training set?\n\nAs the authors point out, the representation is non-invertible. It seems that using an L2 loss in pixel space for training the generator would necessarily lead to blurred reconstructions (and samples) (as it produces a point estimate). Unless the generator overfits the training data, but then it would not generalize. The reason being that many images would lie in the level set for a given feature vector, and the generator cannot deterministically disambiguate which one to match. \n\nThe sampling method described in Section 3.2 does not suffer from this problem, although as the authors point out, a good initialization is required. Would it make sense to combine the two? Use the generator network to produce a good initial condition and then refine it with the iterative procedure.\n\nThis property is exploited in the conditional generation setting in:\n\nBruna, J. et al \"Super-resolution with deep convolutional sufficient statistics.\" arXiv preprint arXiv:1511.05666 (2015).\n\nThe samples produced by the model are of poorer quality than those obtained with GAN’s. Clearly the model is assigning mass to regions of the space where there are not valid images.  (similar effect that suffer models train with MLE). Could you please comment on this point?\n\nThe title is a bit misleading in my view. “Analyzing GANs” suggests analyzing the model in general, this is, its architecture and training method (e.g. loss functions etc). However the analysis concentrates in the structure of the generator and the particular case of inverting scattering coefficients.\n\nHowever, I do find very interesting the analysis provided in Section 3.2. The idea of using meaningful intermediate (and stable) targets for the first two layers seems like a very good idea. Are there any practical differences in terms of quality of the results? This might show in more complex datasets.\n\nCould you please provide details on what is the dimensionality of the scattering representation at different scales? Say, how many coefficients are in S_5?\n\nIn Figure 3, it would be good to show some interpolation results for test images as well, to have a visual reference.\n\nThe authors mention that considering the network as a memory storage would allow to better recover known faces from unknown faces. It seems that it would be known from unknown images. Meaning, it is not clear why this method would generalize to novel image from the same individuals. Also, the memory would be quite rigid, as adding a new image would require adapting the generator.\n\nOther minor points:\n\nLast paragraph of page 1, “Th inverse \\Phi…” is missing the ‘e’.\n\nSome references (to figures or citations) seem to be missing, e.g. at the end of page 4, at the beginning of page 5, before equation (6). \n\nAlso, some citations should be corrected, for instance, at the end of the first paragraph of Section 3.1: \n\n“… wavelet filters Malat (2016).” \n\nSould be:\n\n“... wavelet filters (Malat, 2016).” \n\nFirst paragraph of Section 3.3. The word generator is repeated.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Analyzing GANs with Generative Scattering Networks","abstract":"GANs provide spectacular image generations from Gaussian white noise, which interpolate images through deformations, with little mathematical justifications. We show that such generators do not require to learn a discriminator or learn an embedding space. Deformation and Gaussianization properties provide strong constraints allowing to specify the embedding space operator. It is implemented with a multiscale scattering transform. The resulting generator is computed by inverting the embedding operator, with a deep convolutional network which implements a sparse inversion. This provides a statistical framework to understand estimations of generators. The resulting generative scattering networks produce images of good quality at a fraction of the computational cost and can learn from much smaller training sets. They define new classes of high-dimensional stochastic models for non-stationary and non-Gaussian processes.","pdf":"/pdf/aef590d297e1be54323030268ce041a461ded8b7.pdf","TL;DR":"We introduce Generative Convolutional Networks which do not require to learn a discriminator, and which computes the generator by inverting an embedding defined by a wavelet scattering transform.","paperhash":"anonymous|analyzing_gans_with_generative_scattering_networks","_bibtex":"@article{\n  anonymous2018analyzing,\n  title={Analyzing GANs with Generative Scattering Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1NYjfbR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper938/Authors"],"keywords":["Unsupervised Learning","Inverse Problems","Convolutional Networks","Generative Models","Scattering Transform"]}},{"tddate":null,"ddate":null,"tmdate":1512222823416,"tcdate":1511743718714,"number":2,"cdate":1511743718714,"id":"SkJxZ1FeG","invitation":"ICLR.cc/2018/Conference/-/Paper938/Official_Review","forum":"r1NYjfbR-","replyto":"r1NYjfbR-","signatures":["ICLR.cc/2018/Conference/Paper938/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Authors generate images from Gaussian noise using scattering networks. Interesting analysis of Gaussianization transforms constrained to be continuous to deformations -> Accept","rating":"8: Top 50% of accepted papers, clear accept","review":"The authors introduce scattering transforms as image generative models in the context of Generative Adversarial Networks and suggest why they could be seen as Gaussianization transforms with controlled information loss and invertibility.\nWriting is suggestive and experimental results are interesting, so I clearly recommend acceptation. \n\nI would appreciate more intuition on some claims (e.g. relation between Lipschitz continuity and wavelets) but they refer to the appropriate reference to Mallat, so this is not a major problem for the interested reader.\n\nHowever, related to the above non-intuitive claim, here is a question on a related Gaussianization transform missed by the authors that (I feel) fulfils the conditions defined in the paper but it is not obviously related to wavelets. Authors cite Chen & Gopinath (2000) and critizise that their approach suffers from the curse of dimensionality because of the ICA stage. However, other people [Laparra et al. Iterative Gaussianization from ICA to random rotations IEEE Trans.Neural Nets 2011] proved that the ICA stage is not required (but only marginal operations followed by even random rotations). That transform seems to be Lipschitz continuous as well -since it is smooth and derivable-. In fact it has been also used for image synthesis. However, it is not obviously related to wavelets... Any comment?\n\nAnother relation to previous literature: in the end, the proposed analysis (or Gaussianization) transform is basically a wavelet transform where the different scale filters are applied in a cascade (fig 1). This is similar to Gaussian Scale Mixture  models for texture analysis [Portilla & Simoncelli Int. J. Comp. Vis. 2000] in which after wavelet transform, local division is performed to obtain Gaussian variables, and these can be used to synthesize the learned textures. That is similar to Divisive Normalization models of visual neuroscience that perform similar normalization alfter wavelets to factorize the PDF (e.g. [Lyu&Simoncelli Radial Gaussianization Neur.Comput. 2009], or [Malo et al. Neur.Comput. 2010]).\n\nMinor notation issues: authors use a notation for functions that seems confusing (to me) since it looks like linear products. For instance: GZ for G(Z) [1st page] and phiX for phi(X) [2nd page] Sx for S(x) [in page 5]... \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Analyzing GANs with Generative Scattering Networks","abstract":"GANs provide spectacular image generations from Gaussian white noise, which interpolate images through deformations, with little mathematical justifications. We show that such generators do not require to learn a discriminator or learn an embedding space. Deformation and Gaussianization properties provide strong constraints allowing to specify the embedding space operator. It is implemented with a multiscale scattering transform. The resulting generator is computed by inverting the embedding operator, with a deep convolutional network which implements a sparse inversion. This provides a statistical framework to understand estimations of generators. The resulting generative scattering networks produce images of good quality at a fraction of the computational cost and can learn from much smaller training sets. They define new classes of high-dimensional stochastic models for non-stationary and non-Gaussian processes.","pdf":"/pdf/aef590d297e1be54323030268ce041a461ded8b7.pdf","TL;DR":"We introduce Generative Convolutional Networks which do not require to learn a discriminator, and which computes the generator by inverting an embedding defined by a wavelet scattering transform.","paperhash":"anonymous|analyzing_gans_with_generative_scattering_networks","_bibtex":"@article{\n  anonymous2018analyzing,\n  title={Analyzing GANs with Generative Scattering Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1NYjfbR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper938/Authors"],"keywords":["Unsupervised Learning","Inverse Problems","Convolutional Networks","Generative Models","Scattering Transform"]}},{"tddate":null,"ddate":null,"tmdate":1512222823464,"tcdate":1511730792619,"number":1,"cdate":1511730792619,"id":"H1WORsdlG","invitation":"ICLR.cc/2018/Conference/-/Paper938/Official_Review","forum":"r1NYjfbR-","replyto":"r1NYjfbR-","signatures":["ICLR.cc/2018/Conference/Paper938/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Needs to be rewritten","rating":"4: Ok but not good enough - rejection","review":"This paper addresses the important problem of understanding\nmathematically how GANs work. The approach taken here is to\nlook at GAN through the lense of the scattering transform.\n\nUnfortunately the manuscrit submitted is very poorly written.\nIntroduction and flow of thoughts is really hard to follow.\nIn method sections, the text jumps from one concept to the next without\nproper definitions.\n\nSorry I stopped reading on page 3.\n\nI suggest to rewrite this work before sending it to review.\n\nAmong many things:\n\n- For citations use citep and not citet to have () at the right places.\n\n- Why does it seems -> Why does it seem\n\netc.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Analyzing GANs with Generative Scattering Networks","abstract":"GANs provide spectacular image generations from Gaussian white noise, which interpolate images through deformations, with little mathematical justifications. We show that such generators do not require to learn a discriminator or learn an embedding space. Deformation and Gaussianization properties provide strong constraints allowing to specify the embedding space operator. It is implemented with a multiscale scattering transform. The resulting generator is computed by inverting the embedding operator, with a deep convolutional network which implements a sparse inversion. This provides a statistical framework to understand estimations of generators. The resulting generative scattering networks produce images of good quality at a fraction of the computational cost and can learn from much smaller training sets. They define new classes of high-dimensional stochastic models for non-stationary and non-Gaussian processes.","pdf":"/pdf/aef590d297e1be54323030268ce041a461ded8b7.pdf","TL;DR":"We introduce Generative Convolutional Networks which do not require to learn a discriminator, and which computes the generator by inverting an embedding defined by a wavelet scattering transform.","paperhash":"anonymous|analyzing_gans_with_generative_scattering_networks","_bibtex":"@article{\n  anonymous2018analyzing,\n  title={Analyzing GANs with Generative Scattering Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1NYjfbR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper938/Authors"],"keywords":["Unsupervised Learning","Inverse Problems","Convolutional Networks","Generative Models","Scattering Transform"]}},{"tddate":null,"ddate":null,"tmdate":1510092383907,"tcdate":1509137285978,"number":938,"cdate":1510092362089,"id":"r1NYjfbR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1NYjfbR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Analyzing GANs with Generative Scattering Networks","abstract":"GANs provide spectacular image generations from Gaussian white noise, which interpolate images through deformations, with little mathematical justifications. We show that such generators do not require to learn a discriminator or learn an embedding space. Deformation and Gaussianization properties provide strong constraints allowing to specify the embedding space operator. It is implemented with a multiscale scattering transform. The resulting generator is computed by inverting the embedding operator, with a deep convolutional network which implements a sparse inversion. This provides a statistical framework to understand estimations of generators. The resulting generative scattering networks produce images of good quality at a fraction of the computational cost and can learn from much smaller training sets. They define new classes of high-dimensional stochastic models for non-stationary and non-Gaussian processes.","pdf":"/pdf/aef590d297e1be54323030268ce041a461ded8b7.pdf","TL;DR":"We introduce Generative Convolutional Networks which do not require to learn a discriminator, and which computes the generator by inverting an embedding defined by a wavelet scattering transform.","paperhash":"anonymous|analyzing_gans_with_generative_scattering_networks","_bibtex":"@article{\n  anonymous2018analyzing,\n  title={Analyzing GANs with Generative Scattering Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1NYjfbR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper938/Authors"],"keywords":["Unsupervised Learning","Inverse Problems","Convolutional Networks","Generative Models","Scattering Transform"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}