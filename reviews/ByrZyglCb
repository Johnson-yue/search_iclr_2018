{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222588917,"tcdate":1511902551566,"number":2,"cdate":1511902551566,"id":"SygwaSixG","invitation":"ICLR.cc/2018/Conference/-/Paper205/Official_Review","forum":"ByrZyglCb","replyto":"ByrZyglCb","signatures":["ICLR.cc/2018/Conference/Paper205/AnonReviewer1"],"readers":["everyone"],"content":{"title":"The main issue I am having is what are the applicable insight from the analysis","rating":"5: Marginally below acceptance threshold","review":"This paper discusses universal perturbations - perturbations that can mislead a trained classifier if added to most of input data points. The main results are two fold: if the decision boundary are flat (such as linear classifiers), then the classifiers tend to be vulnerable to universal perturbations when the decision boundaries are correlated. If the decision boundary are curved, then vulnerability to universal perturbations is directly resulted from existence of shared direction along with the decision boundary positively curved. The authors also conducted experiments to show that deep nets produces decision boundary that satisfies the curved model.\n\nThe main issue I am having is what are the applicable insight from the analysis:\n\n1. Why is universal perturbation an important topic (as opposed to adversarial perturbation).\n2. Does the result implies that we should make the decision boundary more flat, or curved but on different directions? And how to achieve that? It might be my mis-understanding but from my reading a prescriptive procedure for universal perturbation seems not attained from the results presented.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Robustness of Classifiers to Universal Perturbations: A Geometric Perspective","abstract":"Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we provide a quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exist shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.","pdf":"/pdf/bb2ab1363c7e0f145a0706410394e5f96d920e6e.pdf","TL;DR":"Analysis of vulnerability of classifiers to universal perturbations and relation to the curvature of the decision boundary.","paperhash":"anonymous|robustness_of_classifiers_to_universal_perturbations_a_geometric_perspective","_bibtex":"@article{\n  anonymous2018robustness,\n  title={Robustness of Classifiers to Universal Perturbations: A Geometric Perspective},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByrZyglCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper205/Authors"],"keywords":["Universal perturbations","robustness","curvature"]}},{"tddate":null,"ddate":null,"tmdate":1512222588957,"tcdate":1511816123301,"number":1,"cdate":1511816123301,"id":"H17poxceM","invitation":"ICLR.cc/2018/Conference/-/Paper205/Official_Review","forum":"ByrZyglCb","replyto":"ByrZyglCb","signatures":["ICLR.cc/2018/Conference/Paper205/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The paper provides an interesting analysis linking the geometry of classifier decision boundaries to  small universal adversarial perturbations.","rating":"6: Marginally above acceptance threshold","review":"The paper is written well and clear.   The core contribution of the paper is the illustration that: under the assumption of flat, or curved decision boundaries with positive curvature small universal adversarial perturbations exist.  \n\nPros: the intuition and geometry is rather clearly presented.  \n\nCons: \nReferences to \"CaffeNet\"  and \"LeNet\" (even though the latter is well-known) are missing.  In the experimental section used to validate the main hypothesis that the deep networks have positive curvature decision boundaries, there is no description of how these networks were trained. \n\nIt is not clear why the authors have decided to use out-dated 5-layer \"LeNet\"  and NiN (Network in network) architectures instead of more recent and much better performing architectures (and less complex than NiN architectures). It would be nice to see how the behavior and boundaries look in these cases.  \n\nThe conclusion is speculative:\n\"Our analysis hence shows that to construct classifiers that are robust to universal perturbations, it\nis key to suppress this subspace of shared positive directions, which can possibly be done through\nregularization of the objective function. This will be the subject of future works.\" \n\nIt is clear that regularization should play a significant role in shaping the decision boundaries. Unfortunately, the paper does not provide details at the basic level, which algorithms,  architectures, hyper-parameters or regularization terms are used. All these factors should play a very significant role in the experimental validation of their hypothesis.\n\nNotes: I did not check the proofs of the theorems in detail. \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Robustness of Classifiers to Universal Perturbations: A Geometric Perspective","abstract":"Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we provide a quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exist shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.","pdf":"/pdf/bb2ab1363c7e0f145a0706410394e5f96d920e6e.pdf","TL;DR":"Analysis of vulnerability of classifiers to universal perturbations and relation to the curvature of the decision boundary.","paperhash":"anonymous|robustness_of_classifiers_to_universal_perturbations_a_geometric_perspective","_bibtex":"@article{\n  anonymous2018robustness,\n  title={Robustness of Classifiers to Universal Perturbations: A Geometric Perspective},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByrZyglCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper205/Authors"],"keywords":["Universal perturbations","robustness","curvature"]}},{"tddate":null,"ddate":null,"tmdate":1509739430465,"tcdate":1509060349393,"number":205,"cdate":1509739427809,"id":"ByrZyglCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"ByrZyglCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Robustness of Classifiers to Universal Perturbations: A Geometric Perspective","abstract":"Deep networks have recently been shown to be vulnerable to universal perturbations: there exist very small image-agnostic perturbations that cause most natural images to be misclassified by such classifiers. In this paper, we provide a quantitative analysis of the robustness of classifiers to universal perturbations, and draw a formal link between the robustness to universal perturbations, and the geometry of the decision boundary. Specifically, we establish theoretical bounds on the robustness of classifiers under two decision boundary models (flat and curved models). We show in particular that the robustness of deep networks to universal perturbations is driven by a key property of their curvature: there exist shared directions along which the decision boundary of deep networks is systematically positively curved. Under such conditions, we prove the existence of small universal perturbations. Our analysis further provides a novel geometric method for computing universal perturbations, in addition to explaining their properties.","pdf":"/pdf/bb2ab1363c7e0f145a0706410394e5f96d920e6e.pdf","TL;DR":"Analysis of vulnerability of classifiers to universal perturbations and relation to the curvature of the decision boundary.","paperhash":"anonymous|robustness_of_classifiers_to_universal_perturbations_a_geometric_perspective","_bibtex":"@article{\n  anonymous2018robustness,\n  title={Robustness of Classifiers to Universal Perturbations: A Geometric Perspective},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=ByrZyglCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper205/Authors"],"keywords":["Universal perturbations","robustness","curvature"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}