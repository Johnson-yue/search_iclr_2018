{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222728211,"tcdate":1512112472182,"number":3,"cdate":1512112472182,"id":"rkevbtAgf","invitation":"ICLR.cc/2018/Conference/-/Paper715/Official_Review","forum":"BkM3ibZRW","replyto":"BkM3ibZRW","signatures":["ICLR.cc/2018/Conference/Paper715/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Very nice paper, very clearly presented, on using a learned distribution to regularize the embedding space of a discrete-space autoencoder. ","rating":"9: Top 15% of accepted papers, strong accept","review":"The authors present a new variation of autoencoder, in which they jointly train (1) a discrete-space autoencoder to minimize reconstuction loss, and (2) a simpler continuous-space generator function to learn a distribution for the codes, and (3) a GAN formulation to constrain the distributions in the latent space to be similar.\n\nThe paper is very clearly written, very clearly presented, addresses an important issue, and the results are solid.\n\nMy primary suggestion is that I would like to know a lot more (even qualitatively, does not need to be extensively documented runs) about how sensitive the results were--- and in what ways were they sensitive--- to various hyperparameters. Currently, the authors mention in the conclusion that, as is known to often be the case with GANS, that the results were indeed sensitive. More info on this throughout the paper would be a valuable contribution. Clearly the authors were able to make it work, with good results. When does it not work? Any observations about how it breaks down?\n\nIt is interesting how strong the denoising effect is, as simply a byproduct of the adversarial regularization.\n\nSome of the results are quite entertaining indeed. I found the yelp transfer results particularly impressive.\n\n(The transfer from positive->negative on an ambiguous example was interesting: Original \"service is good but not quick\" -> \"service is good but not quick, but the service is horrible\", and \"service is good, and horrible, is the same and worst time ever\". I found it interesting to see what it does with the mixed signals of the word \"but\": on one hand, keeping it helps preserve the structure of the sentence, but on the other hand, keeping it makes it hard to flip the valence. I guess the most accurate opposite would have been \"The service is quick but not good\"... )\n\nI really like the reverse perplexity measure. Also, it was interesting how that was found to be high on AAE due to mode-collapse.\n\nBeyond that, I only have a list of very insignificant typos:\n-p3, end of S3, \"this term correspond to minimizing\"\n-p3, S4, \"to approximate Wasserstein-1 term\" --> \"to approximate the Wasserstein-1 term\"\n-Figure 1, caption \"which is similarly decoded to $\\mathbf{\\~x}$\" . I would say that it is \"similarly decoded to $\\mathbf{c}$\", since it is \\mathbf{c} that gets decoded. Unless the authors meant that it \"is similarly decoded to produce $\\mathbf{\\~x}$. Alternately, I would just say something like \"to produce a code vector, which lies in the same space as \\mathbf{c}\", since the decoding of the generated code vector does not seem to be particularly relevant right here.\n\n-p5, beginning of Section 6.1:  \"to regularize the model produce\" --> \"to regularize the model to produce\" ?\n-p6, end of first par. \"is quite high for the ARAE than in the case\" --> quite a bit higher than? etc...\n-p7, near the bottom \"shown in figure 6\". --> table, not figure...\n-p8  \"ability mimic\" -->\"ability to mimic\"\n-p9 Fig 3 -- the caption is mismatched with the figure.. top/bottom/left/right/etc.... Something is confusing there...\n-p9 near the bottom \"The model learns a improved\" --> \"The model learns an improved\"\n-p14 left side, 4th cell up, \"Cross-AE\"-->\"ARAE\"\n\nThis is a very nice paper with a clear idea (regularize discrete autoencoder using a flexible rather than a fixed prior), that makes good sense and is very clearly presented. \n\nIn the words of one of the paper's own examples: \"It has a great atmosphere, with wonderful service.\" :)\nStill, I wouldn't mind knowing a little more about what happened in the kitchen...\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarially Regularized Autoencoders","abstract":"While autoencoders are a key technique in representation learning for continuous structures, such as images or wave forms, developing general-purpose autoencoders for discrete structures, such as text sequence or discretized images, has proven to be more challenging. In particular, discrete inputs make it more difficult to learn a smooth encoder that preserves the complex local relationships in the input space. In this work, we propose an adversarially regularized autoencoder (ARAE) with the goal of learning more robust discrete-space representations. ARAE jointly trains both a rich discrete-space encoder, such as an RNN, and a simpler continuous space generator function, while using generative adversarial network (GAN) training to constrain the distributions to be similar. This method yields a smoother contracted code space that maps similar inputs to nearby codes, and also an implicit latent variable GAN model for generation. Experiments on text and discretized images demonstrate that the GAN model produces clean interpolations and captures the multimodality of the original space, and that the autoencoder produces improvements in semi-supervised learning as well as state-of-the-art results in unaligned text style transfer task using only a shared continuous-space representation.","pdf":"/pdf/c6018a1358f0b0242e02f3f51a42bb30b889bb01.pdf","TL;DR":"Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.","paperhash":"anonymous|adversarially_regularized_autoencoders","_bibtex":"@article{\n  anonymous2018adversarially,\n  title={Adversarially Regularized Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BkM3ibZRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper715/Authors"],"keywords":["representation learning","natural language generation","discrete structure modeling","adversarial training","unaligned text style-transfer"]}},{"tddate":null,"ddate":null,"tmdate":1512222728290,"tcdate":1512018090036,"number":2,"cdate":1512018090036,"id":"rkzhgMpgM","invitation":"ICLR.cc/2018/Conference/-/Paper715/Official_Review","forum":"BkM3ibZRW","replyto":"BkM3ibZRW","signatures":["ICLR.cc/2018/Conference/Paper715/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Good paper but disregards formatting suggestions, making fair evaluation impossible","rating":"3: Clear rejection","review":"This paper introduces a model for learning robust discrete-space representations with autoencoders. The proposed method jointly trains an RNN encoder with a GAN to produce latent representations which are designed to better encode similarity in the discrete input space. A variety of experiments are conducted that demonstrate the efficacy of the proposed methodology.\n\nGenerally speaking, I like the overall idea, which, as far as I know, is a novel approach for dealing with discrete inputs. The generated textual samples look good and offer strong support for the model. However, I would have preferred to see more quantitative evaluation and less qualitative evaluation, but I understand that doing so is challenging in this domain.\n\nI will refrain from adding additional detailed commentary in this review because I am unable to judge this paper fairly with respect to other submissions owing to its large deviation from the suggested length limits. The call for papers states that \"we strongly recommend keeping the paper at 8 pages\", yet the current submission extends well into its 10th page. In addition (and more importantly), the margins appear to have been reduced relative to the standard latex template. Altogether, it seems like this paper contains a significant amount of additional text beyond what other submissions enjoyed. I see no strong reason why this particular paper needed the extra space. In fact, there are obvious places where the exposition is excessively verbose, and there are clear opportunities to reduce the length of the submission. While I fully understand that the length suggestions are not requirements, in my opinion this paper did not make an adequate effort to abide by these suggestions. Moreover, as a result, I believe this extra length has earned this paper an unfair advantage relative to other submissions, which themselves may have removed important content in order to abide by the length suggestions. As such, I find it difficult or impossible to judge this paper fairly relative to other submissions. I regrettably cannot recommend this paper for acceptance owing to these concerns.\n\nThere are many good ideas and experiments in this paper and I would strongly encourage the authors to resubmit this work to a future conference, making sure to reorganize the paper to adhere to the relevant formatting guidelines.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarially Regularized Autoencoders","abstract":"While autoencoders are a key technique in representation learning for continuous structures, such as images or wave forms, developing general-purpose autoencoders for discrete structures, such as text sequence or discretized images, has proven to be more challenging. In particular, discrete inputs make it more difficult to learn a smooth encoder that preserves the complex local relationships in the input space. In this work, we propose an adversarially regularized autoencoder (ARAE) with the goal of learning more robust discrete-space representations. ARAE jointly trains both a rich discrete-space encoder, such as an RNN, and a simpler continuous space generator function, while using generative adversarial network (GAN) training to constrain the distributions to be similar. This method yields a smoother contracted code space that maps similar inputs to nearby codes, and also an implicit latent variable GAN model for generation. Experiments on text and discretized images demonstrate that the GAN model produces clean interpolations and captures the multimodality of the original space, and that the autoencoder produces improvements in semi-supervised learning as well as state-of-the-art results in unaligned text style transfer task using only a shared continuous-space representation.","pdf":"/pdf/c6018a1358f0b0242e02f3f51a42bb30b889bb01.pdf","TL;DR":"Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.","paperhash":"anonymous|adversarially_regularized_autoencoders","_bibtex":"@article{\n  anonymous2018adversarially,\n  title={Adversarially Regularized Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BkM3ibZRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper715/Authors"],"keywords":["representation learning","natural language generation","discrete structure modeling","adversarial training","unaligned text style-transfer"]}},{"tddate":null,"ddate":null,"tmdate":1512222728338,"tcdate":1511880890969,"number":1,"cdate":1511880890969,"id":"S1Q6dxjlz","invitation":"ICLR.cc/2018/Conference/-/Paper715/Official_Review","forum":"BkM3ibZRW","replyto":"BkM3ibZRW","signatures":["ICLR.cc/2018/Conference/Paper715/AnonReviewer3"],"readers":["everyone"],"content":{"title":"interesting idea; maybe helpful to present more intuition","rating":"6: Marginally above acceptance threshold","review":"the paper presents a way to encode discrete distributions which is a challenging problem. they propose to use a latent variable gan with one continuous encoding and one discrete encoding. \n\ntwo questions linger around re practices:\n1. gan is known to struggle with discriminating distributions with different supports. the problem also persists here as the gan is discriminating between a continuous and a discrete distribution.  it'll interesting to see how the proposed approach gets around this issue.\n\n2. the second question is related. it is unclear how the optimal distribution would look like with the latent variable gan. ideally, the discrete encoding be simply a discrete approximation of the continuous encoding. but optimization with two latent distributions and one discriminator can be hard. what we get in practice is pretty unclear. also how this could outperform classical discrete autoencoders is unclear. gan is an interesting idea to apply to solve many problems; it'll be helpful to get the intuition of which properties of gan solves the problem in this particular application to discrete autoencoders.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Adversarially Regularized Autoencoders","abstract":"While autoencoders are a key technique in representation learning for continuous structures, such as images or wave forms, developing general-purpose autoencoders for discrete structures, such as text sequence or discretized images, has proven to be more challenging. In particular, discrete inputs make it more difficult to learn a smooth encoder that preserves the complex local relationships in the input space. In this work, we propose an adversarially regularized autoencoder (ARAE) with the goal of learning more robust discrete-space representations. ARAE jointly trains both a rich discrete-space encoder, such as an RNN, and a simpler continuous space generator function, while using generative adversarial network (GAN) training to constrain the distributions to be similar. This method yields a smoother contracted code space that maps similar inputs to nearby codes, and also an implicit latent variable GAN model for generation. Experiments on text and discretized images demonstrate that the GAN model produces clean interpolations and captures the multimodality of the original space, and that the autoencoder produces improvements in semi-supervised learning as well as state-of-the-art results in unaligned text style transfer task using only a shared continuous-space representation.","pdf":"/pdf/c6018a1358f0b0242e02f3f51a42bb30b889bb01.pdf","TL;DR":"Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.","paperhash":"anonymous|adversarially_regularized_autoencoders","_bibtex":"@article{\n  anonymous2018adversarially,\n  title={Adversarially Regularized Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BkM3ibZRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper715/Authors"],"keywords":["representation learning","natural language generation","discrete structure modeling","adversarial training","unaligned text style-transfer"]}},{"tddate":null,"ddate":null,"tmdate":1509739144977,"tcdate":1509133226424,"number":715,"cdate":1509739142308,"id":"BkM3ibZRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BkM3ibZRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Adversarially Regularized Autoencoders","abstract":"While autoencoders are a key technique in representation learning for continuous structures, such as images or wave forms, developing general-purpose autoencoders for discrete structures, such as text sequence or discretized images, has proven to be more challenging. In particular, discrete inputs make it more difficult to learn a smooth encoder that preserves the complex local relationships in the input space. In this work, we propose an adversarially regularized autoencoder (ARAE) with the goal of learning more robust discrete-space representations. ARAE jointly trains both a rich discrete-space encoder, such as an RNN, and a simpler continuous space generator function, while using generative adversarial network (GAN) training to constrain the distributions to be similar. This method yields a smoother contracted code space that maps similar inputs to nearby codes, and also an implicit latent variable GAN model for generation. Experiments on text and discretized images demonstrate that the GAN model produces clean interpolations and captures the multimodality of the original space, and that the autoencoder produces improvements in semi-supervised learning as well as state-of-the-art results in unaligned text style transfer task using only a shared continuous-space representation.","pdf":"/pdf/c6018a1358f0b0242e02f3f51a42bb30b889bb01.pdf","TL;DR":"Adversarially Regularized Autoencoders learn smooth representations of discrete structures allowing for interesting results in text generation, such as unaligned style transfer, semi-supervised learning, and latent space interpolation and arithmetic.","paperhash":"anonymous|adversarially_regularized_autoencoders","_bibtex":"@article{\n  anonymous2018adversarially,\n  title={Adversarially Regularized Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BkM3ibZRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper715/Authors"],"keywords":["representation learning","natural language generation","discrete structure modeling","adversarial training","unaligned text style-transfer"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}