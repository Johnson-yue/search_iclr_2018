{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222795043,"tcdate":1511860208682,"number":3,"cdate":1511860208682,"id":"rJtlOoqlG","invitation":"ICLR.cc/2018/Conference/-/Paper841/Official_Review","forum":"HJC2SzZCW","replyto":"HJC2SzZCW","signatures":["ICLR.cc/2018/Conference/Paper841/AnonReviewer1"],"readers":["everyone"],"content":{"title":"The paper is poorly organized, the presented analysis is hard to read, the obtained results (and mainly all figures) are unclear. ","rating":"2: Strong rejection","review":"This paper proposes an analysis of the robustness of deep neural networks with respect to data perturbations. \n\n*Quality*\nThe quality of exposition is not satisfactory. Actually, the paper is pretty difficult to evaluate at the present stage and it needs a drastic change in the writing style.\n\n*Clarity*\nThe paper is not clear and highly unstructured.\n\n*Originality* \nThe originality is limited for what regards Section 3: the proposed metrics are quite standard tools from differential geometry. Also, the idea of taking into account the data manifold is not brand new since already proposed in “Universal Adversarial Perturbation” at CVPR 2017.\n\n*Significance*\nDue to some flaws in the experimental settings, the relevance of the presented results is very limited. First, the authors essentially exploit a customized architecture, which has been broadly fine-tuned regarding hyper-parameters, gating functions and optimizers. Why not using well established architectures (such as DenseNets, ResNets, VGG, AlexNet)? \nMoreover, despite having a complete portrait of the fine-tuning process is appreciable, this compromises the clarity of the figures which are pretty hard to interpret and absolutely not self-explanatory: probably it’s better to only consider the best configuration as opposed to all the possible ones.\nSecond, authors assume that circular interpolation is a viable way to traverse the data manifold. The reviewer believes that it is an over-simplistic assumption. In fact, it is not guaranteed a priori that such trajectories are geodesic curves so, a priori, it is not clear why this could be a sound technique to explore the data manifold.\n\nCONS:\nThe paper is difficult to read and needs to be thoroughly re-organized. The problem is not stated in a clear manner, and paper’s contribution is not outlined. The proposed architectures should be explained in detail. The results of the sensitivity analysis should be discussed in detail. The authors should explain the approach of traversing the data manifold with ellipses (although the reviewer believes that such approach needs to be changed with something more principled). Figures and results are not clear.\nThe authors are kindly asked to shape their paper to match the suggested format of 8 pages + 1 of references (or similar). The work is definitely too long considered its quality. Additional plots and discussion can be moved to an appendix.\nDespite the additional explanation in Footnote 6, the graphs are not clear. Probably authors should avoid to present the result for each possible configuration of the hyper-parameters, gatings and optimizers and just choose the best setting.\nApart from the customized architecture, authors should have considered established deep nets, such as DenseNets, ResNets, VGG, AlexNet.\nThe idea of considering the data manifold within the measurement of complexity is a nice claim, which unfortunately is paired with a not convincing experimental analysis. Why ellipses should be a proper way to explore the data manifold? In general, circular interpolation is not guaranteed to be geodesic curves which lie on the data manifold.\n\nMinor Comments: \nSentence to rephrase: “We study common in the machine learning community ways to ...”\nPlease, put the footnotes in the corresponding page in which it is referred.\nThe reference to ReLU is trivially wrong and need to be changed with [Nair & Hinton ICML 2010]","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Sensitivity and Generalization in Neural Networks","abstract":"In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with different architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.\n\nWe find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the input-output Jacobian of the network, and that this correlates well with generalization. We further establish that factors associated with poor generalization -- such as full-batch training or using random labels -- correspond to higher sensitivity, while factors associated with good generalization  -- such as data augmentation and ReLU non-linearities -- give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points.","pdf":"/pdf/d92f9cebe834a5d3ca127f8858288b974b8d5359.pdf","TL;DR":"We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.","paperhash":"anonymous|sensitivity_and_generalization_in_neural_networks","_bibtex":"@article{\n  anonymous2018sensitivity,\n  title={Sensitivity and Generalization in Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJC2SzZCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper841/Authors"],"keywords":["generalization","complexity","experimental study","linear regions","Jacobian"]}},{"tddate":null,"ddate":null,"tmdate":1512222795091,"tcdate":1511794265811,"number":2,"cdate":1511794265811,"id":"rJzvIiKlf","invitation":"ICLR.cc/2018/Conference/-/Paper841/Official_Review","forum":"HJC2SzZCW","replyto":"HJC2SzZCW","signatures":["ICLR.cc/2018/Conference/Paper841/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting experimental setting and validation metrics. Unclear presentation and modelling rationale","rating":"5: Marginally below acceptance threshold","review":"This work investigates sensitivity and generalisation properties of neural networks with respect to a number of metrics aimed at quantifying the robustness with respect to data variability, varying parameters and representativity of training/testing data. \nThe validation is based on the Jacobian of the network, and in the detection of the “transitions” associated to the data space. These measures are linked, as the former quantifies the sensitivity of the network respect to infinitesimal data variations, while the latter quantifies the complexity of the modelled data space. \nThe study explores a number of experimental setting, where the behaviour of the network is analysed on synthetic paths around training data, from pure random data points, to curves interpolating different/same data classes.\nThe experimental results are performed on CIFAR10,CIFAR100, and MNIST. Highly-parameterised networks seem to offer a better generalisation, while lower Jacobian norm are usually associated to better generalisation and fewer transitions, and can be obtained with data augmentation.\n\nThe paper proposes an interesting analysis aimed at the empirical exploration of neural network properties, the proposed metrics provide relevant insights to understand the behaviour of a network under varying data points. \n\nMajor remarks.\n\nThe proposed investigation is to my opinion quite controversial. Interesting data variation does not usually corresponds to linear data change. When considering the linear interpolation of training data, the authors are actually creating data instances not compatible with the original data source: for example, the pixel-wise intensity average of digits is not a digit anymore. For this reason, the conclusions drawn about the model sensitivity are to my opinion based a potentially uninteresting experimental context. Meaningful data variation can be way more complex and high-dimensional, for example by considering spatial warps of digits, or occlusions and superpositions of natural images. This kind of variability is likely to correspond to real data changes, and may lead to more reliable conclusions. For this reason, the proposed results may provide little indications of the true behaviour of the models data in case of meaningful  data variations. \n\nMoreover, although performed within a cross-validation setting, training and testing are still applied to the same dataset. Cross-validation doesn’t rule out validation bias, while it is also known that the classification performance significantly drops when applied to independent “unseen” data, provided for example in different cohorts. I would expect that highly parameterised models would lead to worse performance when applied to genuinely independent cohorts, and I believe that this work should extend the investigation to this experimental setting.\n\nMinor remarks.\n\nThe authors should revise the presentation of the proposed work. The 14 figures(!) of main text are not presented in the order of appearance. The main one (figure 1) is provided in the first paragraph of the introduction and never discussed in the rest of the paper. \n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Sensitivity and Generalization in Neural Networks","abstract":"In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with different architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.\n\nWe find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the input-output Jacobian of the network, and that this correlates well with generalization. We further establish that factors associated with poor generalization -- such as full-batch training or using random labels -- correspond to higher sensitivity, while factors associated with good generalization  -- such as data augmentation and ReLU non-linearities -- give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points.","pdf":"/pdf/d92f9cebe834a5d3ca127f8858288b974b8d5359.pdf","TL;DR":"We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.","paperhash":"anonymous|sensitivity_and_generalization_in_neural_networks","_bibtex":"@article{\n  anonymous2018sensitivity,\n  title={Sensitivity and Generalization in Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJC2SzZCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper841/Authors"],"keywords":["generalization","complexity","experimental study","linear regions","Jacobian"]}},{"tddate":null,"ddate":null,"tmdate":1512222795135,"tcdate":1511780494992,"number":1,"cdate":1511780494992,"id":"HkwqeuYeG","invitation":"ICLR.cc/2018/Conference/-/Paper841/Official_Review","forum":"HJC2SzZCW","replyto":"HJC2SzZCW","signatures":["ICLR.cc/2018/Conference/Paper841/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The authors present a large scale empirical evaluation on sensitivity and generalization for DNNs within the scope of image classification. They convincingly present strong empirical evidence for the F-norm of the input-output Jacobian to be predictive/informative of generalization with large scale DNNs.","rating":"8: Top 50% of accepted papers, clear accept","review":"The authors have undertaken a large scale empirical evaluation on sensitivity and generalization for DNNs within the scope of image classification. They are investigating the suitability of the F-norm of the input-output Jacobian in large scale DNNs and they evaluate sensitivity and generalization metrics across the input space, both on and of the data manifold. They convincingly present strong empirical evidence for the F-norm of the Jacobian to be predictive and informative of generalization of the DNN within the image classification domain.\n\nThe paper is well written. The problem is clearly presented and motivated. Most potential questions of a reader as well as interesting details are supplied by footnotes and the appendix.\nThe contributions are to my knowledge both novel and significant.\nThe paper seem to be technically correct. The methodology and conclusions are reasonable.\nI believe that this is important work and applaud the authors for undertaking it. I hope that the interesting leads will be further investigated and that similar studies will be conducted beyond the scope of image classification. '\nThe research and further investigations would be strengthened if they would include a survey on the networks presented in the literature in a similar manner as the authors did with the generated networks within the presented study. For example compare networks from benchmark competitions in terms of sensitivity and generalization using the metrics presented here.\n\nPlease define \"generalization gap\" and show how you calculate/estimate it. The term us used differently in much of the machine learning literature(?). Given this and that the usually sought after generalization error is unobtainable due to the unknown joint distribution over data and label, it is necessary to clarify the precise meaning of \"generalization gap\" and how you calculated it. I intuitively understand but I am not sure that the metric I have in mind is the same as the one you use. Such clarification will also improve the accessibility for a wider audience.\n\nFigure 4:\nI find Figure 4:Center a bit confusion. Is it there to show where on the x-axis of Figure 4:Top,the three points are located? Does this mean that the points are not located at pi/3, pi, 5pi/3 as indicated in the figure and the vertical lines of the figure grid? If it is not, then is it maybe possible to make the different sub-figure in Figure 4 more distinctive, as to not visually float into each other?\n\nFigure 5:\nThe figure makes me curious about what the regions look like close to the training points, which is currently hidden by the content of the inset squares. Maybe the square content can be made fully transparent so that only the border is kept? The three inset squares could be shown right below each sub-figure, aligned at the x-axis with the respective position of each of the data points.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Sensitivity and Generalization in Neural Networks","abstract":"In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with different architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.\n\nWe find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the input-output Jacobian of the network, and that this correlates well with generalization. We further establish that factors associated with poor generalization -- such as full-batch training or using random labels -- correspond to higher sensitivity, while factors associated with good generalization  -- such as data augmentation and ReLU non-linearities -- give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points.","pdf":"/pdf/d92f9cebe834a5d3ca127f8858288b974b8d5359.pdf","TL;DR":"We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.","paperhash":"anonymous|sensitivity_and_generalization_in_neural_networks","_bibtex":"@article{\n  anonymous2018sensitivity,\n  title={Sensitivity and Generalization in Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJC2SzZCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper841/Authors"],"keywords":["generalization","complexity","experimental study","linear regions","Jacobian"]}},{"tddate":null,"ddate":null,"tmdate":1509739071637,"tcdate":1509135798378,"number":841,"cdate":1509739068973,"id":"HJC2SzZCW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJC2SzZCW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Sensitivity and Generalization in Neural Networks","abstract":"In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with different architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.\n\nWe find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the input-output Jacobian of the network, and that this correlates well with generalization. We further establish that factors associated with poor generalization -- such as full-batch training or using random labels -- correspond to higher sensitivity, while factors associated with good generalization  -- such as data augmentation and ReLU non-linearities -- give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points.","pdf":"/pdf/d92f9cebe834a5d3ca127f8858288b974b8d5359.pdf","TL;DR":"We perform massive experimental studies characterizing the relationships between Jacobian norms, linear regions, and generalization.","paperhash":"anonymous|sensitivity_and_generalization_in_neural_networks","_bibtex":"@article{\n  anonymous2018sensitivity,\n  title={Sensitivity and Generalization in Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJC2SzZCW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper841/Authors"],"keywords":["generalization","complexity","experimental study","linear regions","Jacobian"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}