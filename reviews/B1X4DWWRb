{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222719729,"tcdate":1511804624315,"number":3,"cdate":1511804624315,"id":"ryOA0TKgG","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Good theoretical results, more empirical evaluations can improve the paper","rating":"7: Good paper, accept","review":"Summary:\nThis paper proposes a new approach to tackle the problem of prediction under\nthe shift in design, which consists of the shift in policy (conditional\ndistribution of treatment given features) and the shift in domain (marginal \ndistribution of features).\n\nGiven labeled samples from a source domain and unlabeled samples from a target\ndomain, this paper proposes to minimize the risk on the target domain by \njointly learning the shift-invariant representation and the re-weighting \nfunction for the induced representations. According to Lemma 1 and its finite\nsample version in Theorem 1, the risk on the target domain can be upper bounded\nby the combination of 1) the re-weighted empirical risk on the source domain; \nand 2) the distributional discrepancy between the re-weighted source domain and\nthe target domain. These theoretical results justify the objective function\nshown in Equation 8. \n\nExperiments on the IHDP dataset demonstrates the advantage of the proposed\napproach compared to its competing alternatives.\n\nComments:\n1) This paper is well motivated. For the task of prediction under the shift in\ndesign, shift-invariant representation learning (Shalit 2017) is biased even in\nthe inifite data limit. On the other hand, although re-weighting methods are\nunbiased, they suffer from the drawbacks of high variance and unknown optimal\nweights. The proposed approach aims to overcome these drawbacks.\n\n2) The theoretical results justify the optimization procedures presented in\nsection 5. Experimental results on the IHDP dataset confirm the advantage of\nthe proposed approach.\n\n3) I have some questions on the details. In order to make sure the second \nequality in Equation 2 holds, p_mu (y|x,t) = p_pi (y|x,t) should hold as well.\nIs this a standard assumption in the literature?\n\n4) Two drawbacks of previous methods motivate this work, including the bias of\nrepresentation learning and the high variance of re-weighting. According to\nLemma 1, the proposed method is unbiased for the optimal weights in the large\ndata limit. However, is there any theoretical guarantee or empirical evidence\nto show the proposed method does not suffer from the drawback of high variance?\n\n5) Experiments on synthetic datasets, where both the shift in policy and the\nshift in domain are simulated and therefore can be controlled, would better \ndemonstrate how the performance of the proposed approach (and thsoe baseline \nmethods) changes as the degree of design shift varies. \n\n6) Besides IHDP, did the authors run experiments on other real-world datasets, \nsuch as Jobs, Twins, etc?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a family of algorithms to address these issues, by jointly learning a representation and a re-weighting of observed data. We show that our algorithms minimize an upper bound on the generalization error under design shift, and verify the effectiveness of this approach in causal effect estimation.","pdf":"/pdf/d48ea9ecb98004b71c8d43de7d87169d13415f38.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1512222719765,"tcdate":1511519763052,"number":2,"cdate":1511519763052,"id":"ByozI_rlG","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Deep architecture for shift invariance in predictive modeling","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper proposes a deep learning architecture for joint learning of feature representation, a target-task mapping function, and a sample re-weighting function. Specifically, the method tries to discover feature representations, which are invariance in different domains, by minimizing the re-weighted empirical risk and distributional shift between designs.\nOverall, the paper is well written and organized with good description on the related work, research background, and theoretic proofs. \n\nThe main contribution can be the idea of learning a sample re-weighting function, which is highly important in domain shift. However, as stated in the paper, since the causal effect of an intervention T on Y conditioned on X is one of main interests, it is expected to add the related analysis in the experiment section.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a family of algorithms to address these issues, by jointly learning a representation and a re-weighting of observed data. We show that our algorithms minimize an upper bound on the generalization error under design shift, and verify the effectiveness of this approach in causal effect estimation.","pdf":"/pdf/d48ea9ecb98004b71c8d43de7d87169d13415f38.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1512222719850,"tcdate":1511261917342,"number":1,"cdate":1511261917342,"id":"H1HywYblM","invitation":"ICLR.cc/2018/Conference/-/Paper685/Official_Review","forum":"B1X4DWWRb","replyto":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference/Paper685/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Reweighting for causal inference in absence of confounding","rating":"5: Marginally below acceptance threshold","review":"The paper proposes a novel way of causal inference in situations where in causal SEM notation the outcome Y = f(T,X) is a function of a treatment T and covariates X. The goal is to infer the treatment effect E(Y|T=1,X=x) - E(Y|T=0,X=x) for binary treatments at every location x. If the treatment effect can be learned, then forecasts of Y under new policies that assign treatment conditional on X will still \"work\" and the distribution of X can also change without affecting the accuracy of the predictions. \n\nWhat is proposed seems to be twofold:\n- instead of using a standard inverse probability weighting, the authors construct a bound for the prediction performance under new distributions of X and new policies and learn the weights by optimizing this bound. The goal is to avoid issues that arise if the ratio between source and target densities become very large or small and the weights in a standard approach would become very sparse, thus leading to a small effective sample size.\n- as an additional ingredient the authors also propose \"representation learning\" by mapping x to some representation Phi(x). \nThe goal is to learn the mapping Phi (and its inverse) and the weighting function simultaneously by optimizing the derived bound on the prediction performance. \n\nPros: \n- The problem is relevant and also appears in similar form in domain adaptation and transfer learning. \n- The derived bounds and procedures are interesting and nontrivial, even if there is some overlap with earlier work of Shalit et al. \n\nCons:\n- I am not sure if ICLR is the optimal venue for this manuscript but will leave this decision to others. \n- The manuscript is written in a very compact style and I wish some passages would have been explained in more depth and detail. Especially the second half of page 5 is at times very hard to understand as it is so dense. \n- The implications of the assumptions in Theorem 1 are not easy to understand, especially relating to the quantities B_\\Phi, C^\\mathcal{F}_{n,\\delta} and D^{\\Phi,\\mathcal{H}}_\\delta. Why would we expect these quantities to be small or bounded? How does that compare to the assumptions needed for standard inverse probability weighting? \n- I appreciate that it is difficult to find good test datasets for evaluating causal estimator.  The experiment on the semi-synthetic IHDP dataset is ok, even though there is very little information about its structure in the manuscript (even basic information like number of instances or dimensions seems missing?). The example does not provide much insight into the main ideas and when we would expect the procedure to work more generally.\n\n\n\n\n\n\n\n\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a family of algorithms to address these issues, by jointly learning a representation and a re-weighting of observed data. We show that our algorithms minimize an upper bound on the generalization error under design shift, and verify the effectiveness of this approach in causal effect estimation.","pdf":"/pdf/d48ea9ecb98004b71c8d43de7d87169d13415f38.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]}},{"tddate":null,"ddate":null,"tmdate":1509739160478,"tcdate":1509132074617,"number":685,"cdate":1509739157817,"id":"B1X4DWWRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"B1X4DWWRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Weighted Representations for Generalization Across Designs","abstract":"Predictive models that generalize well under distributional shift are often desirable and sometimes crucial to machine learning applications. One example is the estimation of treatment effects from observational data, where a subtask is to predict the effect of a treatment on subjects that are systematically different from those who received the treatment in the data. A related kind of distributional shift appears in unsupervised domain adaptation, where we are tasked with generalizing to a distribution of inputs that is different from the one in which we observe labels. We pose both of these problems as prediction under a shift in design. Popular methods for overcoming distributional shift are often heuristic or rely on assumptions that are rarely true in practice, such as having a well-specified model or knowing the policy that gave rise to the observed data. Other methods are hindered by their need for a pre-specified metric for comparing observations, or by poor asymptotic properties. In this work, we devise a family of algorithms to address these issues, by jointly learning a representation and a re-weighting of observed data. We show that our algorithms minimize an upper bound on the generalization error under design shift, and verify the effectiveness of this approach in causal effect estimation.","pdf":"/pdf/d48ea9ecb98004b71c8d43de7d87169d13415f38.pdf","TL;DR":"A theory and algorithmic framework for prediction under distributional shift, including causal effect estimation and domain adaptation","paperhash":"anonymous|learning_weighted_representations_for_generalization_across_designs","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Weighted Representations for Generalization Across Designs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=B1X4DWWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper685/Authors"],"keywords":["Distributional shift","causal effects","domain adaptation"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}