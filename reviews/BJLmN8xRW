{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222610391,"tcdate":1511815180860,"number":3,"cdate":1511815180860,"id":"S1SG_l5gz","invitation":"ICLR.cc/2018/Conference/-/Paper273/Official_Review","forum":"BJLmN8xRW","replyto":"BJLmN8xRW","signatures":["ICLR.cc/2018/Conference/Paper273/AnonReviewer1"],"readers":["everyone"],"content":{"title":"-","rating":"4: Ok but not good enough - rejection","review":"This paper proposes to automatically recognize domain names as malicious or benign by deep networks (convnets and RNNs) trained to directly classify the character sequence as such.\n\n\nPros\n\nThe paper addresses an important application of deep networks, comparing the performance of a variety of different types of model architectures.\n\nThe tested networks seem to perform reasonably well on the task.\n\n\nCons\n\nThere is little novelty in the proposed method/models -- the paper is primarily focused on comparing existing models on a new task.\n\nThe descriptions of the different architectures compared are overly verbose -- they are all simple standard convnet / RNN architectures.  The code specifying the models is also excessive for the main text -- it should be moved to an appendix or even left for a code release.\n\nThe comparisons between various architectures are not very enlightening as they aren’t done in a controlled way -- there are a large number of differences between any pair of models so it’s hard to tell where the performance differences come from. It’s also difficult to compare the learning curves among the different models (Fig 1) as they are in separate plots with differently scaled axes.\n\nThe proposed problem is an explicitly adversarial setting and adversarial examples are a well-known issue with deep networks and other models, but this issue is not addressed or analyzed in the paper. (In fact, the intro claims this is an advantage of not using hand-engineered features for malicious domain detection, seemingly ignoring the literature on adversarial examples for deep nets.) For example, in this case an attacker could start with a legitimate domain name and use black box adversarial attacks (or white box attacks, given access to the model weights) to derive a similar domain name that the models proposed here would classify as benign.\n\n\nWhile this paper addresses an important problem, in its current form the novelty and analysis are limited and the paper has some presentation issues.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Character Level Based Detection of DGA Domain Names","abstract":"Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Little studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and less prone to overfitting.","pdf":"/pdf/27da53dc5430b961ffbf4ba7504c654d034fc414.pdf","TL;DR":"A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.","paperhash":"anonymous|character_level_based_detection_of_dga_domain_names","_bibtex":"@article{\n  anonymous2018character,\n  title={Character Level Based Detection of DGA Domain Names},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJLmN8xRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper273/Authors"],"keywords":["deep neural networks","short text classification","cybersecurity","domain generation algorithms","malicious domain names"]}},{"tddate":null,"ddate":null,"tmdate":1512222610441,"tcdate":1511788652559,"number":2,"cdate":1511788652559,"id":"SJ7ulqYxz","invitation":"ICLR.cc/2018/Conference/-/Paper273/Official_Review","forum":"BJLmN8xRW","replyto":"BJLmN8xRW","signatures":["ICLR.cc/2018/Conference/Paper273/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Technically sound but little innovation/insight w.r.t. models","rating":"5: Marginally below acceptance threshold","review":"This paper applies several NN architectures to classify url’s between benign and malware related URLs.\nThe baseline is random forests and feature engineering.\n\nThis is clearly an application paper. \nNo new method is being proposed, only existing methods are applied directly to the task.\n\nI am not familiar with the task at hand so I cannot properly judge the quality/accuracy of the results obtained but it seems ok.\nFor evaluation data was split randomly in 80% train, 10% test and 10% validation. Given the amount of data 2*10**6 samples, this seems sufficient.\nI think the evaluation could be improved by using malware URLs that were obtained during a larger time window.\nSpecifically, it would be nice if train, test and validation URLs would be operated chronologically. I.e. all train url precede the validation and test urls.\nIdeally, the train and test urls would also be different in time. This would enable a better test of the generalization capabilities in what is essentially a continuously changing environment. \n\nThis paper is a very difficult for me to assign a final rating.\nThere is no obvious technical mistake  and the paper is written reasonably well.\nThere is however a lack of technical novelty or insight in the models themselves. \nI think that the paper should be submitted to a journal or conference in the application domain where it would be a better fit.\n\nFor this reason, I will give the score marginally below the acceptance threshold now.\nBut if the other reviewers argue that the paper should be accepted I will change my score.\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Character Level Based Detection of DGA Domain Names","abstract":"Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Little studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and less prone to overfitting.","pdf":"/pdf/27da53dc5430b961ffbf4ba7504c654d034fc414.pdf","TL;DR":"A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.","paperhash":"anonymous|character_level_based_detection_of_dga_domain_names","_bibtex":"@article{\n  anonymous2018character,\n  title={Character Level Based Detection of DGA Domain Names},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJLmN8xRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper273/Authors"],"keywords":["deep neural networks","short text classification","cybersecurity","domain generation algorithms","malicious domain names"]}},{"tddate":null,"ddate":null,"tmdate":1512222610485,"tcdate":1511778528302,"number":1,"cdate":1511778528302,"id":"HJukYvYxf","invitation":"ICLR.cc/2018/Conference/-/Paper273/Official_Review","forum":"BJLmN8xRW","replyto":"BJLmN8xRW","signatures":["ICLR.cc/2018/Conference/Paper273/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A well-written paper that compares five deep architectures for the cybersecurity task of domain generation algorithm detection","rating":"7: Good paper, accept","review":"\nSUMMARY\n\nThis paper addresses the cybersecurity problem of domain generation algorithm (DGA)  detection. A class of malware uses algorithms to automatically generate artificial domain names for various purposes, e.g. to generate large numbers of rendezvous points. DGA detection concerns the (automatic) distinction of actual and artificially generated domain names. In this paper, a basic problem formulation and general solution approach is investigated, namely that of treating the detection as a text classification task and to let domain names arrive to the classifier as strings of characters. A set of five deep learning architectures (both CNNs and RNNs) are compared empirical on the text classification task. A domain name data set with two million instances is used for the experiments. The main conclusion is that the different architectures are almost equally accurate and that this prompts a preference of simpler architectures over more complex architectures, since training time and the likelihood for overfitting can potentially be reduced.\n\nCOMMENTS\n\nThe introduction is well-written, clear, and concise. It describes the studied real-world problem and clarifies the relevance and challenge involved in solving the problem. The introduction provides a clear overview of deep learning architectures that have already been proposed for solving the problem as well as some architectures that could potentially be used. One suggestion for the introduction is that the authors take some of the description of the domain problem and put it into a separate background section to reduce the text the reader has to consume before arriving at the research problem and proposed solution.\n\nThe methods section (Section 2) provides a clear description of each of the five architectures along with brief code listings and details about whether any changes or parameter choices were made for the experiment. In the beginning of the section, it is not clarified why, if a 75 character string is encoded as a 128 byte ASCII sequence, the content has to be stored in a 75 x 128 matrix instead of a vector of size 128. This is clarified later but should perhaps be discussed earlier to allow readers from outside the subarea to grasp the approach.\n\nSection 3 describes the experiment settings, the results, and discusses the learned representations and the possible implications of using either the deep architectures or the “baseline” Random Forest classifier. Perhaps, the authors could elaborate a little bit more on why Random Forests were trained on a completely different set of features than the deep architectures? The data is stated to be randomly divided into training (80%), validation (10%), and testing (10%). How many times is this procedure repeated? (That is, how many experimental runs were averaged or was the experiment run once?).\n\nIn summary, this is an interesting and well-written paper on a timely topic. The main conclusion is intuitive. Perhaps the conclusion is even regarded as obvious by some but, in my opinion, the result is important since it was obtained from new, rather extensive experiments on a large data set and through the comparison of several existing (earlier proposed) architectures. Since the main conclusion is that simple models should be prioritised over complex ones (due to that their accuracy is very similar), it would have been interesting to get some brief comments on a simplicity comparison of the candidates at the conclusion.\n\nMINOR COMMENTS\n\nAbstract: “Little studies” -> “Few studies”\n\nTable 1: “approach” -> “approaches”\n\nFigure 1: Use the same y-axis scale for all subplots (if possible) to simplify comparison. Also, try to move Figure 1 so that it appears closer to its inline reference in the text.\n\nSection 3: “based their on popularity” -> “based on their popularity”\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Character Level Based Detection of DGA Domain Names","abstract":"Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Little studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and less prone to overfitting.","pdf":"/pdf/27da53dc5430b961ffbf4ba7504c654d034fc414.pdf","TL;DR":"A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.","paperhash":"anonymous|character_level_based_detection_of_dga_domain_names","_bibtex":"@article{\n  anonymous2018character,\n  title={Character Level Based Detection of DGA Domain Names},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJLmN8xRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper273/Authors"],"keywords":["deep neural networks","short text classification","cybersecurity","domain generation algorithms","malicious domain names"]}},{"tddate":null,"ddate":null,"tmdate":1509739392130,"tcdate":1509086238154,"number":273,"cdate":1509739389479,"id":"BJLmN8xRW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJLmN8xRW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Character Level Based Detection of DGA Domain Names","abstract":"Recently several different deep learning architectures have been proposed that take a string of characters as the raw input signal and automatically derive features for text classification. Little studies are available that compare the effectiveness of these approaches for character based text classification with each other. In this paper we perform such an empirical comparison for the important cybersecurity problem of DGA detection: classifying domain names as either benign vs. produced by malware (i.e., by a Domain Generation Algorithm). Training and evaluating on a dataset with 2M domain names shows that there is surprisingly little difference between various convolutional neural network (CNN) and recurrent neural network (RNN) based architectures in terms of accuracy, prompting a preference for the simpler architectures, since they are faster to train and less prone to overfitting.","pdf":"/pdf/27da53dc5430b961ffbf4ba7504c654d034fc414.pdf","TL;DR":"A comparison of five deep neural network architectures for detection of malicious domain names shows surprisingly little difference.","paperhash":"anonymous|character_level_based_detection_of_dga_domain_names","_bibtex":"@article{\n  anonymous2018character,\n  title={Character Level Based Detection of DGA Domain Names},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJLmN8xRW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper273/Authors"],"keywords":["deep neural networks","short text classification","cybersecurity","domain generation algorithms","malicious domain names"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}