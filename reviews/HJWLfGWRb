{"notes":[{"tddate":null,"ddate":null,"tmdate":1512137867354,"tcdate":1512137867354,"number":10,"cdate":1512137867354,"id":"SJQqV1JWz","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Spread loss is squared WW-Hinge-Loss","comment":"The spread-loss in 3.1 is the square of the WW-hinge-loss for multi-class SVMs, a large-margin loss.\n\nSee:\n\nWeston, Jason; Watkins, Chris (1999). \"Support Vector Machines for Multi-Class Pattern Recognition\" (PDF). European Symposium on Artificial Neural Networks.\n\nand the following paper describes the relations of the different variants of this loss:\n\nhttp://jmlr.org/papers/v17/11-229.html\nIn the notation of that paper, it would be the combination of sum-over-others aggregation with relative margin concept and squared hinge loss.\n\nFor theoretical considerations, the log-probability should be used, in which case m  = 1 is fine and the last layer would not need to be normalized any more."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1512222767512,"tcdate":1512093897238,"number":3,"cdate":1512093897238,"id":"ByZRu4ClG","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Review","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["ICLR.cc/2018/Conference/Paper789/AnonReviewer2"],"readers":["everyone"],"content":{"title":"An extremely opaque paper with a potentially interesting idea and good results","rating":"4: Ok but not good enough - rejection","review":"The paper describes another instantiation of \"capsules\" which attempt to learn part-whole relationships and the geometric pose transformations between them.  Results are presented on the smallNORB test set obtaining impressive performance.\n\nAlthough I like very much this overall approach, this particular paper is so opaquely written that it is difficult to understand exactly what was done and how the network works.  It sounds like the main innovation here is using a 4x4 matrix for the pose parameters, and an iterative EM algorithm to find the correspondence between capsules (routing by agreement).  But what exactly the pose matrix represents, and how they get transformed from one layer to the next, is left almost entirely to the reader's imagination.  In addition, how EM factors in, what the probabilities P_ih represent, etc. is not clear.  I think the authors could do a much better job explaining this model, the rationale behind it, and how it works.\n\nPerhaps the most interesting and compelling result is Figure 2, which shows how ambiguity in object class assignment is resolved with each iteration.  This is very intriguing, but it would be great to understand what is going on and how this is happening.\n\nAlthough the results are impressive, if one can't understand how this was achieved it is hard to know what to make of it.\n\n","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1511986743075,"tcdate":1511986743075,"number":9,"cdate":1511986743075,"id":"HkAVUc3gz","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["~Kaitlin_Duck_Sherwood1"],"readers":["everyone"],"writers":["~Kaitlin_Duck_Sherwood1"],"content":{"title":"Typo","comment":"The sentence fragment:\n   Spatial transformer networks (Jaderberg et al. (2015) seeks\nis missing a ), and the subject is plural and not singular.  So it should be:\n    Spatial transformer networks (Jaderberg et al. (2015)) seek"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1511969780085,"tcdate":1511969780085,"number":8,"cdate":1511969780085,"id":"rJnxEL2xf","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["~Micha_Pfeiffer1"],"readers":["everyone"],"writers":["~Micha_Pfeiffer1"],"content":{"title":"V_ih","comment":"1) \"V_ih is the product of the the transformation matrix W_ic that is learned discriminatively\"\nThere is part of the sentense missing. Also, I believe this sentence describes \"V_i\" and not \"V_ih\". Suggestion:\n\" ... and V_ih is the value on dimension h of the vote V_i from capsule i to capsule c. V_i is obtained by taking the matrix product of the pose p_i of capsule i and the transformation Matrix W_ic. W_ic is learned discriminatively.\"\n\n2) From what I understand, the vote V_i is a matrix (since it's obtained by multiplying a 4x4 matrix with a 4x4 matrix), and v_ih is a scalar. I found \"V_ih is the value on dimension h of the vote ...\" to be missleading. Maybe it should be mentioned that V_i has to be reshaped into a vector first and then its h'th entry is V_ih?"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1512222767552,"tcdate":1511795879311,"number":2,"cdate":1511795879311,"id":"ry1nhoKgM","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Review","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["ICLR.cc/2018/Conference/Paper789/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Idea is interesting; need more empirical validation than smallNORB","rating":"6: Marginally above acceptance threshold","review":"This paper proposes a new kind of capsules for CNN. The capsule contains a 4x4 pose matrix motivated by 3D geometric transformations describing the relationship between the viewer and the object (parts). An EM-type of algorithm is used to compute the routing.\n\nThe authors use the smallNORB dataset as an example. Since the scenes are simulated from different viewer angles, the pose matrix quite fits the motivation. It would be more beneficial to know if this kind of capsules is limited to the motivation or is general. For example, the authors may consider reporting the results of the affNIST dataset where the digits undergo 2D affine transformations (in which case perhaps 3x3 pose matrices are enough?).\n\nMinor: The arguments in line 5 of the procedure RM Routing(a,V) do not match those in line 1 of the procedure E-Step.\n\nSection 2.1 (objective of EM) is unclear. The authors may want to explicitly write down the free energy function.\n\nThe section about robustness against adversarial attacks is interesting.\n\nOverall the idea appears to be useful but needs more empirical validation (affNIST, ImageNet, etc).\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1512222767592,"tcdate":1511794262643,"number":1,"cdate":1511794262643,"id":"Hykw8iKxG","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Review","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["ICLR.cc/2018/Conference/Paper789/AnonReviewer1"],"readers":["everyone"],"content":{"title":"A novel approach for capsule networks","rating":"7: Good paper, accept","review":"The paper proposes a novel architecture for capsule networks. Each capsule has a logistic unit representing the presence of an entity plus a 4x4 pose matrix representing the entity/viewer relationship. This new representation comes with a novel iterative routing scheme, based on the EM algorithm.\nEvaluated on the SmallNORB dataset, the approach proves to be more accurate than previous work (beating also the recently proposed \"routing-by-agreement\" approach for capsule networks by Sabour et al.). It also generalizes well to new, unseen viewpoints and proves to be more robust to adversarial examples than traditional CNNs.\n\nCapsule networks have recently gained attention from the community. The paper addresses important shortcomings exhibited by previous work (Sabour et al.), introducing a series of valuable technical novelties.\nThere are, however, some weaknesses. The proposed routing scheme is quite complex (involving an EM-based step at each layer); it's not fully clear how efficiently it can be performed / how scalable it is. Evaluation is performed on a small dataset for shape recognition; as noted in Sec. 6, the approach will need to be tested on larger, more challenging datasets. Clarity could be improved in some parts of the paper (e.g.: Sec. 1.1 may not be fully clear if the reader is not already familiar with (Sabour et al., 2017); the authors could give a better intuition about what is kept and what is discarded, and why, from that approach. Sec. 2: the sentence \"this is incorrect because the transformation matrix...\" could be elaborated more. V_{ih} in eq. 1 is defined only a few lines below; perhaps, defining the variables before the equations could improve clarity. Sec. 2.1 could be accompanied by mathematical formulation).\nAll in all, the paper brings an original contribution and will encourage further research / discussion on an important research question (how to effectively leverage knowledge about the part-whole relationships).\n\nOther notes:\n- There are a few typos (e.g. Sec. 1.2 \"(Jaderberg et al. (2015)\",  Sec. 2 \"the the transformation\", Sec. 4 \"cetral crop\" etc.).\n- The authors could discuss in more detail why the approach does not show significant improvement on NORB with respect to the state of the art.\n- The authors could provide more insights about why capsule gradients are smaller than CNN ones.\n- It would be interesting to discuss how the network could potentially be adapted, in the future, to: 1. be more efficient 2. take into account other changes produced by viewpoint changes (pixel intensities, as noted in Sec. 1).\n- In Sec, 4, the authors could provide more details about the network training.\n- In Procedure 1, for indexing tensors and matrices it might be better to use a comma to separate dimensions (e.g. V_{:,c,:} instead of V_{:c:}).","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1511578747698,"tcdate":1511578747698,"number":4,"cdate":1511578747698,"id":"r17t2UIgf","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Comment","forum":"HJWLfGWRb","replyto":"Hy9EvktkG","signatures":["ICLR.cc/2018/Conference/Paper789/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper789/Authors"],"content":{"title":"dimensionality of transformation matrix W_{ic} in ConvCaps","comment":"W_{ic} is 4*4 if you flatten the capsule types and grid positions. Therefore i goes over changes in the range of (1, channels * height * width) in this formulation.\n\nHowever, We share the W_ic between different positions of two capsule types as in a convolutional layer with a kernel size k. Therefore, the total number of trainable parameters between two convolutional capsule layer types is 4*4*k*k and for the whole layer is 4*4*k*k*B*C. Where B is the number of different capsule types in layer bellow and C is the number of different capsule types in the next layer.\n\nPlease note that it is 4*4 rather than (4*4)*(4*4). "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1511578177414,"tcdate":1511578177414,"number":3,"cdate":1511578177414,"id":"BkFS5LLxf","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Comment","forum":"HJWLfGWRb","replyto":"ryM_Fi4JM","signatures":["ICLR.cc/2018/Conference/Paper789/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper789/Authors"],"content":{"title":"How to transform conv layer to the primary capsule layer?","comment":"As Jianfei has explained, the primary capsule layer is a convolutional layer with 1x1 kernel. It transforms the A channels in the first layer to B*(4x4+1) channels. Then we split the B*(4x4+1) channels into B*(4x4) as the pose matrices for B capsules and B*1 as the activation logits of B capsules in primary layer. Then we apply sigmoid nonlinearity on the activation logits."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1511577822890,"tcdate":1511577822890,"number":2,"cdate":1511577822890,"id":"HyvJKULxM","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Comment","forum":"HJWLfGWRb","replyto":"ByAqs7VJf","signatures":["ICLR.cc/2018/Conference/Paper789/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper789/Authors"],"content":{"title":"Re: The objective function","comment":"The objective function in details is:\n\\sum_c a'_c (-\\beta_a) + a'_c ln(a'_c) + (1-a'_c)ln(1-a'_c)+\\sum_h cost_{ch} + \\sum_i a_i *  r_{ic} * ln(r_{ic})\n\na'_c is the activation for capsule c in layer L+1 and a_i is the activation probability for capsule i in layer L. The rest of the notations follow paper. \nFollowing link shows the value of this objective function  at each routing iteration for 400 random input images:\nhttps://drive.google.com/open?id=1z44vmUp6w3nQA0X2yOOj8Lq4ImSffoTA\n\nTo verify that the objective function is decaying at each step and it settles down at the end, you can look at the following plot which shows the difference between two consecutive routing iterations. \nhttps://drive.google.com/open?id=1iyBkgz2sT-ilcGQWyXd1xSzpL264FOsb\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1510696754345,"tcdate":1510696754345,"number":7,"cdate":1510696754345,"id":"Hy9EvktkG","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["~Gavin_Weiguang_Ding1"],"readers":["everyone"],"writers":["~Gavin_Weiguang_Ding1"],"content":{"title":"dimensionality of transformation matrix W_{ic} in ConvCaps","comment":"In the convolutional capsule layers, what's the dimensionality of  transformation matrix W_{ic}?\nIs it still (4*4)->(4*4) which correspond to a 1*1 linear convolutional layer?\nor it is (4*4*k*k)->(4*4) which correspond to a k*k linear convolutional layer?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1510455985555,"tcdate":1510455985555,"number":6,"cdate":1510455985555,"id":"Hkc2c4HyM","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"ryM_Fi4JM","signatures":["~Jianfei_Chen1"],"readers":["everyone"],"writers":["~Jianfei_Chen1"],"content":{"title":"How to transform conv layer to the primary capsule layer?","comment":"Figure 1 explains that. I guess they use a A*B*(4*4+1) kernel to (linear) transform a 1 width * 1 height * 32 channels patch to 32 capsules, each shape is 4*4+1. Then they reshape the 4*4 part as a matrix and apply a sigmoid on the 1 part. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1510418849472,"tcdate":1510418794078,"number":5,"cdate":1510418794078,"id":"ryM_Fi4JM","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"How to transform conv layer to the primary capsule layer?","comment":"I still don't understand the transformation from convolution layer to primary capsule layer? Is it achieved by slicing 4x4*32 patches from the conv layer and then do a linear transformation for each 4x4 matrices?  what is the weight in \"The activations of the primary capsules are produced by applying the sigmoid function to weighted sums of the same set of lower layer ReLUs.\" is it the 4x4 variable? I found it confusing, can you elaborate how this works."},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1510386582459,"tcdate":1510386582459,"number":4,"cdate":1510386582459,"id":"ByAqs7VJf","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["~Jianfei_Chen1"],"readers":["everyone"],"writers":["~Jianfei_Chen1"],"content":{"title":"The objective function","comment":"Can you write down what exactly is the objective function in Section 2.1?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1509581767435,"tcdate":1509581767435,"number":2,"cdate":1509581767435,"id":"rk1Am1uRW","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"ByVzDRDRW","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"state-of-the-art on \"small NORB\"","comment":"The meta data is not used during test time only during training time."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1510092427847,"tcdate":1509578507674,"number":1,"cdate":1509578507674,"id":"ByVzDRDRW","invitation":"ICLR.cc/2018/Conference/-/Paper789/Official_Comment","forum":"HJWLfGWRb","replyto":"S1uPsnwR-","signatures":["ICLR.cc/2018/Conference/Paper789/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper789/Authors"],"content":{"title":"state-of-the-art on \"small NORB\"","comment":"They gain a lot by using the meta data at test time. Without using that information (which normally is not available at test time) they get 2.6%. "},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1509571423975,"tcdate":1509571423975,"number":1,"cdate":1509571423975,"id":"S1uPsnwR-","invitation":"ICLR.cc/2018/Conference/-/Paper789/Public_Comment","forum":"HJWLfGWRb","replyto":"HJWLfGWRb","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"state-of-the-art on \"small NORB\"","comment":"1.5% error rate has previously been reported on small NORB.\nhttps://www.researchgate.net/publication/265335724_Nonlinear_Supervised_Locality_Preserving_Projections_for_Visual_Pattern_Discrimination"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]}},{"tddate":null,"ddate":null,"tmdate":1509739101060,"tcdate":1509134920738,"number":789,"cdate":1509739098401,"id":"HJWLfGWRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJWLfGWRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Matrix capsules with EM routing","abstract":"A capsule is a group of neurons whose outputs represent different properties of the same entity. We describe a version of capsules in which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix which could learn to represent the relationship between that entity and the viewer. A capsule in one layer votes for the pose matrices of many different capsules in the layer above by multiplying its own pose matrix by viewpoint-invariant transformation matrices that could learn to represent part-whole relationships. Each of these votes is weighted by an assignment coefficient. These coefficients are iteratively updated using the EM algorithm such that the output of each capsule is routed to a capsule in the layer above that receives a cluster of similar votes. The whole system is trained discriminatively by unrolling 3 iterations of EM between each pair of adjacent layers. On the smallNORB benchmark, capsules reduce the number of test errors by 45\\% compared to the state-of-the-art. Capsules also show far more resistant to white box adversarial attack than our baseline convolutional neural network.","pdf":"/pdf/99b7cb0c78706ad8e91c13a2242bb15b7de325ad.pdf","TL;DR":"Capsule networks with learned pose matrices and EM routing improves state of the art classification on smallNORB, improves generalizability to new view points, and white box adversarial robustness.  ","paperhash":"anonymous|matrix_capsules_with_em_routing","_bibtex":"@article{\n  anonymous2018matrix,\n  title={Matrix capsules with EM routing},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJWLfGWRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper789/Authors"],"keywords":["Computer Vision","Deep Learning","Dynamic routing"]},"nonreaders":[],"replyCount":16,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}