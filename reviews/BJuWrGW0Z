{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222783230,"tcdate":1512193315374,"number":3,"cdate":1512193315374,"id":"rkdmp2J-f","invitation":"ICLR.cc/2018/Conference/-/Paper832/Official_Review","forum":"BJuWrGW0Z","replyto":"BJuWrGW0Z","signatures":["ICLR.cc/2018/Conference/Paper832/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting application, but lacks clarity","rating":"4: Ok but not good enough - rejection","review":"This paper considers the task of learning program embeddings with neural networks with the ultimate goal of bug detection program repair in the context of students learning to program. Three NN architectures are explored, which leverage program semantics rather than pure syntax.  The approach is validated using programming assignments from an online course, and compared against syntax based approaches as a baseline.\n\nThe problem considered by the paper is interesting, though it's not clear from the paper that the approach is a substantial improvement over previous work. This is in part due to the fact that the paper is relatively short, and would benefit from more detail.  I noticed the following issues:\n\n1) The learning task is based on error patterns, but it's not clear to me what exactly that means from a software development standpoint.\n2) Terms used in the paper are not defined/explained. For example, I assume GRU is gated recurrent unit, but this isn't stated.\n3) Treatment of related work is lacking.  For example, the Cai et al. paper from ICLR 2017 is not considered\n4) If I understand dependency reinforcement embedding correctly, a RNN is trained for every trace. If so, is this scalable?\n\nI believe the work is very promising, but this manuscript should be improved prior to publication.","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Dynamic Neural Program Embeddings for Program Repair","abstract":"Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difﬁcult to capture by only considering its syntax(i.e. syntactically similar programs can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural ﬁt for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding signiﬁcantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our semantic embedding, and show that search efﬁciency is also signiﬁcantly improved.","pdf":"/pdf/3a8faa9384291140f1df6f63bfc5633fac1d20d6.pdf","TL;DR":"A new way of learning semantic program embedding","paperhash":"anonymous|dynamic_neural_program_embeddings_for_program_repair","_bibtex":"@article{\n  anonymous2018dynamic,\n  title={Dynamic Neural Program Embeddings for Program Repair},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJuWrGW0Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper832/Authors"],"keywords":["Program Embedding","Program Semantics","Dynamic Traces"]}},{"tddate":null,"ddate":null,"tmdate":1512222783273,"tcdate":1511895007195,"number":2,"cdate":1511895007195,"id":"H1Pyl4sxM","invitation":"ICLR.cc/2018/Conference/-/Paper832/Official_Review","forum":"BJuWrGW0Z","replyto":"BJuWrGW0Z","signatures":["ICLR.cc/2018/Conference/Paper832/AnonReviewer3"],"readers":["everyone"],"content":{"title":".","rating":"5: Marginally below acceptance threshold","review":"Summary of paper: The paper proposes an RNN-based neural network architecture for embedding programs, focusing on the semantics of the program rather than the syntax. The application is to predict errors made by students on programming tasks. This is achieved by creating training data based on program traces obtained by instrumenting the program by adding print statements. The neural network is trained using this program traces with an objective for classifying the student error pattern (e.g. list indexing, branching conditions, looping bounds).\n\n---\n\nQuality: The experiments compare the three proposed neural network architectures with two syntax-based architectures. It would be good to see a comparison with some techniques from Reed & De Freitas (2015) as this work also focuses on semantics-based embeddings.\nClarity: The paper is clearly written.\nOriginality: This work doesn't seem that original from an algorithmic point of view since Reed & De Freitas (2015) and Cai et. al (2017) among others have considered using execution traces. However the application to program repair is novel (as far as I know).\nSignificance: This work can be very useful for an educational platform though a limitation is the need for adding instrumentation print statements by hand.\n\n---\n\nSome questions/comments:\n- Do we need to add the print statements for any new programs that the students submit? What if the structure of the submitted program doesn't match the structure of the intended solution and hence adding print statements cannot be automated?\n\n---\n\nReferences \n\nCai, J., Shin, R., & Song, D. (2017). Making Neural Programming Architectures Generalize via Recursion. In International Conference on Learning Representations (ICLR).","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Dynamic Neural Program Embeddings for Program Repair","abstract":"Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difﬁcult to capture by only considering its syntax(i.e. syntactically similar programs can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural ﬁt for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding signiﬁcantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our semantic embedding, and show that search efﬁciency is also signiﬁcantly improved.","pdf":"/pdf/3a8faa9384291140f1df6f63bfc5633fac1d20d6.pdf","TL;DR":"A new way of learning semantic program embedding","paperhash":"anonymous|dynamic_neural_program_embeddings_for_program_repair","_bibtex":"@article{\n  anonymous2018dynamic,\n  title={Dynamic Neural Program Embeddings for Program Repair},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJuWrGW0Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper832/Authors"],"keywords":["Program Embedding","Program Semantics","Dynamic Traces"]}},{"tddate":null,"ddate":null,"tmdate":1512222783318,"tcdate":1511841991280,"number":1,"cdate":1511841991280,"id":"H1JAev9gz","invitation":"ICLR.cc/2018/Conference/-/Paper832/Official_Review","forum":"BJuWrGW0Z","replyto":"BJuWrGW0Z","signatures":["ICLR.cc/2018/Conference/Paper832/AnonReviewer1"],"readers":["everyone"],"content":{"title":"A solid paper with some clarity issues","rating":"7: Good paper, accept","review":"The authors present 3 architectures for learning representations of programs from execution traces. In the variable trace embedding, the input to the model is given by a sequence of variable values. The state trace embedding combines embeddings for variable traces using a second recurrent encoder. The dependency enforcement embedding performs element-wise multiplication of embeddings for parent variables to compute the input of the GRU to compute the new hidden state of a variable. The authors evaluate their architectures on the task of predicting error patterns for programming assignments from Microsoft DEV204.1X (an introduction to C# offered on edx) and problems on the Microsoft CodeHunt platform. They additionally use their embeddings to decrease the search time for the Sarfgen program repair system.\n\nThis is a fairly strong paper. The proposed models make sense and the writing is for the most part clear, though there are a few places where ambiguity arises:\n\n- The variable \"Evidence\" in equation (4) is never defined. \n\n- The authors refer to \"predicting the error patterns\", but again don't define what an error pattern is. The appendix seems to suggest that the authors are simply performing multilabel classification based on a predefined set of classes of errors, is this correct? \n\n- It is not immediately clear from Figures 3 and 4 that the architectures employed are in fact recurrent.\n\n- Figure 5 seems to suggest that dependencies are only enforced at points in a program where assignment is performed for a variable, is this correct?\n\nAssuming that the authors can address these clarity issues, I would in principle be happy for the paper to appear. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Dynamic Neural Program Embeddings for Program Repair","abstract":"Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difﬁcult to capture by only considering its syntax(i.e. syntactically similar programs can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural ﬁt for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding signiﬁcantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our semantic embedding, and show that search efﬁciency is also signiﬁcantly improved.","pdf":"/pdf/3a8faa9384291140f1df6f63bfc5633fac1d20d6.pdf","TL;DR":"A new way of learning semantic program embedding","paperhash":"anonymous|dynamic_neural_program_embeddings_for_program_repair","_bibtex":"@article{\n  anonymous2018dynamic,\n  title={Dynamic Neural Program Embeddings for Program Repair},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJuWrGW0Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper832/Authors"],"keywords":["Program Embedding","Program Semantics","Dynamic Traces"]}},{"tddate":null,"ddate":null,"tmdate":1509739077290,"tcdate":1509135615596,"number":832,"cdate":1509739074637,"id":"BJuWrGW0Z","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJuWrGW0Z","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Dynamic Neural Program Embeddings for Program Repair","abstract":"Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difﬁcult to capture by only considering its syntax(i.e. syntactically similar programs can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural ﬁt for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding signiﬁcantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our semantic embedding, and show that search efﬁciency is also signiﬁcantly improved.","pdf":"/pdf/3a8faa9384291140f1df6f63bfc5633fac1d20d6.pdf","TL;DR":"A new way of learning semantic program embedding","paperhash":"anonymous|dynamic_neural_program_embeddings_for_program_repair","_bibtex":"@article{\n  anonymous2018dynamic,\n  title={Dynamic Neural Program Embeddings for Program Repair},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJuWrGW0Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper832/Authors"],"keywords":["Program Embedding","Program Semantics","Dynamic Traces"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}