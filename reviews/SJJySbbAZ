{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222717349,"tcdate":1511911411696,"number":2,"cdate":1511911411696,"id":"Syhxg_jgf","invitation":"ICLR.cc/2018/Conference/-/Paper669/Official_Review","forum":"SJJySbbAZ","replyto":"SJJySbbAZ","signatures":["ICLR.cc/2018/Conference/Paper669/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Nice paper","rating":"8: Top 50% of accepted papers, clear accept","review":"The paper proposes to use optimistic gradient descent (OGD) for GAN training. Optimistic mirror descent is know to yield fast convergence for finding the optimum of zero-sum convex-concave games (when the players collaborate for fast computation), but earlier results concern the performance of the average iterate. This paper extends this result by showing that the last iterate of OGD also provides a good estimate of the value of bilinear games. Based on this new theoretical result (which is not unexpected but is certainly nice), the authors propose to use stochastic OGD in GAN training. Their experiments show that this new approach avoids the cycling behavior observed with SGD and its variants, and provides promising results in GAN training. (Extensive experiments show the cycling behavior of SGD variants in very simple problems, and some theoretical result is also provided when SGD diverges in solving a simple min-max game).\n\nThe paper is clearly written and easy to follow; in fact I quite enjoyed reading it. I have not checked all the details of the proofs, but they seem plausible.\nAll in all, this is a very nice paper.\n\nSome questions/comments:\n- Proposition 1: Could you show a similar example when you can prove the oscillating behavior?\n- Theorem 1: It would be interesting to write out the convergence rate of Delta_t, which could be used to optimize eta. Also, my understanding is that you actually avoid computing gamma, hence tuning eta is not straightforward. Alternatively, you could also use an adaptive OGD to automatically tune eta (see, e.g., Joulani et al, \"A modular analysis of adaptive (non-)convex optimization: optimism, composite objectives, and variational Bounds,\" ALT 2017). The non-adaptive selection of eta might be the reason that your method does not outperform adagrad SGD in 5 (b), although it is true that the behavior of your method seems quite stable for different learning rates).\n- LHS of the second line of (6) should be theta.\n- Below (6): \\mathcal{R}(A) is only defined in the appendix.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]}},{"tddate":null,"ddate":null,"tmdate":1512222717387,"tcdate":1511760396503,"number":1,"cdate":1511760396503,"id":"H1NffmKgz","invitation":"ICLR.cc/2018/Conference/-/Paper669/Official_Review","forum":"SJJySbbAZ","replyto":"SJJySbbAZ","signatures":["ICLR.cc/2018/Conference/Paper669/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Natural and interesting work with some questionable experimental results ","rating":"6: Marginally above acceptance threshold","review":"This paper proposes the use of optimistic mirror descent to train Wasserstein Generative Adversarial Networks (WGANS). The authors remark that the current training of GANs, which amounts to solving a zero-sum game between a generator and discriminator, is often unstable, and they argue that one source of instability is due to limit cycles, which can occur for FTRL-based algorithms even in convex-concave zero-sum games. Motivated by recent results that use Optimistic Mirror Descent  (OMD) to achieve faster convergence rates (than standard gradient descent) in convex-concave zero-sum games and normal form games, they suggest using these techniques for WGAN training as well. The authors prove that, using OMD, the last iterate converges to an equilibrium and use this as motivation that OMD methods should be more stable for WGAN training. They then compare OMD against GD on both toy simulations and a DNA sequence task before finally introducing an adaptive generalization of OMD, Optimistic Adam, that they test on CIFAR10. \n\nThis paper is relatively well-written and clear, and the authors do a good job of introducing the problem of GAN training instability as well as the OMD algorithm, in particular highlighting its differences with standard gradient descent as well as discussing existing work that has applied it to zero-sum games. Given the recent work on OMD for zero-sum and normal form games, it is natural to study its effectiveness in training GANs.The issue of last iterate versus average iterate for non convex-concave problems is also presented well.  \n\nThe theoretical result on last-iterate convergence of OMD for bilinear games is interesting, but somewhat wanting as it does not provide an explicit convergence rate as in Rakhlin and Sridharan, 2013. Moreover, the result is only at best a motivation for using OMD in WGAN training since the WGAN optimization problem is not a bilinear game. \n\nThe experimental results seem to indicate that OMD is at least roughly competitive with GD-based methods, although they seem less compelling than the prior discussion in the paper would suggest. In particular, they are matched by SGD with momentum when evaluated by last epoch performance (albeit while being less sensitive to learning rates). OMD does seem to outperform SGD-based methods when using the lowest discriminator loss, but there doesn't seem to be even an attempt at explaining this in the paper. \n\nI found it a bit odd that Adam was not used as a point of comparison in Section 5, that optimistic Adam was only introduced and tested for CIFAR but not for the DNA sequence problem, and that the discriminator was trained for 5 iterations in Section 5 but only once in Section 6, despite the fact that the reasoning provided in Section 6 seems like it would have also applied for Section 5. This gives the impression that the experimental results might have been at least slightly \"gamed\". \n\nFor the reasons above, I give the paper high marks on clarity, and slightly above average marks on originality, significance, and quality.\n\nSpecific comments:\nPage 1, \"no-regret dynamics in zero-sum games can very often lead to limit cycles\": I don't think limit cycles are actually ever formally defined in the entire paper.  \nPage 3, \"standard results in game theory and no-regret learning\": These results should be either proven or cited.\nPage 3: Don't the parameter spaces need to be bounded for these convergence results to hold? \nPage 4, \"it is well known that GD is equivalent to the Follow-the-Regularized-Leader algorithm\": For completeness, this should probably either be (quickly) proven or a reference should be provided.\nPage 5, \"the unique equilibrium of the above game is...for the discriminator to choose w=0\": Why is w=0 necessary here?\nPage 6, \"We remark that the set of equilibrium solutions of this minimax problem are pairs (x,y) such that x is in the null space of A^T and y is in the null space of A\": Why is this true? This should either be proven or cited.\nPage 6, Initialization and Theorem 1: It would be good to discuss the necessity of this particular choice of initialization for the theoretical result. In the Initialization section, it appears simply to be out of convenience.\nPage 6, Theorem 1: It should be explicitly stated that this result doesn't provide a convergence rate, in contrast to the existing OMD results cited in the paper.   \nPage 7, \"we considered momentum, Nesterov momentum and AdaGrad\": Why isn't Adam used in this section if it is used in  later experiments?\nPage 7-8, \"When evaluated by....the lowest discriminator loss on the validation set, WGAN trained with Stochastic OMD (SOMD) achieved significantly lower KL divergence than the competing SGD variants.\": Can you explain why SOMD outperforms the other methods when using the lowest discriminator loss on the validation set? None of the theoretical arguments presented earlier in the paper seem to even hint at this. The only result that one might expect from the earlier discussion and results is that SOMD would outperform the other methods when evaluating by the last epoch. However, this doesn't even really hold, since there exist learning rates in which SGD with momentum matches the performance of SOMD.\nPage 8, \"Evaluated by the last epoch, SOMD is much less sensitive to the choice of learning rate than the SGD variants\": Learning rate sensitivity doesn't seem to be touched upon in the earlier discussion. Can these results be explained by theory?\nPage 8, \"we see that optimistic Adam achieves high numbers of inception scores after very few epochs of training\": These results don't mean much without error bars.\nPage 8, \"we only trained the discriminator once after one iteration of generator training. The latter is inline with the intuition behind the use of optimism....\": Why didn't this logic apply to the previous section on DNA sequences, where the discriminator was trained multiple times?\n\n\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]}},{"tddate":null,"ddate":null,"tmdate":1510451673119,"tcdate":1510451673119,"number":2,"cdate":1510451673119,"id":"HJZkcmSJf","invitation":"ICLR.cc/2018/Conference/-/Paper669/Public_Comment","forum":"SJJySbbAZ","replyto":"rJ99FMSkf","signatures":["~Leon_Boellmann1"],"readers":["everyone"],"writers":["~Leon_Boellmann1"],"content":{"title":"Thanks a lot!","comment":"Thanks a lot for your reply!"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]}},{"tddate":null,"ddate":null,"tmdate":1510447505808,"tcdate":1510447505808,"number":1,"cdate":1510447505808,"id":"rJ99FMSkf","invitation":"ICLR.cc/2018/Conference/-/Paper669/Official_Comment","forum":"SJJySbbAZ","replyto":"SJxehjl1G","signatures":["ICLR.cc/2018/Conference/Paper669/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper669/Authors"],"content":{"title":"RE: OMD on nonconvex optimization ","comment":"Our main theoretical result in Section 4 is that OMD exhibits last-iterate, rather than average-iterate, convergence in zero-sum games. In particular, its dynamics converges to equilibrium rather than cycling, as gradient descent does, around the equilibrium. We believe that this theoretical guarantee extends to general convex-concave settings.\n\nInspired by the better behavior of OMD in theory, we evaluate experimentally its performance outside of the convex-concave setting. We observe that it performs better than other methods (e.g. adagrad, adam, nesterov momentum) in adversarial training applications such as training on cifar10 and DNA sequence data. \n\nOn the theory front the non convex-concave setting is not well-understood yet. We believe that the theoretical part our analysis could generalize to show convergence to local minimax solutions, but defer this as an interesting open question for future work. We should note that even for non-adversarial training, the non-convex case is not well-understood. Here too methods only have good theoretical properties in the convex setting while still being used in the non-convex setting. One way to view our results it that they complement these results. We show that OMD has last-iterate convergence in the convex-concave setting, and propose using it in the non convex-concave setting where our experimental evaluation shows promising results."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]}},{"tddate":null,"ddate":null,"tmdate":1510157287906,"tcdate":1510157287906,"number":1,"cdate":1510157287906,"id":"SJxehjl1G","invitation":"ICLR.cc/2018/Conference/-/Paper669/Public_Comment","forum":"SJJySbbAZ","replyto":"SJJySbbAZ","signatures":["~Leon_Boellmann1"],"readers":["everyone"],"writers":["~Leon_Boellmann1"],"content":{"title":"OMD on nonconvex optimization","comment":" Dear authors,\n I have a question on the convergence of OMD. It claims that OMD has a faster convergence rate to the equilibrium of a zero-sum game. Does it hold for an objective function that is convex-concave, or any general objective function? Section 4 only shows the convergence results for a bilinear function. If similar convergence result does not hold for a general objective function,  how does OMD help in the minimax game of GAN, which is generally not convex-concave in the generator and discriminator network parameters?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]}},{"tddate":null,"ddate":null,"tmdate":1509739170357,"tcdate":1509131479517,"number":669,"cdate":1509739167693,"id":"SJJySbbAZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SJJySbbAZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Training GANs with Optimism","abstract":"We address the issue of limit cycling behavior in training Generative Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for training Wasserstein GANs. Recent theoretical results have shown that optimistic mirror decent (OMD) can enjoy faster regret rates in the context of zero-sum games. WGANs is exactly a context of solving a zero-sum game with simultaneous no-regret dynamics.  Moreover, we show that optimistic mirror decent addresses the limit cycling problem in training WGANs. We formally show that in the case of bi-linear zero-sum games the last iterate of OMD dynamics converges to an equilibrium, in contrast to GD dynamics which are bound to cycle. We also portray the huge qualitative difference between GD and OMD dynamics with toy examples, even when GD is modified with many adaptations proposed in the recent literature, such as gradient penalty or momentum. We apply OMD WGAN training to a bioinformatics problem of generating DNA sequences. We observe that models trained with OMD achieve consistently smaller KL divergence with respect to the true underlying distribution, than models trained with GD variants. Finally, we introduce a new algorithm, Optimistic Adam, which is an optimistic variant of Adam. We apply it to WGAN training on CIFAR10 and observe improved performance in terms of inception score as compared to Adam.","pdf":"/pdf/595db2ab0eaf2f8b569239d8f7367e14f849cca6.pdf","TL;DR":"We propose the use of optimistic mirror decent to address cycling problems in the training of GANs. We also introduce the Optimistic Adam algorithm","paperhash":"anonymous|training_gans_with_optimism","_bibtex":"@article{\n  anonymous2018training,\n  title={Training GANs with Optimism},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SJJySbbAZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper669/Authors"],"keywords":["GANs","Optimistic Mirror Decent","Cycling","Last Iterate Convergence","Optimistic Adam"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}