{"notes":[{"tddate":null,"ddate":null,"tmdate":1512226361379,"tcdate":1512220414906,"number":1,"cdate":1512220414906,"id":"H1vZPmg-G","invitation":"ICLR.cc/2018/Conference/-/Paper590/Public_Comment","forum":"HyWrIgW0W","replyto":"HyWrIgW0W","signatures":["~James_T_Griffin1"],"readers":["everyone"],"writers":["~James_T_Griffin1"],"content":{"title":"An mathematician's perspective","comment":"I really like this paper and have learnt a lot from reading it.  I think the basic ideas behind it are very important indeed and I don't know of anywhere else they are written down.  However I think it has some major issues.\n\nMost importantly I think the statements at the very start the introduction \"[Φ] is only a function of the architecture and the dataset\" and at the start of Section 3, \"The potential Φ(x) depends only on the full-gradient and the diffusion matrix, and will be made explicit in Section 5.\" are *wildly* misleading.  They depend on both of Assumptions 4 and 16, which even at the start of Section 3 have not been made yet.  I think's it's entirely reasonable to think that \"in the wild\" Φ(x) would depend on the learning rate, and the burden of proof to convince a reader otherwise should be very high.\n\nI am also confused by the use of the term \"full-gradient\".  In Lemma 14 formula for Φ involves U, but U depends on the Hessian of f.  So more than the gradient of f at x.\n\nThe very first equation of the introduction is a tautology if Phi is defined as in equation (6) and only has value if it has a given formula which is never actually given in the text and only alluded to (I don't count Lemma 14 as that applies to a quadratic form only).  There is nothing logically wrong about doing this and I personally find it quite entertaining, but it does feel like a sleight of hand that could hide the assumptions from an inattentive reader.\n\nThe second part of Theorem 5 is just an entropy maximisating theorem which is in every standard textbook (eg it's a corollary of Thm 12.1.1 from Elements of Infromation Theory 2nd Ed. by Cover and Thomas).  The first part feels familiar but I couldn't point you to a specific reference.\n\nConcerning Assumption 4... This assumption is not invariant w.r.t. a change in coordinates of the parameter space.  So it is reliant on the Euclidean metric, but why not any other metric, perhaps the Fisher metric?  In physics there is usually some kind of symmetry group on the underlying space pushing us to a metric, but there isn't here so I don't think the argument given backing up this assumption is very convincing.  In fact my opinion is that this assumption is wrong (though I don't think this disqualifies it from being assumed, it's interesting enough to see what happens given the assumption).\n\nFinally in Section 4, the experimental section about Brownian motion, I don't think the null hypothesis that SGD undergoes Brownian motion at a local minimum (which I assume is approximated by a quadratic form) is very strong.  Is the evidence consistent with Brownian motion in a degenerate minimum with more complicated topology?\n\nSo in summary I really like this paper, but it needs both the assumptions 4 and 16 to be prominent.  To my mind neither of the assumptions are strictly correct, but that doesn't disqualify them from being made or stop the resulting models being taken seriously."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the inductive bias of stochastic gradient descent","abstract":"Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such \"out-of-equilibrium\" behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic; the covariance matrix of mini-batch gradients has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.","pdf":"/pdf/00ad468839c45257417d6432288fd0eea76978ea.pdf","TL;DR":"SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss","paperhash":"anonymous|on_the_inductive_bias_of_stochastic_gradient_descent","_bibtex":"@article{\n  anonymous2018on,\n  title={On the inductive bias of stochastic gradient descent},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyWrIgW0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper590/Authors"],"keywords":["sgd","variational inference","gradient noise","out-of-equilibrium"]}},{"tddate":null,"ddate":null,"tmdate":1512222694953,"tcdate":1511837330613,"number":3,"cdate":1511837330613,"id":"Bkic0BclM","invitation":"ICLR.cc/2018/Conference/-/Paper590/Official_Review","forum":"HyWrIgW0W","replyto":"HyWrIgW0W","signatures":["ICLR.cc/2018/Conference/Paper590/AnonReviewer1"],"readers":["everyone"],"content":{"title":"An interesting paper on analyzing the impact of gradient noise for SGD","rating":"6: Marginally above acceptance threshold","review":"This paper develop theory to study the impact of stochastic gradient noise for SGD, especially for deep neural network models. It is shown that when the gradient noise is isotropic normal, SGD converges to a distribution tilted by the original objective function. However, when the gradient noise is non isotropic normal, which is shown common in many models especially in deep neural network models, the behavior of SGD is intriguing, which will not converge to the tilted distribution by the original objective function, sometimes more interestingly, will converge to limit cycles around some critical points of the original objective function. The paper also provides some hints on why using SGD can get good generalization ability than gradient descend.\n\nI think the finding of this paper is interesting, and the technical details are correct. I still have the following comments.\n\nFirst, Assumption 4 seems a bit too abstract. It is not easy to see what the assumption means. It would be better if an example is given, which is verified to satisfy the assumption.\n\nAnother comment is related to the overall content of this paper. Thought the paper point out that SGD will have the out-of-equilibrium behavior when the gradient noise is non isotropic normal, it remains to show how far away this stationary distribution is from the original distribution defined by the objective function.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the inductive bias of stochastic gradient descent","abstract":"Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such \"out-of-equilibrium\" behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic; the covariance matrix of mini-batch gradients has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.","pdf":"/pdf/00ad468839c45257417d6432288fd0eea76978ea.pdf","TL;DR":"SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss","paperhash":"anonymous|on_the_inductive_bias_of_stochastic_gradient_descent","_bibtex":"@article{\n  anonymous2018on,\n  title={On the inductive bias of stochastic gradient descent},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyWrIgW0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper590/Authors"],"keywords":["sgd","variational inference","gradient noise","out-of-equilibrium"]}},{"tddate":null,"ddate":null,"tmdate":1512222694993,"tcdate":1511807103509,"number":2,"cdate":1511807103509,"id":"B1PK_0tgf","invitation":"ICLR.cc/2018/Conference/-/Paper590/Official_Review","forum":"HyWrIgW0W","replyto":"HyWrIgW0W","signatures":["ICLR.cc/2018/Conference/Paper590/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Well written, but lacking in novelty.","rating":"5: Marginally below acceptance threshold","review":"The authors discuss the regularized objective function minimized by standard SGD in the context of neural nets, and provide a variational inference perspective using the Fokker-Planck equation. They note that the objective can be very different from the desired loss function if the SGD noise matrix is low rank, as evidenced in their experiments.\n\nOverall the paper is written quite well, and the authors do a good job of explaining their thesis. However I was unable to identify any real novelty in the theory: the Fokker-Planck equation has been widely used in analysis of stochastic noise in MCMC samplers in recent years, and this paper mostly rephrases those results. Also the fact that SGD theory only works for isotropic noise is well known, and that there is divergence from the true loss function in case of low rank noise is obvious. Thus I found most of section 3 to be a reformulation of known results, including Theorem 5 and its proof.\n\nSame goes for section 5; the symmetric- anti symmetric split is a common technique used in the stochastic MCMC literature over the last few years, and I did not find any new insight into those manipulations of the Fokker-Planck equation from this paper.\n\nThus I think that although this paper is written well, the theory is mostly recycled and the empirical results in Section 4 are known; thus it is below acceptance threshold due to lack of novelty.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the inductive bias of stochastic gradient descent","abstract":"Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such \"out-of-equilibrium\" behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic; the covariance matrix of mini-batch gradients has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.","pdf":"/pdf/00ad468839c45257417d6432288fd0eea76978ea.pdf","TL;DR":"SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss","paperhash":"anonymous|on_the_inductive_bias_of_stochastic_gradient_descent","_bibtex":"@article{\n  anonymous2018on,\n  title={On the inductive bias of stochastic gradient descent},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyWrIgW0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper590/Authors"],"keywords":["sgd","variational inference","gradient noise","out-of-equilibrium"]}},{"tddate":null,"ddate":null,"tmdate":1512222695032,"tcdate":1511730439224,"number":1,"cdate":1511730439224,"id":"HkJG6iOlM","invitation":"ICLR.cc/2018/Conference/-/Paper590/Official_Review","forum":"HyWrIgW0W","replyto":"HyWrIgW0W","signatures":["ICLR.cc/2018/Conference/Paper590/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A variational analysis of SGD as a non-equilibrium process.","rating":"8: Top 50% of accepted papers, clear accept","review":"The paper takes a closer look at the analysis of SGD as variational inference, first proposed by Duvenaud et al. 2016\nand Mandt et al. 2016. In particular, the authors point out that in general, SGD behaves quite differently from Langevin diffusion due to the multivariate nature of the Gaussian noise. As the authors show based on the Fokker-Planck equation of the underlying stochastic process, there exists a conservative current (a gradient of an underlying potential) and a non-conservative current (which might induce stationary persistent currents at long times). The non-conservative part leads to the fact that the dynamics of SGD\tmay show oscillations, and these oscillations may even prevent the algorithm from converging to the 'right' local optima. The theoretical analysis is carried-out very nicely, and the theory is supported by experiments on two-dimensional toy examples, and Fourier-spectra of the iterates of SGD.\n\nThis is a nice paper which I would like to see accepted. In particular I appreciate that the authors stress the importance\nof 'non-equilibrium physics' for understanding the SGD process. Also, the presentation is quite clear and the paper well written.\n\nThere are a few minor points which I would like to ask the authors to address:\n\n1. Why cite Kingma and Welling as a source for variational inference in\tsection 3.1? VI is a much older\tfield, and Kingma and Welling proposed a very special form of VI, namely amortized VI with inference networks. A better citation would be Jordan et\tal 1999.\n\n2. I'm not sure how much to trust the Fourier-spectra. In particular, perhaps the deviations from Brownian motion could also be due to the discrete\tnature of SGD (i.e. that the continuous-time formalism is only an approximation of a discrete process). Could you elaborate on this?\n\n3. Could you give the reader more details on how the uncertainty estimates on the Fourier transformations were obtained?\n\nThanks.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the inductive bias of stochastic gradient descent","abstract":"Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such \"out-of-equilibrium\" behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic; the covariance matrix of mini-batch gradients has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.","pdf":"/pdf/00ad468839c45257417d6432288fd0eea76978ea.pdf","TL;DR":"SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss","paperhash":"anonymous|on_the_inductive_bias_of_stochastic_gradient_descent","_bibtex":"@article{\n  anonymous2018on,\n  title={On the inductive bias of stochastic gradient descent},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyWrIgW0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper590/Authors"],"keywords":["sgd","variational inference","gradient noise","out-of-equilibrium"]}},{"tddate":null,"ddate":null,"tmdate":1509739215234,"tcdate":1509127736955,"number":590,"cdate":1509739212574,"id":"HyWrIgW0W","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HyWrIgW0W","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"On the inductive bias of stochastic gradient descent","abstract":"Stochastic gradient descent (SGD) is widely believed to perform implicit regularization when used to train deep neural networks, but the precise manner in which this occurs has thus far been elusive. We prove that SGD minimizes an average potential over the posterior distribution of weights along with an entropic regularization term. This potential is however not the original loss function in general. So SGD does perform variational inference, but for a different loss than the one used to compute the gradients. Even more surprisingly, SGD does not even converge in the classical sense: we show that the most likely trajectories of SGD for deep networks do not behave like Brownian motion around critical points. Instead, they resemble closed loops with deterministic components. We prove that such \"out-of-equilibrium\" behavior is a consequence of the fact that the gradient noise in SGD is highly non-isotropic; the covariance matrix of mini-batch gradients has a rank as small as 1% of its dimension. We provide extensive empirical validation of these claims, proven in the appendix.","pdf":"/pdf/00ad468839c45257417d6432288fd0eea76978ea.pdf","TL;DR":"SGD implicitly performs variational inference; gradient noise is highly non-isotropic, so SGD does not even converge to critical points of the original loss","paperhash":"anonymous|on_the_inductive_bias_of_stochastic_gradient_descent","_bibtex":"@article{\n  anonymous2018on,\n  title={On the inductive bias of stochastic gradient descent},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyWrIgW0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper590/Authors"],"keywords":["sgd","variational inference","gradient noise","out-of-equilibrium"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}