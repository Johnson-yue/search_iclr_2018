{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222594744,"tcdate":1511817801120,"number":3,"cdate":1511817801120,"id":"HkZ8Gb9eG","invitation":"ICLR.cc/2018/Conference/-/Paper244/Official_Review","forum":"r1RF3ExCb","replyto":"r1RF3ExCb","signatures":["ICLR.cc/2018/Conference/Paper244/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Solid description of a general class of autoregressive density estimation models with potential utility","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper is well constructed and written. It consists of a number of broad ideas regarding density estimation using transformations of autoregressive networks. Specifically, the authors examine models involving linear maps from past states (LAM) and recurrence relationships (RAM). \n\nThe critical insight is that the hidden states in the LAM are not coupled allowing considerable flexibility between consecutive conditional distributions. This is at the expense of an increased number of parameters and a lack of information sharing. In contrast, the RAM transfers information between conditional densities via the coupled hidden states allowing for more constrained smooth transitions.\n\nThe authors then explored a variety of transformations designed to increase the expressiveness of LAM and RAM. The authors importantly note that one important restriction on the class of transformations is the ability to evaluate the Jacobian of the transformation efficiently. A composite of transformations coupled with the LAM/RAM networks provides a highly expressive model for modelling arbitrary joint densities but retaining interpretable conditional structure.\n\nThere is a rich variety of synthetic and real data studies which demonstrate that LAM and RAM consistently rank amongst the top models demonstrating potential utility for this class of models.\n\nWhilst the paper provides no definitive solutions, this is not the point of the work which seeks to provide a description of a general class of potentially useful models.\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Transformation Autoregressive Networks","abstract":"The fundamental task of general density estimation has been of keen interest to machine learning. Recent advances in density estimation have either: a) proposed using a flexible model to estimate the conditional factors of the chain rule; or b) used flexible, non-linear transformations of variables of a simple base distribution. Instead, this work jointly leverages transformations of variables and autoregressive conditional models, and proposes novel methods for both. We provide a deeper understanding of our models, showing a considerable improvement with our methods through a comprehensive study over both real world and synthetic data. Moreover, we illustrate the use of our models in outlier detection and image modeling task.","pdf":"/pdf/81cd2a8aea2bd3c2e20b225c17fba46ad24086d7.pdf","paperhash":"anonymous|transformation_autoregressive_networks","_bibtex":"@article{\n  anonymous2018transformation,\n  title={Transformation Autoregressive Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1RF3ExCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper244/Authors"],"keywords":["density estimation","autoregressive models","RNNs"]}},{"tddate":null,"ddate":null,"tmdate":1512222594790,"tcdate":1511817631832,"number":2,"cdate":1511817631832,"id":"By_sZWcgz","invitation":"ICLR.cc/2018/Conference/-/Paper244/Official_Review","forum":"r1RF3ExCb","replyto":"r1RF3ExCb","signatures":["ICLR.cc/2018/Conference/Paper244/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Incremental work with unclear contribution","rating":"5: Marginally below acceptance threshold","review":"This paper offers an extension to density estimation networks that makes them better able to learn dependencies between covariates of a distribution.\n\nThis work does not seem particularly original as applying transformations to input is done in most AR estimators.\n\nUnfortunately, it's not clear if the work is better than the state-of-the-art. Most results in the paper are comparisons of toy conditional models. The paper does not compare to work for example from Papamakarios et al. on the same datasets. The one Table that lists other work showed LAM and RAM to be comparable. Many of the experiments are on synthetic results, and the paper would have benefited from concentrating on more real-world datasets.","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Transformation Autoregressive Networks","abstract":"The fundamental task of general density estimation has been of keen interest to machine learning. Recent advances in density estimation have either: a) proposed using a flexible model to estimate the conditional factors of the chain rule; or b) used flexible, non-linear transformations of variables of a simple base distribution. Instead, this work jointly leverages transformations of variables and autoregressive conditional models, and proposes novel methods for both. We provide a deeper understanding of our models, showing a considerable improvement with our methods through a comprehensive study over both real world and synthetic data. Moreover, we illustrate the use of our models in outlier detection and image modeling task.","pdf":"/pdf/81cd2a8aea2bd3c2e20b225c17fba46ad24086d7.pdf","paperhash":"anonymous|transformation_autoregressive_networks","_bibtex":"@article{\n  anonymous2018transformation,\n  title={Transformation Autoregressive Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1RF3ExCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper244/Authors"],"keywords":["density estimation","autoregressive models","RNNs"]}},{"tddate":null,"ddate":null,"tmdate":1512222594830,"tcdate":1511808721347,"number":1,"cdate":1511808721347,"id":"S1FCACYeG","invitation":"ICLR.cc/2018/Conference/-/Paper244/Official_Review","forum":"r1RF3ExCb","replyto":"r1RF3ExCb","signatures":["ICLR.cc/2018/Conference/Paper244/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Comparison with MAF missing in several Tables","rating":"5: Marginally below acceptance threshold","review":"The authors propose to combine nonlinear bijective transformations and flexible density models for density estimation. In terms of bijective change of variables transformations, they propose linear triangular transformations and recurrent transformations. They also propose to use as base transformation an autoregressive distribution with mixture of gaussians emissions.\nComparing with the Masked Autoregressive Flows (Papamakarios et al., 2017) paper, it seems that the true difference is using the linear autoregressive transformation (LAM) and recurrent autoregressive transformation (RAM), already present in the Inverse Autoregressive Flow (Kingma et al., 2016) paper they cite, instead of the masked feedforward architecture used Papamakarios et al. (2017).\nGiven that, the most important part of the paper would be to demonstrate how it performs compared to Masked Autoregressive Flows. A comparison with MAF/MADE is lacking in Table 1 and 2. Nonetheless, the comparison between models in flexible density models, change of variables transformations and combinations of both remain relevant.\n\nDiederik P. Kingma, Tim Salimans, Rafal JÃ³zefowicz, Xi Chen, Ilya Sutskever, Max Welling: Improving Variational Autoencoders with Inverse Autoregressive Flow. NIPS 2016\nGeorge Papamakarios, Theo Pavlakou, Iain Murray: Masked Autoregressive Flow for Density Estimation. NIPS 2017\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Transformation Autoregressive Networks","abstract":"The fundamental task of general density estimation has been of keen interest to machine learning. Recent advances in density estimation have either: a) proposed using a flexible model to estimate the conditional factors of the chain rule; or b) used flexible, non-linear transformations of variables of a simple base distribution. Instead, this work jointly leverages transformations of variables and autoregressive conditional models, and proposes novel methods for both. We provide a deeper understanding of our models, showing a considerable improvement with our methods through a comprehensive study over both real world and synthetic data. Moreover, we illustrate the use of our models in outlier detection and image modeling task.","pdf":"/pdf/81cd2a8aea2bd3c2e20b225c17fba46ad24086d7.pdf","paperhash":"anonymous|transformation_autoregressive_networks","_bibtex":"@article{\n  anonymous2018transformation,\n  title={Transformation Autoregressive Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1RF3ExCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper244/Authors"],"keywords":["density estimation","autoregressive models","RNNs"]}},{"tddate":null,"ddate":null,"tmdate":1509739409596,"tcdate":1509080198395,"number":244,"cdate":1509739406951,"id":"r1RF3ExCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1RF3ExCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Transformation Autoregressive Networks","abstract":"The fundamental task of general density estimation has been of keen interest to machine learning. Recent advances in density estimation have either: a) proposed using a flexible model to estimate the conditional factors of the chain rule; or b) used flexible, non-linear transformations of variables of a simple base distribution. Instead, this work jointly leverages transformations of variables and autoregressive conditional models, and proposes novel methods for both. We provide a deeper understanding of our models, showing a considerable improvement with our methods through a comprehensive study over both real world and synthetic data. Moreover, we illustrate the use of our models in outlier detection and image modeling task.","pdf":"/pdf/81cd2a8aea2bd3c2e20b225c17fba46ad24086d7.pdf","paperhash":"anonymous|transformation_autoregressive_networks","_bibtex":"@article{\n  anonymous2018transformation,\n  title={Transformation Autoregressive Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1RF3ExCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper244/Authors"],"keywords":["density estimation","autoregressive models","RNNs"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}