{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222722093,"tcdate":1512114292359,"number":3,"cdate":1512114292359,"id":"ry2OdYCeM","invitation":"ICLR.cc/2018/Conference/-/Paper701/Official_Review","forum":"rJe7FW-Cb","replyto":"rJe7FW-Cb","signatures":["ICLR.cc/2018/Conference/Paper701/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review for A Painless Attention Mechanism for Convolutional Neural Networks ","rating":"6: Marginally above acceptance threshold","review":"Paper presents an interesting attention mechanism for fine-grained image classification. Introduction states that the method is simple and easy to understand. However, the presentation of the method is bit harder to follow. It is not clear to me if the attention modules are applied over all  pooling layers. How they are combined? \n\nWhy use cross -correlation as the regulariser? Why not much stronger constraint such as orthogonality over elements of M in equation 1? What is the impact of this regularisation?\n\nWhy use soft-max in equation 1? One may use a Sigmoid as well? Is it better to use soft-max?\n\nEquation 9 is not entirely clear to me. Undefined notations.\n\nIn Table 2, why stop from AD= 2 and AW=2?  What is the performance of AD=1, AW=1 with G? Why not perform this experiment over all 5 datasets? Is this performances, dataset specific?\n\nThe method is compared against 5 datasets. Obtained results are quite good.\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"A Painless Attention Mechanism for Convolutional Neural Networks","abstract":"We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. The proposed mechanism reuses CNN feature activations to find the most informative parts of the image at different depths with the help of gating mechanisms and without part annotations. Thus, it can be used to augment any layer of a CNN to extract low- and high-level local information to be more discriminative. \n\nDifferently, from other approaches, the mechanism we propose just needs a single pass through the input and it can be trained end-to-end through SGD. As a consequence, the proposed mechanism is modular, architecture-independent, easy to implement, and faster than iterative approaches.\n\nExperiments show that, when augmented with our approach, Wide Residual Networks systematically achieve superior performance on each of five different fine-grained recognition datasets: the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100, obtaining competitive and state-of-the-art scores.","pdf":"/pdf/9503486eb36397df7ebed763ca8a6d50b3e1768c.pdf","TL;DR":"We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.","paperhash":"anonymous|a_painless_attention_mechanism_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018a,\n  title={A Painless Attention Mechanism for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJe7FW-Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper701/Authors"],"keywords":["computer vision","deep learning","convolutional neural networks","attention"]}},{"tddate":null,"ddate":null,"tmdate":1512222722135,"tcdate":1511902599415,"number":2,"cdate":1511902599415,"id":"Sky96rolf","invitation":"ICLR.cc/2018/Conference/-/Paper701/Official_Review","forum":"rJe7FW-Cb","replyto":"rJe7FW-Cb","signatures":["ICLR.cc/2018/Conference/Paper701/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Improvement gain is small","rating":"5: Marginally below acceptance threshold","review":"This paper proposes a feed-forward attention mechanism for fine-grained image classification. It is modular and can be added to any convolutional layer, the attention model uses CNN feature activations to find the most informative parts then combine with the original feature map for the final prediction. Experiments show that wide residual net together with this new attention mechanism achieve slightly better performance on several fine-grained image classification tasks.\n\nStrength of this work:\n1) It is end-to-end trainable and doesn't require multiple stages, prediction can be done in single feedforward pass.\n2) Easy to train and doesn't increase the model size a lot.\n\nWeakness:\n1) Both attention depth and attention width are small. The choice of which layer to add this module is unclear to me. \n2) No analysis on using the extra regularization loss actually helps.\n3) My main concern is the improvement gain is very small. In Table3, the gain of using the gate module is only 0.1%. It argues that this attention module can be added to any layer but experiments show only 1 layer and 1 attention map already achieve most of the improvement. From Table 4 to Table 7, WRNA compared to WRN only improve ~1% on average.  \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"A Painless Attention Mechanism for Convolutional Neural Networks","abstract":"We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. The proposed mechanism reuses CNN feature activations to find the most informative parts of the image at different depths with the help of gating mechanisms and without part annotations. Thus, it can be used to augment any layer of a CNN to extract low- and high-level local information to be more discriminative. \n\nDifferently, from other approaches, the mechanism we propose just needs a single pass through the input and it can be trained end-to-end through SGD. As a consequence, the proposed mechanism is modular, architecture-independent, easy to implement, and faster than iterative approaches.\n\nExperiments show that, when augmented with our approach, Wide Residual Networks systematically achieve superior performance on each of five different fine-grained recognition datasets: the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100, obtaining competitive and state-of-the-art scores.","pdf":"/pdf/9503486eb36397df7ebed763ca8a6d50b3e1768c.pdf","TL;DR":"We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.","paperhash":"anonymous|a_painless_attention_mechanism_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018a,\n  title={A Painless Attention Mechanism for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJe7FW-Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper701/Authors"],"keywords":["computer vision","deep learning","convolutional neural networks","attention"]}},{"tddate":null,"ddate":null,"tmdate":1512222722174,"tcdate":1511813993821,"number":1,"cdate":1511813993821,"id":"rkzOQxcgM","invitation":"ICLR.cc/2018/Conference/-/Paper701/Official_Review","forum":"rJe7FW-Cb","replyto":"rJe7FW-Cb","signatures":["ICLR.cc/2018/Conference/Paper701/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A limited evaluation and a limited contribution","rating":"5: Marginally below acceptance threshold","review":"The manuscript describes a novel attentional mechanism applied to fine-grained recognition. \n\nOn the positive side, the approach seems to consistently improve the recognition accuracy of the baseline  (a wide residual net). The approach is also consistently tested on the main fine-grained recognition datasets (the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100).\n\nOn the negative side, the paper could be better written and motivated.\n\nFirst, some claimed are made about how the proposed approach \"enhances most of the desirable properties from previous approaches” (see pp 1-2) but these claims are never backed up. More generally since the paper focuses on attention, other attentional approaches should be used as benchmarks beyond the WRN baseline. If the authors want to claim that the proposed approach is \"more robust to deformation and clutter” then they should design an experiment that shows that this is the case. \n\nBeyond, the approach seems a little ad hoc. No real rationale is provided for the different mechanisms including the gating etc and certainly no experimental validation is provided to demonstrate the need for these mechanisms. More generally, it is not clear from reading the paper specifically what computational limitation of the CNN is being solved by the proposed attentional mechanism. \n\nSome of the masks shown in Fig 3 seem rather suspicious and prompt this referee to think that the networks are seriously overfitting to the data. For instance, why would attending to a right ear help in gender recognition? \n\nThe proposed extension adds several hyperparameters (for instance the number K of attention heads). Apologies if I missed it but I am not clear how this was optimized for the experiments reported. In general, the paper could be clearer. For instance, it is not clear from either the text or Fig 2 how H goes from XxYxK for the attention head o XxYxN for the output head.\n\nAs a final point, I would say that while some of the criticisms could be addressed in a revision, the improvements seem relatively modest. Given that the focus of the paper is already limited to fine-grained recognition, it seems that the paper would be better suited for a computer vision conference.\n\n\nMinor point: \n\n\"we incorporate the advantages of visual and biological attention mechanisms” not sure this statement makes much sense. Seems like visual and biological are distinct attributes but visual attention can be biological (or not, I guess) and it is not clear how biological the proposed approach is. Certainly no attempt is made by the authors to connect to biology.\n\n\"top-down feed-forward attention mechanism” -> it should be just feed-forward attention. Not clear what \"top-down feed-forward” attention could be...","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"A Painless Attention Mechanism for Convolutional Neural Networks","abstract":"We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. The proposed mechanism reuses CNN feature activations to find the most informative parts of the image at different depths with the help of gating mechanisms and without part annotations. Thus, it can be used to augment any layer of a CNN to extract low- and high-level local information to be more discriminative. \n\nDifferently, from other approaches, the mechanism we propose just needs a single pass through the input and it can be trained end-to-end through SGD. As a consequence, the proposed mechanism is modular, architecture-independent, easy to implement, and faster than iterative approaches.\n\nExperiments show that, when augmented with our approach, Wide Residual Networks systematically achieve superior performance on each of five different fine-grained recognition datasets: the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100, obtaining competitive and state-of-the-art scores.","pdf":"/pdf/9503486eb36397df7ebed763ca8a6d50b3e1768c.pdf","TL;DR":"We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.","paperhash":"anonymous|a_painless_attention_mechanism_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018a,\n  title={A Painless Attention Mechanism for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJe7FW-Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper701/Authors"],"keywords":["computer vision","deep learning","convolutional neural networks","attention"]}},{"tddate":null,"ddate":null,"tmdate":1509739152221,"tcdate":1509132568152,"number":701,"cdate":1509739149550,"id":"rJe7FW-Cb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rJe7FW-Cb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"A Painless Attention Mechanism for Convolutional Neural Networks","abstract":"We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. The proposed mechanism reuses CNN feature activations to find the most informative parts of the image at different depths with the help of gating mechanisms and without part annotations. Thus, it can be used to augment any layer of a CNN to extract low- and high-level local information to be more discriminative. \n\nDifferently, from other approaches, the mechanism we propose just needs a single pass through the input and it can be trained end-to-end through SGD. As a consequence, the proposed mechanism is modular, architecture-independent, easy to implement, and faster than iterative approaches.\n\nExperiments show that, when augmented with our approach, Wide Residual Networks systematically achieve superior performance on each of five different fine-grained recognition datasets: the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100, obtaining competitive and state-of-the-art scores.","pdf":"/pdf/9503486eb36397df7ebed763ca8a6d50b3e1768c.pdf","TL;DR":"We enhance CNNs with a novel attention mechanism for fine-grained recognition. Superior performance is obtained on 5 datasets.","paperhash":"anonymous|a_painless_attention_mechanism_for_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018a,\n  title={A Painless Attention Mechanism for Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJe7FW-Cb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper701/Authors"],"keywords":["computer vision","deep learning","convolutional neural networks","attention"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}