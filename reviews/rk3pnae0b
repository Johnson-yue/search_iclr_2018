{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222652129,"tcdate":1511794609563,"number":3,"cdate":1511794609563,"id":"B1chwjFlz","invitation":"ICLR.cc/2018/Conference/-/Paper430/Official_Review","forum":"rk3pnae0b","replyto":"rk3pnae0b","signatures":["ICLR.cc/2018/Conference/Paper430/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting paper on a question generation approach focusing on some topics and question type with promising experimental results. ","rating":"8: Top 50% of accepted papers, clear accept","review":"The authors propose a scheme to generate questions based on some answer sentences, topics and question types. Topics are extracted from questions using similar words in question-answer pairs. It is similar to what we find in some Q&A systems (like lexical answer types in Watson). A sequence classifier is also used to tag the presence of topic words. Question types correspond mostly to salient questions words. LSTMs are used to encode the various inputs and generate the questions. \n\nThe paper is well written and easy to follow. I would expect more explanations why sentence classification and labeling results presented in Table 2 are so low. \n\nExperimental results on question generation are convincing and clearly indicate that the approach is effective to generate relevant and well-structured short questions. \n\nThe main weakness of the paper is the selected set of question types that seems to be a fuzzy combination of answer types and question types (for ex. yes/no). Some questions type can be highly ambiguous; for instance “What” might lead to a definition, a quantity, some named entities... Hence I suggest you revise your qt set. \n\nI would also suggest, for your next experiments, that you try to generate questions leading to answers with list of values. ","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topic-Based Question Generation","abstract":"Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline.","pdf":"/pdf/c77e09b95d892bdd9df1235bdbb55c56275098dd.pdf","TL;DR":"We propose a neural network that is able to generate topic-specific questions.","paperhash":"anonymous|topicbased_question_generation","_bibtex":"@article{\n  anonymous2018topic-based,\n  title={Topic-Based Question Generation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk3pnae0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper430/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222652172,"tcdate":1511769644601,"number":2,"cdate":1511769644601,"id":"HyrNUBYlz","invitation":"ICLR.cc/2018/Conference/-/Paper430/Official_Review","forum":"rk3pnae0b","replyto":"rk3pnae0b","signatures":["ICLR.cc/2018/Conference/Paper430/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review from AnonReviewer1","rating":"4: Ok but not good enough - rejection","review":"This paper proposed a topic-based question generation method, which requires the input of target topic in addition to the descriptive text. In the proposed method, the authors first extract the topic based on the similarity of the target question token and answer token using word embedding. Then, the author proposed a topic-specific question generation model by encoding the extracted topic using LSTM and a pre-decode technique that the second decoding is conditioned on the hidden representation of the first decoding result. The authors performed the experiment on AQAD dataset, and show their performance achieve state-of-the-art result when using automatically generated topic, and perform better when using the ground truth topic. \n\n[Strenghts]\n\nThis paper introduced a topic-based question generation model, which generate question conditioned on the topic and question type. The authors proposed heuristic method to extract the topic and question type without further annotation. The proposed model can generate question with respect to different topic and pre-decode seems a useful trick. \n\n[Weaknesses]\n\nThis paper proposed an interesting and intuitive question generation model. However, there are several weaknesses existed:\n\n1: It's true that given a descriptive text, it is often possible to ask many types of questions. But it also leads to different answers. In this paper, the authors treat the descriptive text as answers, is this motivation still true if the question generation is conditioned on answers, not descriptive text? Table 4 shows some examples, given the sentence, even conditioned on different topics, the generated question is similar. \n\n2: In terms of the experiment,  the authors use AQAD to evaluate proposed method. When the ground truth topic is provided, it's not fair to compare with the previous method, since knowing the similar word present in the answer will have great benefits to question generation. \n\nIf we only consider the automatically generated topic, the performance of the proposed model is similar to the previous method (Du et al). Without the pre-decode technique, the performance is even worse. \n\n3: In section 4.2, the authors claim this is the theoretical explanation of the generalization capability of the proposed model (also appear in topic effect analysis). It is true that the proposed method may have better compositionality, but I didn't see any **theoretical** explantation about this. \n\n4: The automatically extracted topic can be very noisy, but the paper didn't mention any of the extracted topics on AQAD dataset. \n\n[Summary]\n\na topic-based question generation method, which requires the input of target topic in addition to the descriptive text. However, as I pointed out above, there are several weaknesses in the paper. Taking all these into account, I think this paper still needs more works to make it solid and comprehensive before being accepted.\nAdd Comment","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topic-Based Question Generation","abstract":"Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline.","pdf":"/pdf/c77e09b95d892bdd9df1235bdbb55c56275098dd.pdf","TL;DR":"We propose a neural network that is able to generate topic-specific questions.","paperhash":"anonymous|topicbased_question_generation","_bibtex":"@article{\n  anonymous2018topic-based,\n  title={Topic-Based Question Generation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk3pnae0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper430/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222652211,"tcdate":1511670819943,"number":1,"cdate":1511670819943,"id":"rk27E6PlG","invitation":"ICLR.cc/2018/Conference/-/Paper430/Official_Review","forum":"rk3pnae0b","replyto":"rk3pnae0b","signatures":["ICLR.cc/2018/Conference/Paper430/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Motivation, experiments, and evaluation are flawed","rating":"3: Clear rejection","review":"This paper presents a neural network-based approach to generate topic-specific questions with the motivation that topical questions are more meaningful in practical applications like real-world conversations. Experiments and evaluation have been conducted on the AQAD corpus to show the effectiveness of the approach.\n\nAlthough the main contributions are clear, the paper contains numerous typos, grammatical errors, incomplete sentences, and a lot of discrepancies between text, notations, and figures making it ambiguous and difficult to follow. \n\nAuthors claim to generate topic-specific questions, however, the dataset choice, experiments, and examples show that the generated questions are essentially keyword/key phrase-based. This is also apparent in Section 4.1 where authors present some observation without any supporting proof or empirical evidence. Moreover, the example in Figure 1 shows a conversation, but, typically, in an ongoing multi-round conversation people do not tend to repeat the keywords or key phrases or named entities, and topic shifts might occur at any time. \n\nOverall, a misconception about topic vs. keywords might have led the authors to claim that their work is the first to generate topic-specific questions whereas this has been studied before by Chali & Hasan (2015) in a non-neural setting. \"Topic\" in general has a broader meaning, I would suggest authors to see this to get an idea about what topic entails to in a conversational setting: https://developer.amazon.com/alexaprize/contest-rules . I think the proposed work is mostly related to: 1) \"Towards Natural Question-Guided Search\" by Kotov and Zhai (2010), and 2) \"K2Q: Generating Natural Language Questions from Keywords with User Refinements\" by Zheng et al. (2011), and other recent factoid question generation papers where questions are generated from a given fact (e.g. \"Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus\" by Serban et al. (2016)).\n\nIt is not clear how the question types are extracted from the given sentences. Please provide details. Which keywords are employed to accomplish this? Also, please explain the absence of the \"why\" type question. \n\nFigure 3 and the associated descriptions are very hard to follow. Please draw the figure by matching it with the descriptions.  Where are the bi-LSTMs in the figure? What are ac_t and em_t? \n\nMy major concern is with the experiments and evaluation. The dataset essentially contains questions about product reviews and does not match authors motivation/observation about real-world conversations. Moreover, evaluation has been conducted on a very small test set (just about 1% of the selected corpus), making the results unconvincing. More details are necessary about how exactly Kim's and Liu's models are used to get question types and topics. \n\nHuman evaluation results per category would have been more useful. How did you combine the scores of the human evaluation categories? Also, automatic evaluation and human evaluation results do not correlate well. Please explain.\n\n\n\n\n\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topic-Based Question Generation","abstract":"Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline.","pdf":"/pdf/c77e09b95d892bdd9df1235bdbb55c56275098dd.pdf","TL;DR":"We propose a neural network that is able to generate topic-specific questions.","paperhash":"anonymous|topicbased_question_generation","_bibtex":"@article{\n  anonymous2018topic-based,\n  title={Topic-Based Question Generation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk3pnae0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper430/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509739307814,"tcdate":1509117123843,"number":430,"cdate":1509739305139,"id":"rk3pnae0b","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rk3pnae0b","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Topic-Based Question Generation","abstract":"Asking questions is an important ability for a chatbot. This paper focuses on question generation. Although there are existing works on question generation based on a piece of descriptive text, it remains to be a very challenging problem. In the paper, we propose a new question generation problem, which also requires the input of a target topic in addition to a piece of descriptive text. The key reason for proposing the new problem is that in practical applications, we found that useful questions need to be targeted toward some relevant topics. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. To solve the problem, we propose a novel neural network that is able to generate topic-specific questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating topics in the questions or answers. Experimental results show that our model outperforms the state-of-the-art baseline.","pdf":"/pdf/c77e09b95d892bdd9df1235bdbb55c56275098dd.pdf","TL;DR":"We propose a neural network that is able to generate topic-specific questions.","paperhash":"anonymous|topicbased_question_generation","_bibtex":"@article{\n  anonymous2018topic-based,\n  title={Topic-Based Question Generation},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rk3pnae0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper430/Authors"],"keywords":[]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}