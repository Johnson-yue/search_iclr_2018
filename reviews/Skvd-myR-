{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222564942,"tcdate":1511843253074,"number":2,"cdate":1511843253074,"id":"SkT3Sw9lG","invitation":"ICLR.cc/2018/Conference/-/Paper120/Official_Review","forum":"Skvd-myR-","replyto":"Skvd-myR-","signatures":["ICLR.cc/2018/Conference/Paper120/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Motivation is unclear and more evaluations are needed","rating":"4: Ok but not good enough - rejection","review":"(1) The motivation\nThe paper argues that it is more suitable to use non-metric distances instead of metric distances. However, the distance function used in this work is cosine similarity between two l2 normalized features. It is known that in such a situation, cosine similarity is equivalent to Euclidean distance. The motivation should be further explained.\n\n(2) In Eq. (5), I am not sure why not directly set y_ij = 1 if two images come from the same category, and set to 0 otherwise. It is weird to see the annotation is related to the input features considering that we already have the groundtruth labels.\n\n(3) The whole pipeline is not trained in an end-to-end manner. It requires some other features as the input (RMAC used in this work), and three-stage training. It is interesting to see some more experiments where image pixels are the input.\n\n(4) The algorithm is not comparable to the state-of-the-art. Some representative papers have reported much better performances on the datasets used in this paper. It is suggested to refer to some recent papers in top conferences.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Non-Metric Visual Similarity for Image Retrieval","abstract":"Measuring visual (dis)similarity between two or more instances within a data distribution is a fundamental task in many applications, specially in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the similarity model. In this work, we analyze a simple approach for deep learning networks to be used as an approximation of non-metric similarity functions and we study how these models generalize across different image retrieval datasets.","pdf":"/pdf/c579ff9c4ebe8447f77750c548584ef8615af0ea.pdf","TL;DR":"Similarity network to learn a non-metric visual similarity estimation between a pair of images","paperhash":"anonymous|learning_nonmetric_visual_similarity_for_image_retrieval","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Non-Metric Visual Similarity for Image Retrieval},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Skvd-myR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper120/Authors"],"keywords":["image retrieval","visual similarity","non-metric learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222564982,"tcdate":1511809715891,"number":1,"cdate":1511809715891,"id":"By32fJqlG","invitation":"ICLR.cc/2018/Conference/-/Paper120/Official_Review","forum":"Skvd-myR-","replyto":"Skvd-myR-","signatures":["ICLR.cc/2018/Conference/Paper120/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Pushing the performance in image retrieval by learning a non-metric similarity","rating":"7: Good paper, accept","review":"The authors of this work propose learning a similarity measure for visual similarity and obtain, by doing that, an improvement in the very well-known datasets of Oxford and Paris for image retrieval. The work takes high-level image representations generated with an existing architecture (R-MAC), and train on top a neural network of two fully connected layers. \n\nThe training of such network is performed in three stages: firstly approximating the cosine similarity with a large amount of random feature vectors, secondly using image pairs from the same class, and finally using the hard examples.\n\n\nPROS\n\nP1. Results indicate the benefit of this approach in terms of similarity estimation and, overall, the paper present results that extend the state of the art in well-known datasets. \n\nP2. The authors make a very nice effort in motivation the paper, relating it with the state of the art and funding their proposal on studies regarding human visual perception. The whole text is very well written and clear to follow.\n\nCONS\n\nC1. As already observed by the authors, training a similarity function without considering images from the target dataset is actually harmful. In this sense, the simple cosine similarity does not present this drawback in terms of lack of generalization. This observation is not new, but relevant in the field of image retrieval, where in many applications the object of interest for a query is actually not present in the training dataset.\n\nC2. The main drawback of this approach is in terms of computation. Feed-forwarding the two samples through the trained neural network is far more expensive that computing the simple cosine similarity, which is computed very quickly with a GPU as a matrix multiplication. The authors already point at this in Section 4.3.\n\nC3. I am somehow surprised that the authors did not explore also training the network that would extract the high-level representations, that is, a complete end-to-end approach. While I would expect to have the weights frozen in the first phase of training to miimic the cosine similarity, why not freeing the rest of layers when dealing with pairs of images ?\n\nC4. There are a couple of recent papers that include results of the state of the art which are closer and sometimes better than the ones presented in this work. I do not think they reduce at all the contribution of this work, but they should be cited and maybe included in the tables:\n\nA. Gordo, J. Almazan, J. Revaud, and D. Larlus. End-to-end learning of deep visual representations for image retrieval.\nInternational Journal of Computer Vision, 124(2):237–254, 2017.\n\nAlbert Jimenez, Jose M. Alvarez, and Xavier Giro-i-Nieto. “Class-Weighted Convolutional Features for Visual Instance Search.” In Proceedings of the 28th British Machine Vision Conference (BMVC). 2017.\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Non-Metric Visual Similarity for Image Retrieval","abstract":"Measuring visual (dis)similarity between two or more instances within a data distribution is a fundamental task in many applications, specially in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the similarity model. In this work, we analyze a simple approach for deep learning networks to be used as an approximation of non-metric similarity functions and we study how these models generalize across different image retrieval datasets.","pdf":"/pdf/c579ff9c4ebe8447f77750c548584ef8615af0ea.pdf","TL;DR":"Similarity network to learn a non-metric visual similarity estimation between a pair of images","paperhash":"anonymous|learning_nonmetric_visual_similarity_for_image_retrieval","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Non-Metric Visual Similarity for Image Retrieval},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Skvd-myR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper120/Authors"],"keywords":["image retrieval","visual similarity","non-metric learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739473714,"tcdate":1509007726823,"number":120,"cdate":1509739471060,"id":"Skvd-myR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Skvd-myR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Non-Metric Visual Similarity for Image Retrieval","abstract":"Measuring visual (dis)similarity between two or more instances within a data distribution is a fundamental task in many applications, specially in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the similarity model. In this work, we analyze a simple approach for deep learning networks to be used as an approximation of non-metric similarity functions and we study how these models generalize across different image retrieval datasets.","pdf":"/pdf/c579ff9c4ebe8447f77750c548584ef8615af0ea.pdf","TL;DR":"Similarity network to learn a non-metric visual similarity estimation between a pair of images","paperhash":"anonymous|learning_nonmetric_visual_similarity_for_image_retrieval","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Non-Metric Visual Similarity for Image Retrieval},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Skvd-myR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper120/Authors"],"keywords":["image retrieval","visual similarity","non-metric learning"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}