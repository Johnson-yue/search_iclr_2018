{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222701096,"tcdate":1512030203895,"number":3,"cdate":1512030203895,"id":"ryEbgBTxG","invitation":"ICLR.cc/2018/Conference/-/Paper61/Official_Review","forum":"HkgNdt26Z","replyto":"HkgNdt26Z","signatures":["ICLR.cc/2018/Conference/Paper61/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Very relevant for the application in mind. Too simple for publication.","rating":"4: Ok but not good enough - rejection","review":"This paper discusses the application of word prediction for software keyboards. The goal is to customize the predictions for each user to account for member specific information while adhering to the strict compute constraints and privacy requirements. \n\nThe authors propose a simple method of mixing the global model with user specific data. Collecting the user specific models and averaging them to form the next global model. \n\nThe proposal is practical. However, I am not convinced that this is novel enough for publication at ICLR. \n\nOne major question. The authors assume that the global model will depict general english. However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English. It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Distributed Fine-tuning of Language Models on Private Data","abstract":"One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, the language of users (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge (i.e. general model of English). We study approaches to distributed fine-tuning of a general model on user private data with the additional requirement of maintaining the quality on the general data. Our experiments demonstrate that a technique based on model averaging and random rehearsal outperforms an approach based on transfer learning, and show that the proposed method improves prediction quality in a reasonable time. The procedure leads to an 8.7 percentage point improvement in keystroke saving rate on informal English texts compared to a basic model trained on Wikipedia. We also propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.","pdf":"/pdf/a2d5b1e271af91343f01fd76f26fc90aa923c0b1.pdf","TL;DR":"We propose a method of distributed fine-tuning of language models on user devices without collection of private data","paperhash":"anonymous|distributed_finetuning_of_language_models_on_private_data","_bibtex":"@article{\n  anonymous2018distributed,\n  title={Distributed Fine-tuning of Language Models on Private Data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkgNdt26Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper61/Authors"],"keywords":["distributed training","federated learning","language modeling","differential privacy"]}},{"tddate":null,"ddate":null,"tmdate":1512222701136,"tcdate":1511831127414,"number":2,"cdate":1511831127414,"id":"H1ywUV9gf","invitation":"ICLR.cc/2018/Conference/-/Paper61/Official_Review","forum":"HkgNdt26Z","replyto":"HkgNdt26Z","signatures":["ICLR.cc/2018/Conference/Paper61/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The relevance of this paper to ICLR is low and the details of the experiments are missing.","rating":"4: Ok but not good enough - rejection","review":"my main concern is the relevance of this paper to ICLR.\nThis paper is much related not to representation learning but to user-interface.\nThe paper is NOT well organized and so the technical novelty of the method is unclear.\nFor example, the existing method and proposed method seems to be mixed in Section 2.\nYou should clearly divide the existing study and your work. \nThe experimental setting is also unclear.\nKSS seems to need the user study.\nBut I do not catch the details of the user study, e.g., the number of users.\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Distributed Fine-tuning of Language Models on Private Data","abstract":"One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, the language of users (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge (i.e. general model of English). We study approaches to distributed fine-tuning of a general model on user private data with the additional requirement of maintaining the quality on the general data. Our experiments demonstrate that a technique based on model averaging and random rehearsal outperforms an approach based on transfer learning, and show that the proposed method improves prediction quality in a reasonable time. The procedure leads to an 8.7 percentage point improvement in keystroke saving rate on informal English texts compared to a basic model trained on Wikipedia. We also propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.","pdf":"/pdf/a2d5b1e271af91343f01fd76f26fc90aa923c0b1.pdf","TL;DR":"We propose a method of distributed fine-tuning of language models on user devices without collection of private data","paperhash":"anonymous|distributed_finetuning_of_language_models_on_private_data","_bibtex":"@article{\n  anonymous2018distributed,\n  title={Distributed Fine-tuning of Language Models on Private Data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkgNdt26Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper61/Authors"],"keywords":["distributed training","federated learning","language modeling","differential privacy"]}},{"tddate":null,"ddate":null,"tmdate":1512222701177,"tcdate":1511780829275,"number":1,"cdate":1511780829275,"id":"ByBJfdKxM","invitation":"ICLR.cc/2018/Conference/-/Paper61/Official_Review","forum":"HkgNdt26Z","replyto":"HkgNdt26Z","signatures":["ICLR.cc/2018/Conference/Paper61/AnonReviewer1"],"readers":["everyone"],"content":{"title":"More explanations on the assumption are required","rating":"5: Marginally below acceptance threshold","review":"This paper deals with improving language models on mobile equipments\nbased on small portion of text that the user has ever input. For this\npurpose, authors employed a linearly interpolated objectives between user\nspecific text and general English, and investigated which method (learning\nwithout forgetting and random reheasal) and which interepolation works better.\nMoreover, authors also look into privacy analysis to guarantee some level of\ndifferential privacy is preserved.\n\nBasically the motivation and method is good, the drawback of this paper is\nits narrow scope and lack of necessary explanations. Reading the paper,\nmany questions arise in mind:\n\n- The paper implicitly assumes that the statistics from all the users must\n  be collected to improve \"general English\". Why is this necessary? Why not\n  just using better enough basic English and the text of the target user?\n\n- To achieve the goal above, huge data (not the \"portion of the general English\") should be communicated over the network. Is this really worth doing? If only\n  \"the portion of\" general English must be communicated, why is it validated?\n\n- For measuring performance, authors employ keystroke saving rate. For the\n  purpose of mobile input, this is ok: but the use of language models will\n  cover much different situation where keystrokes are not necessarily \n  available, such as speech recognition or machine translation. Since this \n  paper is concerned with a general methodology of language modeling, \n  perplexity improvement (or other criteria generally applicable) is also\n  important.\n\n- There are huge number of previous work on context dependent language models,\n  let alone a mixture of general English and specific models. Are there any\n  comparison with these previous efforts?\n\nFinally, this research only relates to ICLR in that the language model employed\nis LSTM: in other aspects, it easily and better fit to ordinary NLP conferences, such as EMNLP, NAACL or so. I would like to advise the authors to submit\nthis work to such conferences where it will be reviewed by more NLP experts.\n\nMinor:\n- t of $G_t$ in page 2 is not defined so far.\n- What is \"gr\" in Section 2.2?\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Distributed Fine-tuning of Language Models on Private Data","abstract":"One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, the language of users (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge (i.e. general model of English). We study approaches to distributed fine-tuning of a general model on user private data with the additional requirement of maintaining the quality on the general data. Our experiments demonstrate that a technique based on model averaging and random rehearsal outperforms an approach based on transfer learning, and show that the proposed method improves prediction quality in a reasonable time. The procedure leads to an 8.7 percentage point improvement in keystroke saving rate on informal English texts compared to a basic model trained on Wikipedia. We also propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.","pdf":"/pdf/a2d5b1e271af91343f01fd76f26fc90aa923c0b1.pdf","TL;DR":"We propose a method of distributed fine-tuning of language models on user devices without collection of private data","paperhash":"anonymous|distributed_finetuning_of_language_models_on_private_data","_bibtex":"@article{\n  anonymous2018distributed,\n  title={Distributed Fine-tuning of Language Models on Private Data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkgNdt26Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper61/Authors"],"keywords":["distributed training","federated learning","language modeling","differential privacy"]}},{"tddate":null,"ddate":null,"tmdate":1509739507639,"tcdate":1508837416143,"number":61,"cdate":1509739504984,"id":"HkgNdt26Z","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkgNdt26Z","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Distributed Fine-tuning of Language Models on Private Data","abstract":"One of the big challenges in machine learning applications is that training data can be different from the real-world data faced by the algorithm. In language modeling, the language of users (e.g. in private messaging) could change in a year and be completely different from what we observe in publicly available data. At the same time, public data can be used for obtaining general knowledge (i.e. general model of English). We study approaches to distributed fine-tuning of a general model on user private data with the additional requirement of maintaining the quality on the general data. Our experiments demonstrate that a technique based on model averaging and random rehearsal outperforms an approach based on transfer learning, and show that the proposed method improves prediction quality in a reasonable time. The procedure leads to an 8.7 percentage point improvement in keystroke saving rate on informal English texts compared to a basic model trained on Wikipedia. We also propose an experimental framework for evaluating differential privacy of distributed training of language models and show that our approach has good privacy guarantees.","pdf":"/pdf/a2d5b1e271af91343f01fd76f26fc90aa923c0b1.pdf","TL;DR":"We propose a method of distributed fine-tuning of language models on user devices without collection of private data","paperhash":"anonymous|distributed_finetuning_of_language_models_on_private_data","_bibtex":"@article{\n  anonymous2018distributed,\n  title={Distributed Fine-tuning of Language Models on Private Data},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkgNdt26Z}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper61/Authors"],"keywords":["distributed training","federated learning","language modeling","differential privacy"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}