{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222764051,"tcdate":1511794663506,"number":3,"cdate":1511794663506,"id":"HJygOiYxM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A well written paper with somehow weak experimental results","rating":"5: Marginally below acceptance threshold","review":"The authors present a new scheme for applying adversarial networks to dialog generation. The idea of why using adversarial networks is important in dialog generation is really well motivated in the paper and related works are discussed in details. \n\nIn the proposed approach, a more flexible discrimination score is obtained by treating independently each sub-sequence of the input. Technically speaking, the authors' contribution is to add a set of free parameters in the sub-sequence discriminator sum of equation 8. From a more general point of view, what is the key output of the paper, except to confirm that curriculum learning can help in dialog generation?  \n\nThe experiments do not seem to show that a net performance improvement can be associated with the introduced free weights and what is a good strategy to tune them in an optimal way. In general, as the authors report also in the abstract, the performance of the proposed algorithm is 'comparable' with the state of the art but never outperforms other existing methods in a consistent way. \n\nIn fact, the performance of the algorithms depends strongly on the specific grammar used to generate the dataset and on the specific evaluation score. The human evaluation experiment is interesting but the proposed method is only compared with one other algorithm (seqGAN) and only two examples of the output are given explicitly.\n\nThe increase in computational cost due to the weighted sub-sequence evaluation is also poorly discussed.   \n\nFew more questions:\n-through the experiments section, the authors focus on evaluating the set of possible good answers (softmax and coverage score) instead of the best answer (argmax). Why is this important for dialog generation? In the generation of a real conversation, shouldn t one always choose the argmax option? What would be a practical use of the second and third-best options?\n-why softmax is always lower than argmax in the synthetic experiment and always higher than argmax in the human evaluation experiment?\n-why MLE, which is used as initialization, does better than all optimized models in the first simulation? Why is the GAN approach expected to increase the coverage compared to MLE? And why, in general, this is not always the case?\n-would it be possible to compare the output of the proposed methods with the output of a non-GAN conditional sequence generator (if any) on human-scored dialog?  ","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is famously composed of input-output pairs with one-to-many property. Recently, the success of generative adversarial network (GAN) has attributed researchers to apply GAN on sequence generation. However, there are still limited researches on the conditional sequence generation. We then investigate the influence of GAN on conditional sequence generation with three artificial grammars which share similar properties with dialogue generation. We compare the state-of-the-art GAN related algorithms by evaluation indexes: the accuracy and the coverage of answers. Moreover, we proposed every step GAN (ESGAN)  for conditional sequence generation, which predicts reward at each time-step. ESGAN can be considered as the general version of SeqGAN including MCMC and REGS in the model. We also explore energy-based ESGAN (EBESGAN). These then solve the sparse rewards problem in reinforcement learning. In addition, with weighted rewards for every steps, the advantage of curriculum learning is also included. The experimental results show that ESGAN and EBESGAN are usually comparable with the state-of-the-art algorithms, and sometimes outperform them.","pdf":"/pdf/b596704e61e32204e13d398234c0bbb6b2c8c2ce.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_evaluating_at_every_generation_step","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1512222764094,"tcdate":1511790086039,"number":2,"cdate":1511790086039,"id":"HyRbL5YxM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting and potentially powerful approach to language generation, but incomplete and lacking insight / more thorough evaluation","rating":"4: Ok but not good enough - rejection","review":"The approach is interesting, but as a contribution the paper has a long way to go. The ideas are there and everything seems correct, but there’s little motivation / insight on the model and why it might be better than competing methods for NLP tasks.\n\nIt would be good to see some sort of concrete analysis as far as what the model is doing (for instance how the discriminator scores change), and a comparison of how the reward signal given here might differ from other methods (SeqGAN, MaliGAN), and why this might be better. All we get is some scores, but it’s never clear why these scores indicate good (conditional) language generation. Can we not also look at BLEU scores for language generation or some other metric?\n\nFinally, the writing need to be improved: it starts out OK, but it progressively gets worse and worse.\n\nDetailed notes:\nP2\nIt might be good to mention beam search and scheduled sampling as other common methods to address the exposure bias.\n“objective function irrelevant to backpropagation”: what does this mean?\nMaliGAN actually also uses a “policy gradient”, which corresponds to an estimate of the likelihood ratio, to address the discrete problem.\nThough distinct from this work, Gulrajani used a CNN.\n\nP3\nUse \\log for logarithm\n“Moreover, the likelihood is only estimated at word-level”: is this true? It seems to me that likelihood of the sequence is estimated as well.\n\nP5\nWhy is this a generalized version of SeqGAN? The claim the discriminator value D(x_1..t | y) is the same as what you would get from a full-sequence generator using MCMC seems like a stretch.\nDid you not use a baseline?\nYou might want to build in a little more motivation for these different update rules. I think I understand that (10) is meant to accumulate credit across the rest of the sequence, while (11) does not, but it would be good to have this clearly stated. Why do you think one would work better than the other?\n\nP6\n“The generator G, in the mean time, struggle to maximize the likelihood of discriminator D” I don’t understand what this means.\nWhat was the motivation for using the same model here? Is the energy in this formulation related in any ways to EBGAN? Could you do something similar with separate parameters? Why would be or why would this not be a good idea?\nI do like these synthetic tasks. I think that more analyses would be helpful in understanding what the model (and what competing models) are doing.\n\nP7:\nWhat is VLGAN in the table?\nPerhaps it would be worth exploring changing alpha through optimization?\n\nP8:\nIt seems like many of the improvements in the table are marginal (with some exceptions): is it possible that ESGAN was optimized better?\n“auxiliary tricks” I would avoid this wording.\n\nOther comments on experiments:\nIt seems like the actual NLP part of this paper is quite sparse. Why was MaliGAN left out of the real experiments?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is famously composed of input-output pairs with one-to-many property. Recently, the success of generative adversarial network (GAN) has attributed researchers to apply GAN on sequence generation. However, there are still limited researches on the conditional sequence generation. We then investigate the influence of GAN on conditional sequence generation with three artificial grammars which share similar properties with dialogue generation. We compare the state-of-the-art GAN related algorithms by evaluation indexes: the accuracy and the coverage of answers. Moreover, we proposed every step GAN (ESGAN)  for conditional sequence generation, which predicts reward at each time-step. ESGAN can be considered as the general version of SeqGAN including MCMC and REGS in the model. We also explore energy-based ESGAN (EBESGAN). These then solve the sparse rewards problem in reinforcement learning. In addition, with weighted rewards for every steps, the advantage of curriculum learning is also included. The experimental results show that ESGAN and EBESGAN are usually comparable with the state-of-the-art algorithms, and sometimes outperform them.","pdf":"/pdf/b596704e61e32204e13d398234c0bbb6b2c8c2ce.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_evaluating_at_every_generation_step","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1512222764138,"tcdate":1511704613231,"number":1,"cdate":1511704613231,"id":"HkTXuSulM","invitation":"ICLR.cc/2018/Conference/-/Paper780/Official_Review","forum":"r1YqWz-R-","replyto":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference/Paper780/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The paper is concerned with improving the sequence generation problem, in particular, for dialogue generation problem. The main contribution is in proposing to compute the cumulative reward for each step in the sequence generation procedure. The paper demonstrates that this leads to better performance in artificially generated grammar and for dialogue generation.","rating":"4: Ok but not good enough - rejection","review":"Quality: The paper proposes a direct improvement over SeqGAN by Yu. et. al. (2017). My assessment is partially determined by comparing this paper to Yu et. al (2017). In my opinion, this paper is lacking in quality in comparison to Yu et. al (2017). In particular, Yu et. al. (2017) provides detailed derivation of the policy gradient accompanied by a pseudo-code (algorithm) on how one can implement SeqGAN. On the contrary, this paper does not provide such details. Perhaps, all of the details of SeqGAN follows immediately, but the paper should not assume that all readers will be familiar with SeqGAN. \n\nClarity: \n\n1. The paper provides a review of related methods on conditional sequence generation in Section 3. However, it is very brief and as a non-expert in this field, I needed to refer to the original papers anyways. Perhaps, the review of the related methods can go to the Appendix and this space can be better utilized to expand on the original contributions made by the paper. \n2. MCMC (Markov chain Monte Carlo) is mentioned in 4.1 but it is not explained. \n3. Figure 1 is not sufficiently explained; neither in text nor in the figure caption. It would help greatly to describe the details of the network architecture shown in this figure.\n\nOriginality: The paper proposes a generalization of SeqGAN; however, in my opinion, the methodological contribution appears to be only incremental on SeqGAN. \n\nSignificance: The paper's significance may be evaluated in terms of its impact on applications as it proposes an improvement over the previous work of SeqGAN. However, the extent to which the evaluation is carried out is somewhat unsatisfactory with only one real application. Also, the applications considered in the experiments are primarily on dialogue generation. My initial impression is that the methodology lacks generality and may perhaps cater better to domain specific publication venues. \n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is famously composed of input-output pairs with one-to-many property. Recently, the success of generative adversarial network (GAN) has attributed researchers to apply GAN on sequence generation. However, there are still limited researches on the conditional sequence generation. We then investigate the influence of GAN on conditional sequence generation with three artificial grammars which share similar properties with dialogue generation. We compare the state-of-the-art GAN related algorithms by evaluation indexes: the accuracy and the coverage of answers. Moreover, we proposed every step GAN (ESGAN)  for conditional sequence generation, which predicts reward at each time-step. ESGAN can be considered as the general version of SeqGAN including MCMC and REGS in the model. We also explore energy-based ESGAN (EBESGAN). These then solve the sparse rewards problem in reinforcement learning. In addition, with weighted rewards for every steps, the advantage of curriculum learning is also included. The experimental results show that ESGAN and EBESGAN are usually comparable with the state-of-the-art algorithms, and sometimes outperform them.","pdf":"/pdf/b596704e61e32204e13d398234c0bbb6b2c8c2ce.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_evaluating_at_every_generation_step","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]}},{"tddate":null,"ddate":null,"tmdate":1509739107098,"tcdate":1509134736900,"number":780,"cdate":1509739104442,"id":"r1YqWz-R-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1YqWz-R-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step","abstract":"Conditional sequence generation is a widely researched topic. One of the most important tasks is dialogue generation, which is famously composed of input-output pairs with one-to-many property. Recently, the success of generative adversarial network (GAN) has attributed researchers to apply GAN on sequence generation. However, there are still limited researches on the conditional sequence generation. We then investigate the influence of GAN on conditional sequence generation with three artificial grammars which share similar properties with dialogue generation. We compare the state-of-the-art GAN related algorithms by evaluation indexes: the accuracy and the coverage of answers. Moreover, we proposed every step GAN (ESGAN)  for conditional sequence generation, which predicts reward at each time-step. ESGAN can be considered as the general version of SeqGAN including MCMC and REGS in the model. We also explore energy-based ESGAN (EBESGAN). These then solve the sparse rewards problem in reinforcement learning. In addition, with weighted rewards for every steps, the advantage of curriculum learning is also included. The experimental results show that ESGAN and EBESGAN are usually comparable with the state-of-the-art algorithms, and sometimes outperform them.","pdf":"/pdf/b596704e61e32204e13d398234c0bbb6b2c8c2ce.pdf","paperhash":"anonymous|improving_conditional_sequence_generative_adversarial_networks_by_evaluating_at_every_generation_step","_bibtex":"@article{\n  anonymous2018improving,\n  title={Improving Conditional Sequence Generative Adversarial Networks by Evaluating at Every Generation Step},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YqWz-R-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper780/Authors"],"keywords":["conditional sequence generation","generative adversarial network","REINFORCE","dialogue generation"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}