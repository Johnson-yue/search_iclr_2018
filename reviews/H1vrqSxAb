{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222604018,"tcdate":1511987160052,"number":3,"cdate":1511987160052,"id":"rJlJd93ef","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Review of Assessing Generalization Capability of Convolutional Neural Networks","rating":"5: Marginally below acceptance threshold","review":"The paper presents a series of empirical studies of the generalization ability of convolutional neural networks (CNNs) applied to image recognition tasks related to shape images.  The paper makes a number of observations about the learning or transfer learning of shape bias vs. color by controlling and manipulating the input of training data based on shapes, negative shapes, and random images.   A concluding observation is that CNN models learn and generalize the structure content of images.\n\nThe work is described in sufficient detail including the experimental setups, data set, neural networks, and results.  The experiments should be reproducible given the descriptions in the paper.\n\nThe overall significance of the results is not very strong since the paper focuses solely on experiments conducted on very limited data and artificially manipulated data.  It is not clear how the observations made from the experiments generalize beyond these specific learning tasks or how one may take advantage of them in practice. \n\nOne way to greatly improve the impact of the paper would be to take the observations made from the simulated data experiments (e.g., MNIST) and use them to make changes to how CNN training is done on another real task (e.g., ImageNet) and show improvements in performance.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Generalization Capability of Convolutional Neural Networks","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/40da0c20702f9dba41a1a197de84c93805bafa95.pdf","paperhash":"anonymous|assessing_generalization_capability_of_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1512222604066,"tcdate":1511818272531,"number":2,"cdate":1511818272531,"id":"SkdQ4Z5xz","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This paper studies the generalization capability of CNNs on object shapes. In particular, it trains CNNs with negative images with different architectures, regularizations, etc. The approach is heuristic, and the conclusion is not very surprising.","rating":"5: Marginally below acceptance threshold","review":"Pros: \nThe paper is clearly written and studies an interesting problem. \nThe transferrability of features described in Section 6 is interesting.\n\nCons:\n\n1. The title “assessing the generalization capability of CNNs” is too broad, as the paper is only studying a narrow aspect of generalization.\n\n2. One of the conclusions of the paper is: “Although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors.” The conclusion is obvious when we train the network to make it invariant to colors and textures.  If the emphasis of this conclusion is on  the number of images needed, then it will be good to show more analysis on Figure 6: e.g. Why does the accuracy curve drops to zero before going up? Are the negative images messing up the training when the number is between 10^1 and 10^2?\n\n3. Negative images are fast to obtain, but they are oversimplified, and can be obtained via linear transform which is easy for neural networks. Therefore it is not very convincing whether the conclusion applies to other types of data, e.g. train/test on RGB&Gray image pairs, which are more commonly seen. Larger scale experiments on ImageNet is also recommended to show how general the conclusion of the paper is.\n\n4. The transferrability of features in Section 6 is an interesting problem to explore. It could provide more insights to practical problems if more experiments were done: e.g. can this technique help domain adaptation?\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Generalization Capability of Convolutional Neural Networks","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/40da0c20702f9dba41a1a197de84c93805bafa95.pdf","paperhash":"anonymous|assessing_generalization_capability_of_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1512222604108,"tcdate":1511743158560,"number":1,"cdate":1511743158560,"id":"BJ1p0Adxz","invitation":"ICLR.cc/2018/Conference/-/Paper260/Official_Review","forum":"H1vrqSxAb","replyto":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference/Paper260/AnonReviewer3"],"readers":["everyone"],"content":{"title":"A lot of experiments, but the concusions are a bit confused","rating":"4: Ok but not good enough - rejection","review":"The paper proposes a large experimental analysis with the goal of evaluating the generalization capabilities of CNNs.\nSpecifically the analysis involves three datasets and two visual domains for each dataset: besides the original version\nof each image a new version is created by inverting its colors, i.e. simply rescaling the color channels in [0,1] and then\napplying (1-pixel_value).\n\n+ Several possible combinations between datasets and domains are considered to evaluate the network behaviour.\nThe analysis is also performed by varying the network architectures, considering data augmentation and/or fine tuning.\n\n- The text is confused in several points and the final overall conclusions are not fully clear. Some experimental settings\nare well defined to shed light on few generalization aspects of the networks. Other do not add a significant novelty\nand their contribution is not clear.\n\nDeatailed comments:\n1) at the end of page 2 \"most conventional data transformation only introduce slight variations...limited in evaluating \nthe generalization capabilities\". Conventional data transformations are introduced for data augmentation without\nsupposing the existance of a significand domain shift between training and test data. If this shift exists (as for the\ncase of negative images) it is possible to refer to the extensive deep domain adaptation literature. \n\n2) With reference to the previous point, the experiment 1 in Figure 2 provides a standard example of domain shift.\nThe fact that 1-layer softmax and 2-layers MLP perform worse than VGG is not surprising, I do not see it as an \ninteresting contribution. It would it make more sense if the comparison was between VGG and ResNet or other\ndifferent deep structures.\n\n3) Also the results of experiments 2 and 3 in figure 2 are not surprising. \nIn my understanding, in experiment 2 the network, while learning to recognize the numbers, it also learns to\nbe invariant to color thanks to a tailored data augmentation and the good final results are expected. \nIn experiment 3 instead, the defined setting is supposed to give imporance to colors, as stated at the end of page 4.\nHowever, there is no reason to automatically expect that this will decrease the importance of shape. Every category \nis defined by a specific combination of color and shape that is well recognized at test time.\n\n4) the experiments in figure 3 show that the tailored data augmentation can be done even for a subset of the\nclasses and still work well for all of them. It would be interesting to investigate the limits of this statement: what\nwould happen by augmenting only 8 or 7 or 6 or 5... categories instead of 9?\n\n5) the experiment in section 6.1, figure 5 is just slightly different from that in figure 3. I would suggest to \nput the two together since they both demonstrate that the network can learn to be invariant to a certain\ndomain aspect as far as data augmentation is used to cover that aspect for at least a part of the observed\ncategories.\n\n6) I do not see any novel contribution in the analysis of the batch normalization (end of section 5): bn has been \npreviously used for  domain adaptation\nRevisiting Batch Normalization For Practical Domain Adaptation, arXiv:1603.04779\nAutoDIAL: Automatic DomaIn Alignment Layers, ICCV 2017\n\n7) the experiment in section 6.4 should be presented as an extreme case of that of figure 7. \nSo the two can be presented together in the same section. Dividing them makes more complicated to \ndraw general conclusions from this particular data augmentation setting.\n\n8) the fine-tuning experiments do not bring significant novelty. In figure 8, my interpretation of (a) is\nthat the initial model has learned to be invariant to color and this remains true even if the fine-tuning data\ndo not contain any negative data. Given this conclusion, I would have expected a discussion about \nthe difference between learning with all data at the same time or with fine-tuning in two different \nsteps. Morever this fine-tuning experiment needs more details: is it based only on parameter initialization\nor there are some fully frozen network layers?\n\nThis work shows few interesting results but the paper is not easy to read, the presentation is sparse \nand the bit and pieces of information do not allow to derive strong final conclusions.\n\n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Assessing Generalization Capability of Convolutional Neural Networks","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/40da0c20702f9dba41a1a197de84c93805bafa95.pdf","paperhash":"anonymous|assessing_generalization_capability_of_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]}},{"tddate":null,"ddate":null,"tmdate":1509739398684,"tcdate":1509083711429,"number":260,"cdate":1509739396029,"id":"H1vrqSxAb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1vrqSxAb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Assessing Generalization Capability of Convolutional Neural Networks","abstract":"In this paper, we assess the capability of Convolutional Neural Networks (CNNs) in generalizing to images with different distribution than the training data, specifically images with similar shapes but different colors. We show that, although CNNs do not intrinsically classify objects based on their shapes, they can learn to do so when trained with enough number of images with the same shape and different colors. In experiments, we use original and negative images of training data as such images. Through systematic experiments, we investigate the role of training data, model architecture, initialization and regularization techniques on model generalization to negative images. We conclude that although CNNs can memorize any training data, they only learn and generalize the structures.","pdf":"/pdf/40da0c20702f9dba41a1a197de84c93805bafa95.pdf","paperhash":"anonymous|assessing_generalization_capability_of_convolutional_neural_networks","_bibtex":"@article{\n  anonymous2018assessing,\n  title={Assessing Generalization Capability of Convolutional Neural Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1vrqSxAb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper260/Authors"],"keywords":["Deep learning","Convolutional Neural Networks","Generalization"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}