{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222563630,"tcdate":1511948332142,"number":3,"cdate":1511948332142,"id":"H1V4eZ3lG","invitation":"ICLR.cc/2018/Conference/-/Paper1169/Official_Review","forum":"HJ5AUm-CZ","replyto":"HJ5AUm-CZ","signatures":["ICLR.cc/2018/Conference/Paper1169/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Conceptually only incremental; but generally good paper.","rating":"6: Marginally above acceptance threshold","review":"The paper presents some conceptually incremental improvements over the models in “Neural Statistician” and “Generative matching networks”. Nevertheless, it is well written and I think it is solid work with reasonable convincing experiments and good results. Although, the authors use powerful PixelCNN priors and decoders and they do not really disentangle to what degree their good results rely on the capabilities of these autoregressive components.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-Shot Learning with Variational Homoencoders","abstract":"Few-shot learning of generative models typically falls into two philosophies: conditional models, trained to generate new elements conditioned on observations, and hierarchical Bayesian models, which frame conditioning as inference of latent variables shared by a class. We modify the Variational Autoencoder framework to marry these two approaches, learning a hierarchical Bayesian model by a novel training procedure in which observations are encoded and decoded into new elements from the same class. We call this a Variational Homoencoder (VHE) and apply it to Caltech 101 Silhouettes and the Omniglot dataset. On Omniglot, our hierarchical PixelCNN outperforms existing models on joint likelihood of the data set, and achieves state-of-the-art results on both one-shot generation and one-shot classification tasks. The VHE framework also applies naturally to richer latent structures such as factorial or hierarchical categories. We illustrate this by training models to separate character content from simple variations in drawing style, and to generalise the style of an alphabet to new characters.","pdf":"/pdf/36668c5f207557f4d40dcb81393774d2f0908266.pdf","TL;DR":"Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.","paperhash":"anonymous|fewshot_learning_with_variational_homoencoders","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-Shot Learning with Variational Homoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ5AUm-CZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1169/Authors"],"keywords":["generative models","one-shot learning","metalearning","pixelcnn","hierarchical bayesian","omniglot"]}},{"tddate":null,"ddate":null,"tmdate":1512222563669,"tcdate":1511877334980,"number":2,"cdate":1511877334980,"id":"rkJkoJogf","invitation":"ICLR.cc/2018/Conference/-/Paper1169/Official_Review","forum":"HJ5AUm-CZ","replyto":"HJ5AUm-CZ","signatures":["ICLR.cc/2018/Conference/Paper1169/AnonReviewer3"],"readers":["everyone"],"content":{"title":"An interesting work on having VAEs for few-shot generation. Some tuning is need though, I think.","rating":"5: Marginally below acceptance threshold","review":"- Good work on developing VAEs for few-shot learning.\n- Most of the results are qualitative and I reckon the paper was written in haste.\n- The rest of the comments are below:\n\n- 3.1: I got a bit confused over what X actually is:\n -- \"We would like to learn a generative model for **sets X** of the form\".\n --\"... to refer to the **class X_i** ...\".\n -- \"we can lower bound the log-likelihood of each **dataset X** ...\"\n\n- 3.2: \"In general, if we wish to learn a model for X in which each latent variable ci affects some arbitrary subset Xi of the data (**where the Xi may overlap**), ...\": Which is just like learning a Z for a labeled X but learning it in an unsupervised manner, i.e. the normal VAE, isn't it? If not, could you please elaborate on what is different (in the case of 3.2 only, I mean)? i.e. Could you please elaborate on what's different (in terms of learning) between 3.2 and a normal latent Z that is definitely allowed to affect different classes of the data without knowing the classes?\n\n- Figure 1 is helpful to clarify the main idea of a VHE.\n\n- \"In a VHE, this recognition network takes only small subsets of a class as input, which additionally ...\": And that also clearly leads to loss of information that could have been used in learning. So there is a possibility for potential regularization but there is definitely a big loss in estimation power. This is obviously possible with any regularization technique, but I think it is more of an issue here since parts of the data are not even used in learning.\n\n- \"Table 4.1 compares these log likelihoods, with VHE achieving state-of-the-art. To\": Where is Table 4.1??\n\n- This is a minor point and did not have any impact on the evaluation but VAE --> VHE, reparameterization trick --> resampling trick. Maybe providing rather original headings is better? It's a style issue that is up to tastes anyway so, again, it is minor.\n\n- \"However, sharing latent variables across an entire class reduces the encoding cost per element is significantly\": typo.\n\n- \"Figure ?? illustrates\".\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-Shot Learning with Variational Homoencoders","abstract":"Few-shot learning of generative models typically falls into two philosophies: conditional models, trained to generate new elements conditioned on observations, and hierarchical Bayesian models, which frame conditioning as inference of latent variables shared by a class. We modify the Variational Autoencoder framework to marry these two approaches, learning a hierarchical Bayesian model by a novel training procedure in which observations are encoded and decoded into new elements from the same class. We call this a Variational Homoencoder (VHE) and apply it to Caltech 101 Silhouettes and the Omniglot dataset. On Omniglot, our hierarchical PixelCNN outperforms existing models on joint likelihood of the data set, and achieves state-of-the-art results on both one-shot generation and one-shot classification tasks. The VHE framework also applies naturally to richer latent structures such as factorial or hierarchical categories. We illustrate this by training models to separate character content from simple variations in drawing style, and to generalise the style of an alphabet to new characters.","pdf":"/pdf/36668c5f207557f4d40dcb81393774d2f0908266.pdf","TL;DR":"Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.","paperhash":"anonymous|fewshot_learning_with_variational_homoencoders","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-Shot Learning with Variational Homoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ5AUm-CZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1169/Authors"],"keywords":["generative models","one-shot learning","metalearning","pixelcnn","hierarchical bayesian","omniglot"]}},{"tddate":null,"ddate":null,"tmdate":1512222563713,"tcdate":1511801502550,"number":1,"cdate":1511801502550,"id":"BkviGptxG","invitation":"ICLR.cc/2018/Conference/-/Paper1169/Official_Review","forum":"HJ5AUm-CZ","replyto":"HJ5AUm-CZ","signatures":["ICLR.cc/2018/Conference/Paper1169/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting, though still avoiding the toughest questions","rating":"7: Good paper, accept","review":"This paper presents an alternative approach to constructing variational lower bounds on data log likelihood in deep, directed generative models with latent variables. Specifically, the authors propose using approximate posteriors shared across groups of examples, rather than posteriors which treat examples independently. The group-wise posteriors allow amortization of the information cost KL(group posterior || prior) across all examples in the group, which the authors liken to the \"KL annealing\" tricks that are sometimes used to avoid posterior collapse when training models with strong decoders p(x|z) using current techniques for approximate variational inference in deep nets.\n\nThe presentation of the core idea is solid, though it did take two read-throughs before the equations really clicked for me. I think the paper could be improved by spending more time on a detailed description of the model for the Omniglot experiments (as illustrated in Figure 3). E.g., explicitly describing how group-wise and per-example posteriors are composed in this model, using Equations and pseudo-code for the main training loop, would have saved me some time. For readers less familiar with amortized variational inference in deep nets, the benefit would be larger.\n\nI appreciate that the authors developed extensions of the core method to more complex group structures, though I didn't find the related experiments particularly convincing. \n\nOverall, I like this paper and think the underlying group-wise posterior construction trick is worth exploring further. Of course, the elephant in the room is how to determine the groups across which the posteriors can be shared and their information costs amortized.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-Shot Learning with Variational Homoencoders","abstract":"Few-shot learning of generative models typically falls into two philosophies: conditional models, trained to generate new elements conditioned on observations, and hierarchical Bayesian models, which frame conditioning as inference of latent variables shared by a class. We modify the Variational Autoencoder framework to marry these two approaches, learning a hierarchical Bayesian model by a novel training procedure in which observations are encoded and decoded into new elements from the same class. We call this a Variational Homoencoder (VHE) and apply it to Caltech 101 Silhouettes and the Omniglot dataset. On Omniglot, our hierarchical PixelCNN outperforms existing models on joint likelihood of the data set, and achieves state-of-the-art results on both one-shot generation and one-shot classification tasks. The VHE framework also applies naturally to richer latent structures such as factorial or hierarchical categories. We illustrate this by training models to separate character content from simple variations in drawing style, and to generalise the style of an alphabet to new characters.","pdf":"/pdf/36668c5f207557f4d40dcb81393774d2f0908266.pdf","TL;DR":"Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.","paperhash":"anonymous|fewshot_learning_with_variational_homoencoders","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-Shot Learning with Variational Homoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ5AUm-CZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1169/Authors"],"keywords":["generative models","one-shot learning","metalearning","pixelcnn","hierarchical bayesian","omniglot"]}},{"tddate":null,"ddate":null,"tmdate":1510092379009,"tcdate":1509140178037,"number":1169,"cdate":1510092359156,"id":"HJ5AUm-CZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HJ5AUm-CZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Few-Shot Learning with Variational Homoencoders","abstract":"Few-shot learning of generative models typically falls into two philosophies: conditional models, trained to generate new elements conditioned on observations, and hierarchical Bayesian models, which frame conditioning as inference of latent variables shared by a class. We modify the Variational Autoencoder framework to marry these two approaches, learning a hierarchical Bayesian model by a novel training procedure in which observations are encoded and decoded into new elements from the same class. We call this a Variational Homoencoder (VHE) and apply it to Caltech 101 Silhouettes and the Omniglot dataset. On Omniglot, our hierarchical PixelCNN outperforms existing models on joint likelihood of the data set, and achieves state-of-the-art results on both one-shot generation and one-shot classification tasks. The VHE framework also applies naturally to richer latent structures such as factorial or hierarchical categories. We illustrate this by training models to separate character content from simple variations in drawing style, and to generalise the style of an alphabet to new characters.","pdf":"/pdf/36668c5f207557f4d40dcb81393774d2f0908266.pdf","TL;DR":"Technique for learning deep generative models with shared latent variables, applied to Omniglot with a PixelCNN decoder.","paperhash":"anonymous|fewshot_learning_with_variational_homoencoders","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-Shot Learning with Variational Homoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HJ5AUm-CZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1169/Authors"],"keywords":["generative models","one-shot learning","metalearning","pixelcnn","hierarchical bayesian","omniglot"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}