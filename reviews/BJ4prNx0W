{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222593075,"tcdate":1511782344860,"number":2,"cdate":1511782344860,"id":"Sk-AwdKlf","invitation":"ICLR.cc/2018/Conference/-/Paper237/Official_Review","forum":"BJ4prNx0W","replyto":"BJ4prNx0W","signatures":["ICLR.cc/2018/Conference/Paper237/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Motivation","rating":"4: Ok but not good enough - rejection","review":"In this paper, the authors consider the problem of generating a training data set for the neural programmer-interpreter from an executable oracle. In particular, they aim at generating a complete set that fully specifies the behavior of the oracle. The authors propose a technique that achieves this aim by borrowing ideas from programming language and abstract interpretation. The technique systematically interacts with the oracle using observations, which are abstractions of environment states, and it is guaranteed to produce a data set that completely specifies the oracle. The authors later describes how to improve this technique by further equating certain observations and exploring only one in each equivalence class. Their experiments show that this improve technique can produce complete training sets for three programs.\n\nIt is nice to see the application of ideas from different areas for learning-related questions. However, there is one thing that bothers me again and again. Why do we need a data-generation technique in the paper at all? Typically, we are given a set of data, not an oracle that can generate such data, and our task is to learn something from the data. If we have an executable oracle, it is now clear to me why we want to replicate this oracle by an instance of the neural programmer-interpreter. One thing that I can see is that the technique in the paper can be used when we do research on the neural programmer-interpreter. During research, we have multiple executable oracles and need to produce good training data from them. The authors' technique may let us do this data-generation easily. But this benefit to the researchers does not seem to be strong enough for the acceptance at ICLR'18.\n\n ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222593112,"tcdate":1511579670018,"number":1,"cdate":1511579670018,"id":"B10flwLgz","invitation":"ICLR.cc/2018/Conference/-/Paper237/Official_Review","forum":"BJ4prNx0W","replyto":"BJ4prNx0W","signatures":["ICLR.cc/2018/Conference/Paper237/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Improves data efficiency of NPI, but makes stronger assumptions.","rating":"5: Marginally below acceptance threshold","review":"Quality\nThe paper is well-written and clear, and includes relevant comparisons to previous work (NPI and recursive NPI).\n\nClarity\nThe paper is clearly written.\n\nOriginality\nTo my knowledge the method proposed in this work is novel. It is the first to study constructing minimal training sets for NPI given a black-box oracle. However, as pointed out by the authors, there is a lot of similar prior work in software testing.\n\nSignificance\nThe work could be potentially significant, but there are some very strong assumptions made in the paper that could limit the impact. If the NPI has access to a black-box oracle, it is not clear what is the use of training an NPI in the first place. It would be very helpful to describe a potential scenario where the proposed approach could be useful. Also, it is assumed that the number of possible inputs is finite (also true for the recursive NPI paper), and it is not clear what techniques or lessons of this paper might transfer to tasks with perceptual inputs. The main technical contribution is the search procedure to find minimal training sets and pare down the observation size, and the empirical validation of the idea on several algorithmic tasks.\n\nPros\n- Greatly improves the data efficiency of recursive NPI.\n- Training and verification sets are automatically generated by the proposed method.\n\nCons\n- Requires access to a black-box oracle to construct the dataset.\n- Not clear that the idea will be useful in more complex domains with unbounded inputs.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510569705366,"tcdate":1510569705366,"number":2,"cdate":1510569705366,"id":"H1ZeDgDJG","invitation":"ICLR.cc/2018/Conference/-/Paper237/Public_Comment","forum":"BJ4prNx0W","replyto":"ByvPTmHkM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Role of NPI","comment":"Thanks for the reply, though my main question remains unanswered. I understand that with your procedure, you can obtain a subset of the set of all traces that fully specifies the program behavior. But then, why does the NPI need to be trained on this? Wouldn't a method that just searches through the minimized trace set to find what the next operation should be work just as well, without requiring the whole RNN infrastructure? [and faster as well, without all the linear algebra...]"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1510452575421,"tcdate":1510452575421,"number":1,"cdate":1510452575421,"id":"ByvPTmHkM","invitation":"ICLR.cc/2018/Conference/-/Paper237/Official_Comment","forum":"BJ4prNx0W","replyto":"ryp3LaFA-","signatures":["ICLR.cc/2018/Conference/Paper237/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper237/Authors"],"content":{"title":"Reply to question","comment":"Thanks for your question! The high-level motivation for our work follows from the challenges unaddressed by previous work. Reed & de Freitas [1] showed that by providing structured supervision, it is possible to learn compositional models of program behavior. However, the learned programs fail to behave correctly when run on inputs of greater length than used during training. Cai et al. [2] addressed the problem of generalizability by adding recursive structure to the execution traces used as supervision, which ensured that the learned models can generalize to inputs of arbitrary length.\n\nHowever, these past works did not address the problem of what the training set should contain in order to learn a program successfully. Furthermore, while Cai et al. described how to verify that a learned neural program has perfect generalizability, the procedure described was fully manual. Our work addresses these challenges and fully automate the process of learning a NPI program with perfect generalization for a given task. As such, the training of NPI follows from the context set by the previous work.\n\n[1] Scott Reed and Nando de Freitas. Neural programmer-interpreters. ICLR 2016.\n[2] Jonathon Cai, Richard Shin, and Dawn Song. Making neural programming architectures generalize via recursion. ICLR 2017."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509705396868,"tcdate":1509705396868,"number":1,"cdate":1509705396868,"id":"ryp3LaFA-","invitation":"ICLR.cc/2018/Conference/-/Paper237/Public_Comment","forum":"BJ4prNx0W","replyto":"BJ4prNx0W","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"High-level motivation","comment":"I'm a bit confused at what the role of the learned NPI component in the paper is. The authors describe a method to construct a method to build a set of examples that describes /all/ program behaviours. Then, they train an NPI on this. However, as /all/ behaviours are known already, it should be possible to derive a deterministic implementation (as a lookup table in the samples). What value does training the NPI add?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509739412836,"tcdate":1509078460530,"number":237,"cdate":1509739410176,"id":"BJ4prNx0W","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJ4prNx0W","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning what to learn in a neural program","abstract":"Learning programs with neural networks is a challenging task, addressed by a long line of existing work. It is difficult to learn neural networks which will generalize to problem instances that are much larger than those used during training. Furthermore, even when the learned neural program empirically works on all test inputs, we cannot verify that it will work on every possible input. Recent work has shown that it is possible to address these issues by using recursion in the Neural Programmer-Interpreter, but this technique requires a verification set which is difficult to construct without knowledge of the internals of the oracle used to generate training data. In this work, we show how to automatically build such a verification set, which can also be directly used for training. By interactively querying an oracle, we can construct this set with minimal additional knowledge about the oracle. We empirically demonstrate that our method allows automated learning and verification of a recursive NPI program with provably perfect generalization.\n","pdf":"/pdf/b31f28659d7d7247de7ac986fc9c31528edd70ef.pdf","paperhash":"anonymous|learning_what_to_learn_in_a_neural_program","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning what to learn in a neural program},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJ4prNx0W}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper237/Authors"],"keywords":[]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}