{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222653460,"tcdate":1511825113898,"number":3,"cdate":1511825113898,"id":"HJf1JQqez","invitation":"ICLR.cc/2018/Conference/-/Paper44/Official_Review","forum":"BJInEZsTb","replyto":"BJInEZsTb","signatures":["ICLR.cc/2018/Conference/Paper44/AnonReviewer1"],"readers":["everyone"],"content":{"title":"interesting approach, but concerns about method","rating":"5: Marginally below acceptance threshold","review":"Summary:\n\nThis paper proposes generative models for point clouds. First, they train an auto-encoder for 3D point clouds,  somewhat similar to PointNet (by Qi et al.). Then, they train generative models over the auto-encoder's latent space, both using a \"latent-space GAN\" (l-GAN) that outputs latent codes, and a Gaussian Mixture Model. To generate point clouds, they sample a latent code and pass it to the decoder. They also introduce a \"raw point cloud GAN\" (r-GAN) that, instead of generating a latent code, directly produces a point cloud.\n\nThey evaluate the methods on several metrics. First, they show that the autoencoder's latent space is a good representation for classification problems, using the ModelNet dataset. Second, they evaluate the generative model on several metrics (such as Jensen-Shannon Divergence) and study the benefits and drawbacks of these metrics, and suggest that one-to-one mapping metrics such as earth mover's distance are desirable over Chamfer distance. Methods such as the r-GAN score well on the latter by over-representing parts of an object that are likely to be filled.\n\nPros:\n\n- It is interesting that the latent space models are most successful, including the relatively simple GMM-based model. Is there a reason that these models have not been as successful in other domains?\n\n- The comparison of the evaluation metrics could be useful for future work on evaluating point cloud GANs. Due to the simplicity of the method, this paper could be a useful baseline for future work.\n\n- The part-editing and shape analogies results are interesting, and it would be nice to see these expanded in the main paper.\n\nCons:\n\n- How does a model that simply memorizes (and randomly samples) the training set compare to the auto-encoder-based models on the proposed metrics? How does the diversity of these two models differ?\n\n- The paper simultaneously proposes methods for generating point clouds, and for evaluating them. The paper could therefore be improved by expanding the section comparing to prior, voxel-based 3D methods, particularly in terms of the diversity of the outputs. Although the performance on automated metrics is encouraging, it is hard to conclude much about under what circumstances one representation or model is better than another.\n\n- The technical approach is not particularly novel. The auto-encoder performs fairly well, but it is just a series of MLP layers that output a Nx3 matrix representing the point cloud, trained to optimize EMD or Chamfer distance. The most successful generative models are based on sampling values in the auto-encoder's latent space using simple models (a two-layer MLP or a GMM).\n\n- While it is interesting that the latent space models seem to outperform the r-GAN, this may be due to the relatively poor performance of r-GAN than to good performance of the latent space models, and directly training a GAN on point clouds remains an important problem.\n\n- The paper could possibly be clearer by integrating more of the \"background\" section into later sections. Some of the GAN figures could also benefit from having captions.\n\nOverall, I think that this paper could serve as a useful baseline for generating point clouds, but I am not sure that the contribution is significant enough for acceptance.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Representations and Generative Models for 3D Point Clouds","abstract":"Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including: GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.\nTo perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.","pdf":"/pdf/eaacba063dc3168953b2bd61fbbe945cb06a1357.pdf","TL;DR":"Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.","paperhash":"anonymous|learning_representations_and_generative_models_for_3d_point_clouds","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Representations and Generative Models for 3D Point Clouds},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJInEZsTb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper44/Authors"],"keywords":["representation learning","auto-encoders","3D point clouds","generative models","GANs","Gaussian Mixture Models"]}},{"tddate":null,"ddate":null,"tmdate":1512222653501,"tcdate":1511817306435,"number":2,"cdate":1511817306435,"id":"B1Mvg-qlM","invitation":"ICLR.cc/2018/Conference/-/Paper44/Official_Review","forum":"BJInEZsTb","replyto":"BJInEZsTb","signatures":["ICLR.cc/2018/Conference/Paper44/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Well written paper with new  important results","rating":"8: Top 50% of accepted papers, clear accept","review":"3D data processing is very important topic nowadays, since it has a lot of applications: robotics, AR/VR, etc.\n\nCurrent approaches to 2D image processing based on Deep Neural Networks provide very accurate results and a wide variety of different architectures for image modelling, generation, classification, retrieval.\n\nThe lack of DL architectures for 3D data is due to complexity of representation of 3D data, especially when using 3D point clouds.\n\nConsidered paper is one of the first approaches to learn GAN-type generative models.\nUsing PointNet architecture and latent-space GAN, the authors obtained rather accurate generative model.\n\nThe paper is well written, results of experiments are convincing, the authors provided the code on the github, realizing their architectures. \n\nThus I think that the paper should be published.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Representations and Generative Models for 3D Point Clouds","abstract":"Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including: GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.\nTo perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.","pdf":"/pdf/eaacba063dc3168953b2bd61fbbe945cb06a1357.pdf","TL;DR":"Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.","paperhash":"anonymous|learning_representations_and_generative_models_for_3d_point_clouds","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Representations and Generative Models for 3D Point Clouds},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJInEZsTb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper44/Authors"],"keywords":["representation learning","auto-encoders","3D point clouds","generative models","GANs","Gaussian Mixture Models"]}},{"tddate":null,"ddate":null,"tmdate":1512222653540,"tcdate":1511803671100,"number":1,"cdate":1511803671100,"id":"SJyXoTtlG","invitation":"ICLR.cc/2018/Conference/-/Paper44/Official_Review","forum":"BJInEZsTb","replyto":"BJInEZsTb","signatures":["ICLR.cc/2018/Conference/Paper44/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Above average results, but needs more experiments/comparisons","rating":"6: Marginally above acceptance threshold","review":"This paper introduces a generative approach for 3D point clouds. More specifically, two Generative Adversarial approaches are introduced: Raw point cloud GAN, and Latent-space GAN (r-GAN and l-GAN as referred to in the paper). In addition, a GMM sampling + GAN decoder approach to generation is also among the experimented variations. \n\nThe results look convincing for the generation experiments in the paper, both from class-specific (Figure 1) and multi-class generators (Figure 6). The quantitative results also support the visuals. \n\nOne question that arises is whether the point cloud approaches to generation is any more valuable compared to voxel-grid based approaches. Especially Octree based approaches [1-below] show very convincing and high-resolution shape generation results, whereas the details seem to be washed out for the point cloud results presented in this paper. \n\nI would like to see comparison experiments with voxel based approaches in the next update for the paper. \n\n[1]\n@article{tatarchenko2017octree,\n  title={Octree Generating Networks: Efficient Convolutional Architectures for High-resolution 3D Outputs},\n  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},\n  journal={arXiv preprint arXiv:1703.09438},\n  year={2017}\n}","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Representations and Generative Models for 3D Point Clouds","abstract":"Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including: GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.\nTo perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.","pdf":"/pdf/eaacba063dc3168953b2bd61fbbe945cb06a1357.pdf","TL;DR":"Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.","paperhash":"anonymous|learning_representations_and_generative_models_for_3d_point_clouds","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Representations and Generative Models for 3D Point Clouds},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJInEZsTb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper44/Authors"],"keywords":["representation learning","auto-encoders","3D point clouds","generative models","GANs","Gaussian Mixture Models"]}},{"tddate":null,"ddate":null,"tmdate":1509739514771,"tcdate":1508738221768,"number":44,"cdate":1509739512117,"id":"BJInEZsTb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BJInEZsTb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Representations and Generative Models for 3D Point Clouds","abstract":"Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including: GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.\nTo perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.","pdf":"/pdf/eaacba063dc3168953b2bd61fbbe945cb06a1357.pdf","TL;DR":"Deep autoencoders to learn a good representation for geometric 3D point-cloud data; Generative models for point clouds.","paperhash":"anonymous|learning_representations_and_generative_models_for_3d_point_clouds","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Representations and Generative Models for 3D Point Clouds},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BJInEZsTb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper44/Authors"],"keywords":["representation learning","auto-encoders","3D point clouds","generative models","GANs","Gaussian Mixture Models"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}