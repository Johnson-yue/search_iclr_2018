{"notes":[{"tddate":null,"ddate":null,"tmdate":1511975954964,"tcdate":1511975954964,"number":1,"cdate":1511975954964,"id":"Byjzhwnlf","invitation":"ICLR.cc/2018/Conference/-/Paper663/Public_Comment","forum":"HkGcX--0-","replyto":"HkGcX--0-","signatures":["~Lucas_Caccia1"],"readers":["everyone"],"writers":["~Lucas_Caccia1"],"content":{"title":"Implementation details","comment":"Hi, I'm a Master's student in Computer Science taking part in the ICLR reproducibility challenge, and I have a few questions regarding implementation. \n\nFirst, you mention that \"We allow each layer of the pixel-CNN to take additional input using non-masked convolutions from the feature stream based on the VAE output\". How is this implemented exactly ? Looking at the PixelCNN++ implementation, we see that every layer is composed of 2 streams of (n=5) resnet blocks, specifically one downwards and one downward+rightward stream. In AGAVE, do you feed the vae output to every resnet block in both streams ? or do you you feed it to the top resnet block at every layer for both streams ?\n\nSecond, you mention that you condition on  the \"VAE decoder output f(z), or possibly an upsampled (downsampled?) version if y has a lower resolution than x\".  How exactly do you perform downsampling ? do you use strided convolutions ? If so,  do you use the same downsampled vae output for the kth and the (K-k)th layer of the PixelCNN, as they have the same resolution?\n\nThird, did you use the default hyperparameters proposed on the repositories of IAF/VAE and PixelCNN++ ? If not, what modifications did you make? Did you reduce the size of the networks so that they both fit on a single GPU ? What kind of initialisation was performed on the weights ?\n\nLastly, for how long were the PixelCNN and IAF/VAE models pretrained ? Do you have any other advice/specifications for people aiming to reproduce your results ? \n\n\nMany thanks"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Auxiliary Guided Autoregressive Variational Autoencoders","abstract":"Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.","pdf":"/pdf/df9435a10a791f48e310e5f03afac28f5eec1b8e.pdf","paperhash":"anonymous|auxiliary_guided_autoregressive_variational_autoencoders","_bibtex":"@article{\n  anonymous2018auxiliary,\n  title={Auxiliary Guided Autoregressive Variational Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkGcX--0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper663/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222712998,"tcdate":1511915640483,"number":3,"cdate":1511915640483,"id":"BylKxYolM","invitation":"ICLR.cc/2018/Conference/-/Paper663/Official_Review","forum":"HkGcX--0-","replyto":"HkGcX--0-","signatures":["ICLR.cc/2018/Conference/Paper663/AnonReviewer3"],"readers":["everyone"],"content":{"title":"AUXILIARY GUIDED AUTOREGRESSIVE VARIATIONAL AUTOENCODERS","rating":"5: Marginally below acceptance threshold","review":"The authors present Auxiliary Guided Autoregressive Variational autoEncoders (AGAVE), a hybrid approach that combines the strengths of variational autoencoders (global statistics) and autorregressive models (local statistics) for improved image modeling. This is done by controlling the capacity of the autorregressive component within an auxiliary loss function.\n\nThe proposed approach is a straightforward combination of VAE and PixelCNN that although empirically better than PixelCNN, and presumably VAE, does not outperform PixelCNN++. Provided that the authors use PixelCNN++ in their approach, quantitively speaking, it is difficult to defend the value of adding a VAE component to the model. The authors do not describe how \\lambda was selected, which is critical for performance, provided the results in Figure 4. That being said, the contribution from the VAE is likely to be negligible given the performance of PixelCNN++ alone.\n\n- The KL divergence in (3) does more than simply preventing the approximation q() from becoming a point mass distribution.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Auxiliary Guided Autoregressive Variational Autoencoders","abstract":"Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.","pdf":"/pdf/df9435a10a791f48e310e5f03afac28f5eec1b8e.pdf","paperhash":"anonymous|auxiliary_guided_autoregressive_variational_autoencoders","_bibtex":"@article{\n  anonymous2018auxiliary,\n  title={Auxiliary Guided Autoregressive Variational Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkGcX--0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper663/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222713038,"tcdate":1511824222349,"number":2,"cdate":1511824222349,"id":"B1LwiG9gz","invitation":"ICLR.cc/2018/Conference/-/Paper663/Official_Review","forum":"HkGcX--0-","replyto":"HkGcX--0-","signatures":["ICLR.cc/2018/Conference/Paper663/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Good paper","rating":"7: Good paper, accept","review":"The proposed approach is straight forward, experimental results are good, but don’t really push the state of the art. But the empirical analysis (e.g. decomposition of different cost terms) is detailed and very interesting.   ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Auxiliary Guided Autoregressive Variational Autoencoders","abstract":"Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.","pdf":"/pdf/df9435a10a791f48e310e5f03afac28f5eec1b8e.pdf","paperhash":"anonymous|auxiliary_guided_autoregressive_variational_autoencoders","_bibtex":"@article{\n  anonymous2018auxiliary,\n  title={Auxiliary Guided Autoregressive Variational Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkGcX--0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper663/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222713080,"tcdate":1511725553930,"number":1,"cdate":1511725553930,"id":"Bk9xqcOgG","invitation":"ICLR.cc/2018/Conference/-/Paper663/Official_Review","forum":"HkGcX--0-","replyto":"HkGcX--0-","signatures":["ICLR.cc/2018/Conference/Paper663/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Important problem but no evidence of progress","rating":"4: Ok but not good enough - rejection","review":"Summary:\n\nThis paper attempts to solve the problem of meaningfully combining variational autoencoders (VAEs) and PixelCNNs. It proposes to do this by simultaneously optimizing a VAE with PixelCNN++ decoder, and a VAE with factorial decoder. The model is evaluated in terms of log-likelihood (with no improvement over a PixelCNN++) and the visual appearance of samples and reconstructions.\n\nReview:\n\nCombining density networks (like VAEs) and autoregressive models is an unsolved problem and potentially very useful. To me, the most interesting bit of information in this paper was the realization that you can weight the reconstruction and KL terms of a VAE and interpret it as variational inference in a generative model with multiple copies of pixels (below Equation 7). Unfortunately the authors were unable to make any good use of this insight, and I will explain below why I don’t see any evidence of an improved generative model in this paper.\n\nAs the paper is written now, it is not clear what the goal of the authors is. Is it density estimation? Then the addition of the VAE had no measurable effect on the PixelCNN++’s performance, i.e., it seems like a bad idea due to the added complexity and loss of tractability. Is it representation learning? Then the paper is missing experiments to support the idea that the learned representations are in any way an improvement. Is it image synthesis (not a real application by itself), then the paper should have demonstrated the usefulness of the model on a real task and probably involve human subjects in a quantitative evaluation.\n\nMuch of the authors’ analysis is based on a qualitative evaluation of samples. However, samples can be very misleading. A lookup table storing the training data generates samples containing objects and perfect details, but obviously has not learned anything about either objects or the low-level statistics of natural images. \n\nIn contrast to the authors, I fail to see a meaningful difference between the groups of samples in Figure 1.\n\nThe VAE samples in Figure 3b) look quite smooth. Was independent Gaussian noise added to the VAE samples or are those (as is sometimes done) sampled means? If the former, what was sigma and how was it chosen?\n\nOn page 7, the authors conclude that “the pixelCNN clearly takes into account the output of the VAE decoder” based on the samples. Being a mixture model, a PixelCNN++ could easily represent the following mixture:\n\np(x | z) = 0.01 \\prod_i p(x_i | x_{<i}) + 0.99 \\prod_i p(x_i | z)\n\nThe first term is just like a regular PixelCNN++, ignoring the latent variables. The second term is just like a variational autoencoder with factorial decoder. The samples in this case would be dominated by the VAE, which depends on the latent state. The log-likelihood would be dominated by the first term and would be minimally effected (see Theis et al., 2016). Note that I am not saying that this is exactly what the model has learned. I am merely providing a possible counter example to the notion that the PixelCNN++ has learned to use of the latent representation in a meaningful way.\n\nWhat happens if the KL term is simply downweighted but the factorial decoder is not included? This seems like it would be a useful control to include.\n\nThe paper is well written and clear.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Auxiliary Guided Autoregressive Variational Autoencoders","abstract":"Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.","pdf":"/pdf/df9435a10a791f48e310e5f03afac28f5eec1b8e.pdf","paperhash":"anonymous|auxiliary_guided_autoregressive_variational_autoencoders","_bibtex":"@article{\n  anonymous2018auxiliary,\n  title={Auxiliary Guided Autoregressive Variational Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkGcX--0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper663/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509739173685,"tcdate":1509131145746,"number":663,"cdate":1509739171022,"id":"HkGcX--0-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkGcX--0-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Auxiliary Guided Autoregressive Variational Autoencoders","abstract":"Generative modeling of high-dimensional data is a key problem in machine learning. Successful approaches include latent variable models and autoregressive models. The complementary strengths of these approaches,  to model global and local image statistics respectively, suggest hybrid models combining the strengths of both models. Our contribution is to train such hybrid models using an auxiliary loss function that controls which information is captured by the latent variables and what is left to the autoregressive decoder. In contrast, prior work on such hybrid models needed to limit the capacity of the autoregressive decoder to prevent degenerate models that ignore the latent variables and only rely on autoregressive modeling. Our approach results in models with meaningful latent variable representations, and which rely on powerful autoregressive decoders to model image details. Our model generates qualitatively convincing samples, and yields state-of-the-art quantitative results.","pdf":"/pdf/df9435a10a791f48e310e5f03afac28f5eec1b8e.pdf","paperhash":"anonymous|auxiliary_guided_autoregressive_variational_autoencoders","_bibtex":"@article{\n  anonymous2018auxiliary,\n  title={Auxiliary Guided Autoregressive Variational Autoencoders},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkGcX--0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper663/Authors"],"keywords":[]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}