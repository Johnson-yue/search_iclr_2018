{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222592464,"tcdate":1512087912920,"number":2,"cdate":1512087912920,"id":"H1-u-QCef","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Review","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Good theoretical results, but would have liked a stronger empirical story","rating":"6: Marginally above acceptance threshold","review":"This paper introduces MiniMax Curriculum learning, as an approach for adaptively train models by providing it different subsets of data. The authors formulate the learning problem as a minimax problem which tries to choose diverse example and \"hard\" examples, where the diversity is captured via a Submodular Loss function and the hardness is captured via the Loss function. The authors formulate the problem as an iterative technique which involves solving a minimax objective at every iteration. The authors argue the convergence results on the minimax objective subproblem, but do not seem to give results on the general problem. The ideas for this paper are built on existing work in Curriculum learning, which attempts to provide the learner easy examples followed by harder examples later on. The belief is that this learning style mimics human learners.\n\nPros:\n- The analysis of the minimax objective is novel and the proof technique introduces several interesting ideas.\n- This is a very interesting application of joint convex and submodular optimization, and uses properties of both to show the final convergence results\n- Even through the submodular objective is only approximately solvable, it still translates into a convergence result\n- The experimental results seem to be complete for the most part. They argue how the submodular optimization does not really affect the performance and diversity seems to empirically bring improvement on the datasets tried.\n\nCons:\n- The main algorithm MCL is only a hueristic. Though the MiniMax subproblem can converge, the authors use this in somewhat of a hueristic manner.\n- It seems somewhat hand wavy in the way the authors describe the hyper parameters of MCL, and it seems unclear when the algorithm converge and how to increase/decrease it over iterations\n- The objective function also seems somewhat non-intuitive. Though the experimental results seem to indicate that the idea works, I think the paper does not motivate the loss function and the algorithm well.\n- It seems to me the authors have experimented with smaller datasets (CIFAR, MNIST, 20NewsGroups). This being mainly an empirical paper, I would have expected results on a few larger datasets (e.g. ImageNet, CelebFaces etc.), particularly to see if the idea also scales to these more real world larger datasets.\n\nOverall, I would like to see if the paper could have been stronger empirically. Nevertheless, I do think there are some interesting ideas theoretically and algorithmically. For this reason, I vote for a borderline accept. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/2a1e95f468f45742e0345c976aca16aeb32e5ae0.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1512222592504,"tcdate":1511318617320,"number":1,"cdate":1511318617320,"id":"BkbPVPzgG","invitation":"ICLR.cc/2018/Conference/-/Paper232/Official_Review","forum":"BywyFQlAW","replyto":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference/Paper232/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Choosing diverse and hard training examples with submodular optimization.","rating":"5: Marginally below acceptance threshold","review":"Overview:\nThis paper proposes an approach to curriculum learning, where subsets of examples to train on are chosen during the training process. The proposed method is based on a submodular set function over the examples, which is intended to capture diversity of the included examples and is added to the training objective (eq. 2). The set is optimized to be as hard as possible (maximize loss), which results in a min-max problem. This is in turn optimized (approximately) by alternating between gradient-based loss minimization and submodular maximization. The theoretical analysis shows that if the loss is strongly convex, then the algorithm returns a solution which is close to the optimal solution. Empirical results are presented for several benchmarks.\nThe paper is mostly clear and the idea seems nice. On the downside, there are some limitations to the theoretical analysis and optimization scheme (see comments below).\n\nComments:\n- The theoretical result (thm. 1) studies the case of full optimization, which is different than the proposed algorithm (running a fixed number of weight updates). It would be interesting to show results on sensitivity to the number of updates (p).\n- The algorithm requires tuning of quite a few hyperparameters (sec. 3).\n- Approximating a cluster with a single sample (sec. 2.3) seems rather crude. There should be some theoretical and/or empirical study of its effect on quality of the solution.\n\nMinor/typos:\n- what is G(j|G\\j) in eq. (9)?\n- why cite Anonymous (2018) instead of Appendix...?\n- define V in Thm. 1.\n- in eq. (4) it may be clearer to denote g_k(w). Likewise in eq. (6) \\hat{g}_\\hat{A}(w), and in eq. (14) \\tilde{g}_{\\cal{A}}(w).\n- figures readability can be improved.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/2a1e95f468f45742e0345c976aca16aeb32e5ae0.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]}},{"tddate":null,"ddate":null,"tmdate":1509739415525,"tcdate":1509075166844,"number":232,"cdate":1509739412871,"id":"BywyFQlAW","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"BywyFQlAW","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Scheduled Learning with Declining Diversity and Incremental Difficulty","abstract":"We study how to adaptively select training subsets for different stages of iterative machine learning. We introduce minimax curriculum learning (MCL), which trains a model on a diverse few samples at first, and then later on a larger training set containing concentrated hard samples, thereby avoiding wasted efforts on redundant samples in early stages and on disperse outliers in later stages. At each stage, model weights and training sets are updated by solving a minimax optimization, whose objective is composed of a loss (reflecting the hardness of the training set) and a submodular regularization (measuring its diversity). MCL repeatedly solves a sequence of such optimizations with decreasing diversity and increasing training set size. Unlike the expensive alternative minimization used in previous work, we reduce MCL to minimization of a surrogate function that can be handled by submodular maximization and optimized by gradient methods. We show that MCL achieves better performance by using fewer labeled samples for both shallow and deep models.","pdf":"/pdf/2a1e95f468f45742e0345c976aca16aeb32e5ae0.pdf","TL;DR":"Scheduling a learning process with decreasing diversity and increasing difficulty improves the performance and requires less training samples.","paperhash":"anonymous|scheduled_learning_with_declining_diversity_and_incremental_difficulty","_bibtex":"@article{\n  anonymous2018scheduled,\n  title={Scheduled Learning with Declining Diversity and Incremental Difficulty},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=BywyFQlAW}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper232/Authors"],"keywords":["deep learning","minimax","curriculum learning","submodular","diversity"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}