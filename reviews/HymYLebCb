{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222695223,"tcdate":1511973538483,"number":3,"cdate":1511973538483,"id":"ry9izvnlf","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"readers":["everyone"],"content":{"title":"interesting idea","rating":"6: Marginally above acceptance threshold","review":"This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I do not understand the intuition behind the success of analogizing graph with images.\n\nFundamentally, a convolutional filter stands for a operation within a small neighborhood on the image. However, it is unclear how it means for the graph representation. Is the neighborhood predefined? Are the graph nodes pre-ordered? \n\nI am also curious with the effect of pre-trained model from ImageNet. Since the graph presentation does not use color channels,  pre-trained model is used different from what it was designed to. I would imagine the benefit of using ImageNet is just to bring a random, high-dimensional embedding.  In addition, I wonder whether it will help to fine-tune the model on the graph classification data. Could this submission show some fine-tune experiments?","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222695260,"tcdate":1511817219465,"number":2,"cdate":1511817219465,"id":"r1jbeZ9xM","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Good paper","rating":"6: Marginally above acceptance threshold","review":"The paper proposed a subgraph image representation and validate it in image classification and transfer learning problems. The image presentation is a minor extension based on a method of producing permutation-invariant adjacency matrix. The experimental results supports the claim.\n\nIt is very positive that the figures are very helpful for delivering the information.\n\nThe work seems to be a little bit incremental. The proposed image representation is mainly based on a previous work of permutation-invariant adjacency matrix. A novelty of this work seems to be transforming a graph into an image. By the proposed representation, the authors are able to apply image classification methods (supervised or unsupervised) to subgraph classification. \n\nIt will be better if the authors could provide more details in the methodology or framework section.\n\nThe experiments on 9 networks support the claims that the image embedding approaches with their image representation of the subgraph outperform the graph kernel and classical features based methods. It seem to be promising when using transfer learning.\n\nThe last two process figures in 1.1 can be improved. No caption or figure number is provided.\n\nIt will be better to make the notations easy to understand and avoid any notation in a sentence without explanation nearby.\nFor example:\n\"the test example is correctly classified if and only if its ground truth matches C.\"(P5)\n\"We carry out this exercise 4 times and set n to 8, 16, 32 and 64 respectively.\"(P6)\n\nSome minor issues:\n\"Zhu et al.(2011) discuss heterogeneous transfer learning where in they use...\"(P3)\n\"Each label vector (a tuple of label, label-probability pairs).\" (incomplete sentence?P5)","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1511650758810,"tcdate":1511650758810,"number":1,"cdate":1511650758810,"id":"rJyCr_Pef","invitation":"ICLR.cc/2018/Conference/-/Paper592/Public_Comment","forum":"HymYLebCb","replyto":"ry6_ZhLgM","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Response","comment":"Thanks for the comment. Please see the responses below.\n\n1. what is the physical meaning of CNN filters respond to the graph representation?\n- I'm not sure I understood your question correctly. I'm assuming you meant image embeddings by \"graph representation\". From CNN's perspective, the structured image embeddings are like any other images. The fact that these structured image embeddings were obtained from adjacency matrices has no effect on CNN. \n\n2. for images from ImageNet, each pixel is represented by 3 color channels (RGB). Will the adjacent matrices representation use such channels?\n\n- Caffe (trained on ImageNet) takes in black & white/grayscale images as input as well. The structured image embeddings of the adjacency matrices do not have to be modified in any way.\n\n3. if we shuffle the order of graph nodes,  the rows/columns  in adjacent matrix will exchange. Will the image based classification result be the same?\n\n- Yes. The shuffling of the order of the nodes in the adjacency matrices does not affect classification. This is because we apply a structuring process on the matrices before we obtain the image embeddings. This ensures that no matter the arrangement of the nodes, the image embedding produces the same structure for a given adjacency matrix. It's permutation invariant. See Section 2.1 for details.\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1511600500802,"tcdate":1511600500802,"number":1,"cdate":1511600500802,"id":"ry6_ZhLgM","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Comment","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper592/AnonReviewer2"],"content":{"title":"what does the image filter mean for adjacent matrices?","comment":"This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I have difficulty to understand the intuition behind the success of analogizing graph with images. More specifically,  I wonder\n\n1. what is the physical meaning of CNN filters respond to the graph representation?\n\n2. for images from ImageNet, each pixel is represented by 3 color channels (RGB). Will the adjacent matrices representation use such channels?\n\n3. if we shuffle the order of graph nodes,  the rows/columns  in adjacent matrix will exchange. Will the image based classification result be the same?"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222695295,"tcdate":1510888284682,"number":1,"cdate":1510888284682,"id":"SJBw7As1f","invitation":"ICLR.cc/2018/Conference/-/Paper592/Official_Review","forum":"HymYLebCb","replyto":"HymYLebCb","signatures":["ICLR.cc/2018/Conference/Paper592/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Surprising that the method works, but the method is too unprincipled for me to really see the value of it.","rating":"3: Clear rejection","review":"The paper proposes to use 2-d image representation techniques as a means of learning representations of graphs via their adjacency matrices. The adjacency matrix (or a subgraph of it) is first re-ordered to produce some canonical ordering which can then be fed into an image representation method. This can then be fed into a classifier.\n\nThis is a little too unprincipled for my taste. In particular the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs. Perhaps this is due to a lack of available graph training data, but it doesn't seem to make a lot of sense.\n\nMaybe I missed or overlooked some detail, but I didn't spot exactly what the classification task was. I think the goal is to identify which of the graphs a subgraph belongs to? I'm not sure how relevant this graph classification task is. \n\nThe method does prove that the Caffe reference model maintains some information that can be used for classification, but this doesn't really suggest a generalizable method that we could confidently use for a variety of tasks. It's surprising that it works at all, but ultimately doesn't reveal a big scientific finding that could be re-used.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]}},{"tddate":null,"ddate":null,"tmdate":1509739213347,"tcdate":1509127803175,"number":592,"cdate":1509739210680,"id":"HymYLebCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HymYLebCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification","abstract":"We propose a novel subgraph image representation for classification of network fragments with the target being their parent networks. The graph image representation is based on 2D image embeddings of adjacency matrices. We use this image representation in two modes. First, as the input to a machine learning algorithm. Second, as the input to a pure transfer learner. Our conclusions from multiple datasets are that\n1. deep learning using structured image features performs the best compared to graph kernel and classical features based methods; and,\n2. pure transfer learning works effectively with minimum interference from the user and is robust against small data.\n","pdf":"/pdf/991b5706239ade201e9c1b3c0bec685d20785980.pdf","TL;DR":"We convert subgraphs into structured images and classify them using 1. deep learning and 2. transfer learning (Caffe) and achieve stunning results.","paperhash":"anonymous|network_signatures_from_image_representation_of_adjacency_matrices_deeptransfer_learning_for_subgraph_classification","_bibtex":"@article{\n  anonymous2018network,\n  title={Network Signatures from Image Representation of Adjacency Matrices: Deep/Transfer Learning for Subgraph Classification},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HymYLebCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper592/Authors"],"keywords":["deep learning","transfer learning","adjacency matrices","image feature representation","Caffe","graph classification"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}