{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222614607,"tcdate":1512025610104,"number":2,"cdate":1512025610104,"id":"SyzG0Q6lz","invitation":"ICLR.cc/2018/Conference/-/Paper287/Official_Review","forum":"HyN-ZvlC-","replyto":"HyN-ZvlC-","signatures":["ICLR.cc/2018/Conference/Paper287/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Careful application of large margin in neural language model, good empirical results on ASR and MT tasks","rating":"7: Good paper, accept","review":"The main contribution of this paper are:\n(a) replacing the typical maximum likelihood criterion in neural language model training with a discriminative criterion,\n(b) propose two large margin criterion -- difference in likelihood and difference in rank (WER or BLUE ordered) hypotheses,\n(c) demonstrate performance gains two standard tasks -- an ASR task on Wall Street Journal (small task) and an MT task.\n\nIn addition, they provide examples in Figure (1) and (2) that illustrate the effect of the cost function on training. Their illustration in Figure 4 is also helpful in seeing the impact of using a warm start with a generative model.\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Large Margin Neural Language Models","abstract":"Neural language models (NLMs) are generative, and they model the distribution of grammatical sentences. Trained on huge corpus, NLMs are pushing the limit of modeling accuracy. Besides, they have also been applied to supervised learning tasks that decode text, e.g., automatic speech recognition (ASR). By re-scoring the n-best list, NLM can select grammatically more correct candidate among the list, and significantly reduce word/char error rate. However, the generative nature of NLM may not guarantee a discrimination between “good” and “bad” (in a task-specific sense) sentences, resulting in suboptimal performance. This work proposes an approach to adapt a generative NLM to a discriminative one. Different from the commonly used maximum likelihood objective, the proposed method aims at enlarging the margin between the “good” and “bad” sentences. It is trained end-to-end and can be widely applied to tasks that involve the re-scoring of the decoded text. Significant gains are observed in both ASR and statistical machine translation (SMT) tasks.","pdf":"/pdf/d2cd1af546725840aa9bc713f462fda318bbc42e.pdf","TL;DR":"Enhance the language model for supervised learning task ","paperhash":"anonymous|large_margin_neural_language_models","_bibtex":"@article{\n  anonymous2018large,\n  title={Large Margin Neural Language Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyN-ZvlC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper287/Authors"],"keywords":["Language Model","discriminative model"]}},{"tddate":null,"ddate":null,"tmdate":1512222614651,"tcdate":1511142424165,"number":1,"cdate":1511142424165,"id":"SygQEnyef","invitation":"ICLR.cc/2018/Conference/-/Paper287/Official_Review","forum":"HyN-ZvlC-","replyto":"HyN-ZvlC-","signatures":["ICLR.cc/2018/Conference/Paper287/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting methods but weak baselines (and difficulty of replication) dilute impact of experimental results","rating":"5: Marginally below acceptance threshold","review":"This paper presents two methods for imposing a margin on discriminative loss functions, one which uses the margin between the reference transcription and alternatively hypothesized transcriptions (LMLM), and another which compares all alternative candidates and uses a margin between those with a better system objective (WER or bleu) and those with a worse system objective (rank-LMLM).  Some interesting results on the development set show the importance of things like warm starting on large language model training data.  The methods presented here could be of interest to those training language models for use in specific systems, and the paper reads reasonably clearly.\n\nThe principal shortcoming of the paper is that there was essentially no effort to establish that the baseline systems that are being improved through reranking via these methods are decent baselines for such a use, or to really specify these systems in a way that would allow for replication of the results being presented in the paper.  Sufficient specification of the exact training data and procedure is standard in papers that purport to establish methods to improve upon such baselines, yet such information is sorely lacking in this paper.  Further, the speech data sets, Fisher and Wall St. Journal, have what would seem to be very high word error rates versus what should be possible with standard open-source speech recognizers such as Kaldi.  For example, by referencing a page that attempts to establish the state of the art on standard data sets (https://github.com/syhw/wer_are_we), we can find links to papers by Povey et al (http://www.danielpovey.com/files/2016_interspeech_mmi.pdf) and the Deep 2 paper in your citations, which themselves include baselines from other papers that cut the error rate in half versus even your best scoring systems, let alone your baselines.  Similarly, your Bleu score on Vietnamese to English translation is way below what were reported (even by the organizer baseline) for the IWSLP conference where the data became available: https://github.com/magizbox/underthesea/wiki/SOTA-Machine-Translation:-IWSLT-2015\n\nGranted, the competing systems also were outperformed by the organizer baseline for that task at IWSLT 2015, but not by the degree to which your system is.  Again, your best performing system (using your new methods) has performance far below the worst reported competing system.  The cavalier presentation of specific details regarding your baseline systems (which is critical for any sort of replicability) and the uniformly weak performance of these systems relative to widely reported results, leads me to discount the probability that your methods would actually result in improvements on truly solid baselines.  I would have preferred one domain experiment carried out with appropriately rock solid documentation of the ball-park competitive baseline system to these results.\n\nOverall, the method is interesting and the dev set experiments were informative, but ultimately the experiments were not.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Large Margin Neural Language Models","abstract":"Neural language models (NLMs) are generative, and they model the distribution of grammatical sentences. Trained on huge corpus, NLMs are pushing the limit of modeling accuracy. Besides, they have also been applied to supervised learning tasks that decode text, e.g., automatic speech recognition (ASR). By re-scoring the n-best list, NLM can select grammatically more correct candidate among the list, and significantly reduce word/char error rate. However, the generative nature of NLM may not guarantee a discrimination between “good” and “bad” (in a task-specific sense) sentences, resulting in suboptimal performance. This work proposes an approach to adapt a generative NLM to a discriminative one. Different from the commonly used maximum likelihood objective, the proposed method aims at enlarging the margin between the “good” and “bad” sentences. It is trained end-to-end and can be widely applied to tasks that involve the re-scoring of the decoded text. Significant gains are observed in both ASR and statistical machine translation (SMT) tasks.","pdf":"/pdf/d2cd1af546725840aa9bc713f462fda318bbc42e.pdf","TL;DR":"Enhance the language model for supervised learning task ","paperhash":"anonymous|large_margin_neural_language_models","_bibtex":"@article{\n  anonymous2018large,\n  title={Large Margin Neural Language Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyN-ZvlC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper287/Authors"],"keywords":["Language Model","discriminative model"]}},{"tddate":null,"ddate":null,"tmdate":1509739384565,"tcdate":1509089532413,"number":287,"cdate":1509739381907,"id":"HyN-ZvlC-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HyN-ZvlC-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Large Margin Neural Language Models","abstract":"Neural language models (NLMs) are generative, and they model the distribution of grammatical sentences. Trained on huge corpus, NLMs are pushing the limit of modeling accuracy. Besides, they have also been applied to supervised learning tasks that decode text, e.g., automatic speech recognition (ASR). By re-scoring the n-best list, NLM can select grammatically more correct candidate among the list, and significantly reduce word/char error rate. However, the generative nature of NLM may not guarantee a discrimination between “good” and “bad” (in a task-specific sense) sentences, resulting in suboptimal performance. This work proposes an approach to adapt a generative NLM to a discriminative one. Different from the commonly used maximum likelihood objective, the proposed method aims at enlarging the margin between the “good” and “bad” sentences. It is trained end-to-end and can be widely applied to tasks that involve the re-scoring of the decoded text. Significant gains are observed in both ASR and statistical machine translation (SMT) tasks.","pdf":"/pdf/d2cd1af546725840aa9bc713f462fda318bbc42e.pdf","TL;DR":"Enhance the language model for supervised learning task ","paperhash":"anonymous|large_margin_neural_language_models","_bibtex":"@article{\n  anonymous2018large,\n  title={Large Margin Neural Language Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HyN-ZvlC-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper287/Authors"],"keywords":["Language Model","discriminative model"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}