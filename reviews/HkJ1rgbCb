{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222693433,"tcdate":1511808863015,"number":2,"cdate":1511808863015,"id":"S1wvy15xz","invitation":"ICLR.cc/2018/Conference/-/Paper578/Official_Review","forum":"HkJ1rgbCb","replyto":"HkJ1rgbCb","signatures":["ICLR.cc/2018/Conference/Paper578/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Careful discussions would be needed to show that neural nets are good for 'hard' combinatorial problems","rating":"5: Marginally below acceptance threshold","review":"This paper presents an interesting approach to identify substructural features of molecular graphs contributing to the target task (e.g. predicting toxicity). The algorithm first builds two conv nets for molecular graphs, one is for searching relevant substructures (policy improvement), and another for evaluating the contribution of selected substructures to the target task (policy evaluation). These two phases are iterated in a reinforcement learning manner as policy iterations. Both parts are based on conv nets for molecular graphs, and this framework is a kind of 'self-supervised' scheme compared to the standard situations that the environment provides rewards. The experimental validations demonstrate that this model can learn a competitive-performed conv nets only dependent on the highlighted substructures, as well as reporting some case study on the inhibition assay for hERG proteins.\n\nTechnically speaking, the proposed self-supervised scheme with two conv nets is very interesting. This demonstrates how we can perform progressive substructure selections over molecular graphs to highlight relevant substructures as well as maximizing the prediction performance. Given that conv nets for molecular graphs are not trivially interpretable, this would provides a useful approach to use conv nets for more explicit interpretations of how the task can be performed by neural nets. \n\nHowever, at the same time, I had one big question about the purpose and usage of this approach. As the paper states in Introduction, the target problem is 'hard selection' of substructures, rather than 'soft selection' that neural nets (with attention, for example) or neural-net fingerprints usually provide. Then, the problem would become a combinatorial search problem, which has been long studied in the data mining and machine learning community. There would exist many exact methods such as LEAP, CORK, and graphSig under the name of 'contrast/emerging/discriminative' pattern mining exactly developed for this task. Also, it is widely known that we can even perform a wrapper approach for supervised learning from graphs simultaneously with searching all relevant subgraphs as seen in Kudo+ NIPS 2004, Tsuda ICML 2007, Saigo+ Machine Learning 2009, etc. It would be unconvincing that the proposed neural nets approach fits to this hard combinatorial task rather than these existing (mostly exact) methods.\n\nIn addition to the above point, several technical points below would also be unclear.\n\n- A simple heuristic by adding 'selected or not' variables to the atom features works as intended? Because this is fed to the conv net, it seems we can ignore this elements of features by tweaking the weight parameters accordingly. If the conv net performs the best when we use the entire structure, then learning might be forced to ignore the selection. Can we guarantee in some sense this would not happen? \n\n- Zeroing out the atom features also sounds quite simple and a bit groundless. Confusingly, the P network also has an attention mechanism, and it is a bit unclear to me what was actually worked.\n\n- In the experiments, the baseline is based on LR, but this would not be fair because usually we cannot expect any linear relationship for molecular fingerprints. It's highly correlated due to the inclusion relationships between subgraphs. At least, any nonlinear baseline (e.g. Random forest or something?) should be presented for discussing the results.\n\nPros:\n- interesting self-supervised framework provided for highlighting relevant substructures for a given prediction task\n- the hard selection setting is encoded in input graph featurization\n\nCons:\n- it would be a bit unconvincing that identifying 'hard selection' is better suited for neural nets, rather than many existing exact methods (without using neural networks). At least one of the typical ones should be compared or discussed.\n- I'm still not quite sure whether or not some heuristic parts work as intended. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Using Deep Reinforcement Learning to Generate Rationales for Molecules","abstract":"Deep learning algorithms are increasingly used in modeling chemical processes. However, black box predictions without rationales have limited used in practical applications, such as drug design. To this end, we learn to identify molecular substructures -- rationales -- that are associated with the target chemical property (e.g., toxicity). The rationales are learned in an unsupervised fashion, requiring no additional information beyond the end-to-end task. We formulate this problem as a reinforcement learning problem over the molecular graph, parametrized by two convolution networks corresponding to the rationale selection and prediction based on it, where the latter induces the reward function. We evaluate the approach on two benchmark toxicity datasets. We demonstrate that our model sustains high performance under the additional constraint that predictions strictly follow the rationales. Additionally, we validate the extracted rationales through comparison against those described in chemical literature and through synthetic experiments. ","pdf":"/pdf/16b1214dab93b299062351e1d98257d46f9263a8.pdf","TL;DR":"We use a reinforcement learning over molecular graphs to generate rationales for interpretable molecular property prediction.","paperhash":"anonymous|using_deep_reinforcement_learning_to_generate_rationales_for_molecules","_bibtex":"@article{\n  anonymous2018using,\n  title={Using Deep Reinforcement Learning to Generate Rationales for Molecules},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkJ1rgbCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper578/Authors"],"keywords":["Reinforcement Learning","Chemistry","Interpretable Models"]}},{"tddate":null,"ddate":null,"tmdate":1512222693477,"tcdate":1510228806723,"number":1,"cdate":1510228806723,"id":"r11LXabJz","invitation":"ICLR.cc/2018/Conference/-/Paper578/Official_Review","forum":"HkJ1rgbCb","replyto":"HkJ1rgbCb","signatures":["ICLR.cc/2018/Conference/Paper578/AnonReviewer2"],"readers":["everyone"],"content":{"title":"review","rating":"5: Marginally below acceptance threshold","review":"\nThe paper proposes a feature learning technique for molecular prediction using reinforcement learning. The predictive model is an interesting two-step approach where important atoms of the molecule are added one-by-one with a reward given by a second Q-network that learns how well we can solve the prediction problem with the given set of atoms. The overall scheme is intuitive, but \n\nThe model is experimented on two small datasets of few thousand of molecules, and compared to a state-of-the-art DeepTox, and also to some basic baselines (RF/SVM/logreg). In the Tox21 dataset the proposed sparse RL-CNN method is less accurate than DeepTox or full CNN. In the hERG dataset RL-CNN is again weaker than the full CNN, but also seems to be beaten by several baseline methods. Overall the results are surprisingly weak, since e.g. with LASSO one often improves by using less features in complex problems. Both datasets should be compared to LASSO as well. \n\nIt's somewhat odd that the test performance in table 2 is often better than CV performance. This feels suspicious, especially with 79.0 vs 84.3. The table 2 does not seem reliable result, and should use more folds and more randomizations, etc.\n\nThe key problem of the method is its seeming inabability to find the correct number of atoms to use. In both datasets the number of atoms were globally fixed, which is counter-intuitive. The authors should at least provide learning curves where different number of atoms are used; but ideally the method should learn the number of atoms to use for each molecule.\n\nThe proposed Q+P network is interesting, but its unclear how well it works in general. There should be experiments that compare the the Q+P model with incresing number of atoms against a full CNN, to see whether the Q+P can converge to maximal performance.\n\nOverall the method is interesting and has a clear impact for molecular prediction, however the paper has limited appeal to the broader audience. Its difficult to assess how useful the Q/P-network is in general. The inability to choose the optimal number of atoms is a major drawback of the method, and the experimental section could be improved. This paper also would probably be more suitable for a chemoinformatics journal, where the rationale learning would be highly appreciated.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Using Deep Reinforcement Learning to Generate Rationales for Molecules","abstract":"Deep learning algorithms are increasingly used in modeling chemical processes. However, black box predictions without rationales have limited used in practical applications, such as drug design. To this end, we learn to identify molecular substructures -- rationales -- that are associated with the target chemical property (e.g., toxicity). The rationales are learned in an unsupervised fashion, requiring no additional information beyond the end-to-end task. We formulate this problem as a reinforcement learning problem over the molecular graph, parametrized by two convolution networks corresponding to the rationale selection and prediction based on it, where the latter induces the reward function. We evaluate the approach on two benchmark toxicity datasets. We demonstrate that our model sustains high performance under the additional constraint that predictions strictly follow the rationales. Additionally, we validate the extracted rationales through comparison against those described in chemical literature and through synthetic experiments. ","pdf":"/pdf/16b1214dab93b299062351e1d98257d46f9263a8.pdf","TL;DR":"We use a reinforcement learning over molecular graphs to generate rationales for interpretable molecular property prediction.","paperhash":"anonymous|using_deep_reinforcement_learning_to_generate_rationales_for_molecules","_bibtex":"@article{\n  anonymous2018using,\n  title={Using Deep Reinforcement Learning to Generate Rationales for Molecules},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkJ1rgbCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper578/Authors"],"keywords":["Reinforcement Learning","Chemistry","Interpretable Models"]}},{"tddate":null,"ddate":null,"tmdate":1509739225978,"tcdate":1509127383030,"number":578,"cdate":1509739223319,"id":"HkJ1rgbCb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkJ1rgbCb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Using Deep Reinforcement Learning to Generate Rationales for Molecules","abstract":"Deep learning algorithms are increasingly used in modeling chemical processes. However, black box predictions without rationales have limited used in practical applications, such as drug design. To this end, we learn to identify molecular substructures -- rationales -- that are associated with the target chemical property (e.g., toxicity). The rationales are learned in an unsupervised fashion, requiring no additional information beyond the end-to-end task. We formulate this problem as a reinforcement learning problem over the molecular graph, parametrized by two convolution networks corresponding to the rationale selection and prediction based on it, where the latter induces the reward function. We evaluate the approach on two benchmark toxicity datasets. We demonstrate that our model sustains high performance under the additional constraint that predictions strictly follow the rationales. Additionally, we validate the extracted rationales through comparison against those described in chemical literature and through synthetic experiments. ","pdf":"/pdf/16b1214dab93b299062351e1d98257d46f9263a8.pdf","TL;DR":"We use a reinforcement learning over molecular graphs to generate rationales for interpretable molecular property prediction.","paperhash":"anonymous|using_deep_reinforcement_learning_to_generate_rationales_for_molecules","_bibtex":"@article{\n  anonymous2018using,\n  title={Using Deep Reinforcement Learning to Generate Rationales for Molecules},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkJ1rgbCb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper578/Authors"],"keywords":["Reinforcement Learning","Chemistry","Interpretable Models"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}