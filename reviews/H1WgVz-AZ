{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222775105,"tcdate":1511844977311,"number":3,"cdate":1511844977311,"id":"HytdnPcgG","invitation":"ICLR.cc/2018/Conference/-/Paper814/Official_Review","forum":"H1WgVz-AZ","replyto":"H1WgVz-AZ","signatures":["ICLR.cc/2018/Conference/Paper814/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting reinterpretation of SPENs","rating":"9: Top 15% of accepted papers, strong accept","review":"This paper proposes an improvement in the speed of training/inference with structured prediction energy networks (SPENs) by replacing the inner optimization loop with a network trained to predict its outputs.\n\nSPENs are an energy-based structured prediction method, where the final prediction is obtained by optimizing min_y E_theta(f_phi(x), y), i.e., finding the label set y with the least energy, as computed by the energy function E(), using a set of computed features f_phi(x) which comes from a neural network. The key innovation in SPENs was representing the energy function E() as an arbitrary neural network which takes the features f(x) and candidate labels y and outputs a value for the energy. At inference time y can be optimized by gradient descent steps. SPENs are trained using maximum-margin loss functions, so the final optimization problem is max -loss(y, y') where y' = argmin_y E(f(x), y).\n\nThe key idea of this paper is to replace the minimization of the energy function min_y E(f(x), y) with a neural network which is trained to predict the resulting output of this minimization. The resulting formulation is a min-max problem at training time with a striking similarity to the GAN min-max problem, where the y-predicting network learns to predict labels with low energy (according to the E-computing network) and high loss while the energy network learns to assign a high energy to predicted labels which have a higher loss than true labels (i.e. the y-predicting network acts as a generator and the E-predicting network acts as a discriminator).\n\nThe paper explores multiple loss functions and techniques to train these models. They seem rather finnicky, and the experimental results aren't particularly strong when it comes to improving the quality over SPENs but they have essentially the same test-time complexity as simple feedforward models while having accuracy comparable to full inference-requiring energy-based models. The improved understanding of SPENs and potential for further work justify accepting this paper.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Approximate Inference Networks for Structured Prediction","abstract":"Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use neural network architectures to define energy functions that can capture arbitrary dependencies among parts of structured outputs. Prior work used gradient descent for inference, relaxing the structured output to a set of continuous variables and then optimizing the energy with respect to them. We replace this use of gradient descent with a neural network trained to approximate structured argmax inference. This “inference network” outputs continuous values that we treat as the output structure. We develop large-margin training criteria for joint training of the structured energy function and inference network. On multi-label classification we report speed-ups of 10-60x compared to (Belanger et al., 2017) while also improving accuracy. For sequence labeling, for simple structured energies, our approach performs comparably to exact inference while being much faster at test time. We also show how inference networks can replace dynamic programming for test-time inference in conditional random fields, suggestive for their general use for fast inference in structured settings.","pdf":"/pdf/62c1bc7a28c819c0c8dc907876b49a467073ef91.pdf","paperhash":"anonymous|learning_approximate_inference_networks_for_structured_prediction","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Approximate Inference Networks for Structured Prediction},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1WgVz-AZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper814/Authors"],"keywords":["Approximate Inference Networks","Structured Prediction","Multi-Label Classification","Sequence Labeling"]}},{"tddate":null,"ddate":null,"tmdate":1512222775147,"tcdate":1511757014439,"number":2,"cdate":1511757014439,"id":"Sk0CEftxG","invitation":"ICLR.cc/2018/Conference/-/Paper814/Official_Review","forum":"H1WgVz-AZ","replyto":"H1WgVz-AZ","signatures":["ICLR.cc/2018/Conference/Paper814/AnonReviewer2"],"readers":["everyone"],"content":{"title":"New idea for training structured predictors, but unclear motivation and evaluation","rating":"5: Marginally below acceptance threshold","review":"The paper proposes training ``inference networks,'' which are neural network structured predictors. The setup is analogous to generative adversarial networks, where the role of the discriminator is played by a structured prediction energy network (SPEN) and the generator is played by an inference network.\n\nThe idea is interesting. It could be viewed as a type of adversarial training for large-margin structured predictors, where counterexamples, i.e., structures with high loss and low energy, cannot be found by direct optimization. However, it remains unclear why SPENs are the right choice for an energy function.\n\nExperiments suggest that it can result in better structured predictors than training models directly via backpropagation gradient descent. However, the experimental results are not clearly presented. The clarity is poor enough that the paper might not be ready for publication.\n\nComments and questions:\n\n1) It is unclear whether this paper is motivated by training SPENs or by training structured predictors. The setup focuses on using SPENs as an inference network, but this seems inessential. Experiments with simpler energy functions seem to be absent, though the experiments are unclear (see below).\n\n2) The confusion over the motivation is confounded by the fact that the experiments are very unclear. Sometimes predictions are described as the output of SPENs (Tables 2, 3, 4, and 7), sometimes as inference networks (Table 5), and sometimes as a CRF (Tables 4 and 6). In 7.2.2 it says that a BiLSTM is used for the inference network in Twitter POS tagging, but Tables 4 and 6 indicate both CRFs and BiLSTMS? It is also unclear when a model, e.g., BiLSTM or CRF is the energy function (discriminator) or inference network (generator).\n\n3) The third and fourth columns of Table 5 are identical. The presentation should be made consistent, either with dev/test or -retuning/+retuning as the top level headers.\n\n4) It is also unclear how to compare Tables 4 and 5. The second to bottom row of Table 5 seems to correspond with the first row of Table 5, but other methods like slack rescaling have higher performance. What is the takeaway from these two tables supposed to be?\n\n5) Part of the motivation for the work is said to be the increasing interest in inference networks: \"In these and related settings, gradient descent has started to be replaced by inference networks. Our results below provide more evidence for making this transition.\" However, no other work on inference networks is directly cited.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Approximate Inference Networks for Structured Prediction","abstract":"Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use neural network architectures to define energy functions that can capture arbitrary dependencies among parts of structured outputs. Prior work used gradient descent for inference, relaxing the structured output to a set of continuous variables and then optimizing the energy with respect to them. We replace this use of gradient descent with a neural network trained to approximate structured argmax inference. This “inference network” outputs continuous values that we treat as the output structure. We develop large-margin training criteria for joint training of the structured energy function and inference network. On multi-label classification we report speed-ups of 10-60x compared to (Belanger et al., 2017) while also improving accuracy. For sequence labeling, for simple structured energies, our approach performs comparably to exact inference while being much faster at test time. We also show how inference networks can replace dynamic programming for test-time inference in conditional random fields, suggestive for their general use for fast inference in structured settings.","pdf":"/pdf/62c1bc7a28c819c0c8dc907876b49a467073ef91.pdf","paperhash":"anonymous|learning_approximate_inference_networks_for_structured_prediction","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Approximate Inference Networks for Structured Prediction},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1WgVz-AZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper814/Authors"],"keywords":["Approximate Inference Networks","Structured Prediction","Multi-Label Classification","Sequence Labeling"]}},{"tddate":null,"ddate":null,"tmdate":1512222775188,"tcdate":1511742627981,"number":1,"cdate":1511742627981,"id":"H12sn0dlf","invitation":"ICLR.cc/2018/Conference/-/Paper814/Official_Review","forum":"H1WgVz-AZ","replyto":"H1WgVz-AZ","signatures":["ICLR.cc/2018/Conference/Paper814/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Amortized inference for SPENs","rating":"5: Marginally below acceptance threshold","review":"= Quality = \nOverall, the authors do a good job of placing their work in the context of related research, and employ a variety of non-trivial technical details to get their methods to work well. \n\n= Clarity = \n\nOverall, the exposition regarding the method is good. I found the setup for the sequence tagging experiments confusing, tough. See more comments below.\n\n= Originality / Significance = \n\nThe paper presents a clever idea that could help make SPENs more practical. The paper's results also suggest that we should be thinking more broadly about how to using complicated structured distributions as teachers for model compression.\n\n= Major Comment =\n\nI'm concerned by the quality of your results and the overall setup of your experiments. In particular, the principal contribution of the sequence tagging experiments seems top be different than what is advertised earlier on in the paper. \n\nMost of your empirical success is obtained by taking a pretrained CRF energy function and using this as a teacher model to train a feed-forward inference network. You have have very few experiments using a SPEN energy function parametrization that doesn't correspond to a CRF, even though you could have used an arbitrary convnet, RNN, etc. The one exception is when you use the tag language model. This is a good idea, but it is pretrained, not trained using the saddle-point objective you introduce. In fact, you don't have any results demonstrating that the saddle-point approach is better than simpler alternatives.\n\nIt seems that you could have written a very different paper about model compression with CRFs that would have been very interesting and you could've have used many of the same experiments. It's unclear why SPENs are so important. The idea of amortizing inference is perhaps more general. My recommendation is that you either rebrand the paper to be more about general methods for amortizing structured prediction inference using model compression or do more fine-grained experiments with SPENs that demonstrate empirical gains that leverage their flexible deep-network-based energy functions.\n\n\n= Minor Comments = \n\n* You should mention 'Energy Based GANs\"\n\n* I don't understand \"This approach performs backpropagation through each step of gradient descent, permitting more stable training but also evidently more overfitting.\" Why would it overfit more? Simply because training was more stable? Couldn't you prevent overfitting by regularizing more?\n\n* You spend too much space talking about specific hyperparameter ranges, etc. This should be moved to the appendix. You should also add a short summary of the TLM architecture to the main paper body.\n\n* Regarding your footnote discussing using a positive vs. negative sign on the entropy regularization term, I recommend checking out \"Regularizing neural networks by penalizing confident output distributions.\"\n\n* You should add citations for the statement \"In these and related settings, gradient descent has started to be replaced by inference networks.\"\n\n* I didn't find Table 1 particularly illuminating. All of the approaches seem to perform about the same. What conclusions should I make from it?\n\n* Why not use KL divergence as your \\Delta function?\n\n* Why are the results in Table 5 on the dev data?\n\n* I was confused by Table 4. First of all, it took me a very long time to figure out that the middle block of results corresponds to taking a pretrained CRF energy and amortizing inference by training an inference network. This idea of training with a standard loss (conditional log lik.) and then amortizing inference post-hoc was not explicitly introduced as an alternative to the saddle point objective you put forth earlier in the paper. Second, I was very surprised that the inference network outperformed Viterbi (89.7 vs. 89.1 for the same CRF energy). Why is this?\n\n* I'm confused by the difference between Table 6 and Table 4? Why not just include the TLM results in Table 4?\n\n\n\n\n\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Approximate Inference Networks for Structured Prediction","abstract":"Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use neural network architectures to define energy functions that can capture arbitrary dependencies among parts of structured outputs. Prior work used gradient descent for inference, relaxing the structured output to a set of continuous variables and then optimizing the energy with respect to them. We replace this use of gradient descent with a neural network trained to approximate structured argmax inference. This “inference network” outputs continuous values that we treat as the output structure. We develop large-margin training criteria for joint training of the structured energy function and inference network. On multi-label classification we report speed-ups of 10-60x compared to (Belanger et al., 2017) while also improving accuracy. For sequence labeling, for simple structured energies, our approach performs comparably to exact inference while being much faster at test time. We also show how inference networks can replace dynamic programming for test-time inference in conditional random fields, suggestive for their general use for fast inference in structured settings.","pdf":"/pdf/62c1bc7a28c819c0c8dc907876b49a467073ef91.pdf","paperhash":"anonymous|learning_approximate_inference_networks_for_structured_prediction","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Approximate Inference Networks for Structured Prediction},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1WgVz-AZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper814/Authors"],"keywords":["Approximate Inference Networks","Structured Prediction","Multi-Label Classification","Sequence Labeling"]}},{"tddate":null,"ddate":null,"tmdate":1509739086754,"tcdate":1509135337433,"number":814,"cdate":1509739084105,"id":"H1WgVz-AZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1WgVz-AZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Approximate Inference Networks for Structured Prediction","abstract":"Structured prediction energy networks (SPENs; Belanger & McCallum 2016) use neural network architectures to define energy functions that can capture arbitrary dependencies among parts of structured outputs. Prior work used gradient descent for inference, relaxing the structured output to a set of continuous variables and then optimizing the energy with respect to them. We replace this use of gradient descent with a neural network trained to approximate structured argmax inference. This “inference network” outputs continuous values that we treat as the output structure. We develop large-margin training criteria for joint training of the structured energy function and inference network. On multi-label classification we report speed-ups of 10-60x compared to (Belanger et al., 2017) while also improving accuracy. For sequence labeling, for simple structured energies, our approach performs comparably to exact inference while being much faster at test time. We also show how inference networks can replace dynamic programming for test-time inference in conditional random fields, suggestive for their general use for fast inference in structured settings.","pdf":"/pdf/62c1bc7a28c819c0c8dc907876b49a467073ef91.pdf","paperhash":"anonymous|learning_approximate_inference_networks_for_structured_prediction","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Approximate Inference Networks for Structured Prediction},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1WgVz-AZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper814/Authors"],"keywords":["Approximate Inference Networks","Structured Prediction","Multi-Label Classification","Sequence Labeling"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}