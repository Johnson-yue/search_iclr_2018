{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222597799,"tcdate":1511837205235,"number":3,"cdate":1511837205235,"id":"HkTzAHqxf","invitation":"ICLR.cc/2018/Conference/-/Paper247/Official_Review","forum":"SkYibHlRb","replyto":"SkYibHlRb","signatures":["ICLR.cc/2018/Conference/Paper247/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Re-positioning with respect to the literature is needed","rating":"5: Marginally below acceptance threshold","review":"This paper proposes a neural network-based approach to converting natural language questions to SQL queries. The idea is to use a small grammar to facilitate the process, together making some independence assumptions. It is evaluated on a recently introduced dataset for natural language to SQL.\n\nPros:\n- good problem, NL2SQL is an important task given how dominant SQL is\n- incorporating a grammar (\"sketch\") is a sensible improvement.\n\nCons:\n- The dataset used makes very strong simplification assumptions. Not  problem per se, but it is not the most challenging SQL dataset. The ATIS corpus is NL2SQL and much more challenging and realistic:\nDeborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate Hunicke-Smith, David Pallett, Christine Pao, Alexander Rudnicky, and Elizabeth Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In Proceedings of the workshop on Human Language Technology (HLT '94). Association for Computational Linguistics, Stroudsburg, PA, USA, 43-48. DOI: https://doi.org/10.3115/1075812.1075823\n\n- In particular, the assumption that every token in the SQL statement is either an SQL keyword or appears in the natural language statement is rather atypical and unrealistic.\n\n- The use of a grammar in the context of semantic parsing is not novel; see this tutorial for many pointers:\nhttp://yoavartzi.com/tutorial/\n\n- As far as I can tell, the set prediction is essentially predicted each element independently, without taking into account any dependencies. Nothing wrong, but also nothing novel, that is what most semantic parsing/semantic role labeling baseline approaches do. The lack of ordering among the edges, doesn't mean they are independent.\n\n- Given the rather constrained type of questions and SQL statements, it would make sense to compare it against approaches for question answering over knowledge-bases:\nhttps://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf\nWhile SQL can express much more complex queries, the ones supported by the grammar here are not very different.\n\n- Pasupat and Liang (2015) also split the data to make sure different tables appear only in training, dev, test and they developed their dataset using crowd sourcing.\n\n- The comparison against Dong and Lapata (2016) is not fair because their model is agnostic and thus applicable to 4 datasets while the one presented here is tailored to the dataset due the grammar/sketch used. Also, suggesting that previous methods might not generalize well sounds odd given that the method proposed seems to use much larger datasets.\n\n- Not sure I agree that mixing the same tables across training/dev/test is more realistic. If anything, it assumes more training data and manual annotation every time a new table is added.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning","abstract":"Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n    \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.","pdf":"/pdf/aca3047246322a6eb3a9f2222798202f304b722a.pdf","paperhash":"anonymous|sqlnet_generating_structured_queries_from_natural_language_without_reinforcement_learning","_bibtex":"@article{\n  anonymous2018sqlnet:,\n  title={SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkYibHlRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper247/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222599345,"tcdate":1511830566771,"number":2,"cdate":1511830566771,"id":"HksQE4cez","invitation":"ICLR.cc/2018/Conference/-/Paper247/Official_Review","forum":"SkYibHlRb","replyto":"SkYibHlRb","signatures":["ICLR.cc/2018/Conference/Paper247/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Well motivated and straightforward approach for WikiSQL","rating":"7: Good paper, accept","review":"The authors present a neural architecture for the WikiSQL task. The approach can be largely seen as graphical model tailored towards the constrained definition of SQL queries in WikiSQL. The model makes strong independence-assumptions, and only includes interactions between structures where necessary, which reduces the model complexity while alleviating the \"order matters\" problem. An attention mechanism over the columns is used to model the interaction between columns and the op or value in a soft differentiable manner. The results show impressive gains over the baseline, despite using a much simpler model. I appreciated the breakdown of accuracy over the various subtasks, which provides insights into where the challenges lie.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning","abstract":"Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n    \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.","pdf":"/pdf/aca3047246322a6eb3a9f2222798202f304b722a.pdf","paperhash":"anonymous|sqlnet_generating_structured_queries_from_natural_language_without_reinforcement_learning","_bibtex":"@article{\n  anonymous2018sqlnet:,\n  title={SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkYibHlRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper247/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222599383,"tcdate":1511798806706,"number":1,"cdate":1511798806706,"id":"B1y7_3YgM","invitation":"ICLR.cc/2018/Conference/-/Paper247/Official_Review","forum":"SkYibHlRb","replyto":"SkYibHlRb","signatures":["ICLR.cc/2018/Conference/Paper247/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The motivation of the work is neither convincing nor verified empirically","rating":"4: Ok but not good enough - rejection","review":"This submission proposes a new seq2sel solution by adopting two new techniques, a sequence-to-set model and column attention mechanism. They show performance improve over existing studies on WikiSQL dataset.\n\nWhile the paper is written clearly, the contributions of the work heavily depends on the WikiSQL dataset. It is not sure if the approach is generally applicable to other sequence-to-sql workloads. Detailed comments are listed below:\n\n1. WikiSQL dataset contains only a small class of SQL queries, with aggregation over single table and various filtering conditions. It does not involve any complex operator in relational database system, e.g., join and groupby. Due to its simple structure, the problem of sequence-to-sql translation over WikiSQL is actually simplified as a parameter selection problem for a fixed template. This greatly limits the generalization of approaches only applicable to WikiSQL. The authors are encouraged to explore other datasets available in the literature.\n\n2. The \"order-matters\" motivation is not very convincing. It is straightforward to employ a global ordering approach to rank the columns and filtering conditions based on certain rules, e.g., alphabetical order. That could ensure the orders in the SQL results are always consistent.\n\n3. The experiments do not fully verify how the approaches bring performance improvements. In the current version, the authors only report superficial accuracy results on final outcomes, without any deep investigation into why and how their approach works. For instance, they could verify how much accuracy improvement is due to the insensitivity to order in filtering expressions.\n\n4. They do not compare against state-of-the-art solution on column and expression selection. While their attention mechanism over the columns could bring performance improvement, they should have included experiments over existing solutions designed for similar purpose. In (Yin, et al., IJCAI 2016), for example, representations over the columns are learned to generate better column selection.\n\nAs a conclusion, I find the submission contains certain interesting ideas but lacks serious research investigations. The quality of the paper could be much enhanced, if the authors deepen their studies on this direction.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning","abstract":"Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n    \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.","pdf":"/pdf/aca3047246322a6eb3a9f2222798202f304b722a.pdf","paperhash":"anonymous|sqlnet_generating_structured_queries_from_natural_language_without_reinforcement_learning","_bibtex":"@article{\n  anonymous2018sqlnet:,\n  title={SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkYibHlRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper247/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509739405825,"tcdate":1509081505496,"number":247,"cdate":1509739403158,"id":"SkYibHlRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"SkYibHlRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning","abstract":"Synthesizing SQL queries from natural language is a long-standing open problem and has been attracting considerable interest recently. Toward solving the problem, the de facto approach is to employ a sequence-to-sequence-style model. Such an approach will necessarily require the SQL queries to be serialized. Since the same SQL query may have multiple equivalent serializations, training a sequence-to-sequence-style model is sensitive to the choice from one of them. This phenomenon is documented as the \"order-matters\" problem. Existing state-of-the-art approaches rely on reinforcement learning to reward the decoder when it generates any of the equivalent serializations. However, we observe that the improvement from reinforcement learning is limited.\n    \nIn this paper, we propose a novel approach, i.e., SQLNet, to fundamentally solve this problem by avoiding the sequence-to-sequence structure when the order does not matter. In particular, we employ a sketch-based approach where the sketch contains a dependency graph, so that one prediction can be done by taking into consideration only the previous predictions that it depends on. In addition, we propose a sequence-to-set model as well as the column attention mechanism to synthesize the query based on the sketch. By combining all these novel techniques, we show that SQLNet can outperform the prior art by 9% to 13% on the WikiSQL task.","pdf":"/pdf/aca3047246322a6eb3a9f2222798202f304b722a.pdf","paperhash":"anonymous|sqlnet_generating_structured_queries_from_natural_language_without_reinforcement_learning","_bibtex":"@article{\n  anonymous2018sqlnet:,\n  title={SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=SkYibHlRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper247/Authors"],"keywords":[]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}