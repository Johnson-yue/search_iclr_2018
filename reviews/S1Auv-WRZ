{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222720050,"tcdate":1511854271354,"number":3,"cdate":1511854271354,"id":"S1vTg99gz","invitation":"ICLR.cc/2018/Conference/-/Paper687/Official_Review","forum":"S1Auv-WRZ","replyto":"S1Auv-WRZ","signatures":["ICLR.cc/2018/Conference/Paper687/AnonReviewer2"],"readers":["everyone"],"content":{"title":"This paper is good at using the GAN for data augmentation for the one shot learning, and have demonstrated good performance for a variety of datasets.","rating":"6: Marginally above acceptance threshold","review":"This paper is good at using the GAN for data augmentation for the one shot learning, and have demonstrated good performance for a variety of datasets.\nHowever, it seems that the main technique contribution is not so clear. E.g., it is not clear as shown in Figure 3, what is key novelty of the proposed DAGAN, and how does it improve from the existing GAN work. It seems that the paper is a pipeline of many existing works.\nBesides, it will also be interested to see whether this DAGAN can help in the training of prevailing ImageNet and MS COCO tasks.","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation Generative Adversarial Networks","abstract":"Effective training of neural networks requires much data. In the low-data regime,\nparameters are underdetermined, and learnt networks generalise poorly. Data\nAugmentation (Krizhevsky et al., 2012) alleviates this by using existing data\nmore effectively. However standard data augmentation produces only limited\nplausible alternative data. Given there is potential to generate a much broader set\nof augmentations, we design and train a generative model to do data augmentation.\nThe model, based on image conditional Generative Adversarial Networks, takes\ndata from a source domain and learns to take any data item and generalise it\nto generate other within-class data items. As this generative process does not\ndepend on the classes themselves, it can be applied to novel unseen classes of data.\nWe show that a Data Augmentation Generative Adversarial Network (DAGAN)\naugments standard vanilla classifiers well. We also show a DAGAN can enhance\nfew-shot learning systems such as Matching Networks. We demonstrate these\napproaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and\nVGG-Face data. In our experiments we can see over 13% increase in accuracy in\nthe low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%\nto 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we\nobserve an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in\nEMNIST (from 59.5% to 61.3%).","pdf":"/pdf/30db496b2453da8d96dde909f8aadd97369fc82a.pdf","TL;DR":"Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance","paperhash":"anonymous|data_augmentation_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1Auv-WRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper687/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222720088,"tcdate":1511750571347,"number":2,"cdate":1511750571347,"id":"Hym3oxKlf","invitation":"ICLR.cc/2018/Conference/-/Paper687/Official_Review","forum":"S1Auv-WRZ","replyto":"S1Auv-WRZ","signatures":["ICLR.cc/2018/Conference/Paper687/AnonReviewer3"],"readers":["everyone"],"content":{"title":"The proposition is technically sound and the novelty is significant. However, the illustration is not clear enough and need improving.","rating":"9: Top 15% of accepted papers, strong accept","review":"In this paper, the authors have proposed a GAN based method to conduct data augmentation. The cross-class transformations are mapped to a low dimensional latent space using conditional GAN. The paper is technically sound and the novelty is significant. The motivation of the proposed methods is clearly illustrated. Experiments on three datasets demonstrate the advantage of the proposed framework. However, this paper still suffers from some drawbacks as below:\n(1)\tThe illustration of the framework is not clear enough. For example, in figure 3, it says the GAN is designed for “class c”, which is ambiguous whether the authors trained only one network for all class or trained multiple networks and each is trained on one class.\n(2)\tSome details is not clearly given, such as the dimension of the Gaussian distribution, the dimension of the projected  noise and .\n(3)\tThe proposed method needs to sample image pairs in each class. As far as I am concerned, in most cases sampling strategy will affect the performance to some extent. The authors need to show the robustness to sampling strategy of the proposed method.\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation Generative Adversarial Networks","abstract":"Effective training of neural networks requires much data. In the low-data regime,\nparameters are underdetermined, and learnt networks generalise poorly. Data\nAugmentation (Krizhevsky et al., 2012) alleviates this by using existing data\nmore effectively. However standard data augmentation produces only limited\nplausible alternative data. Given there is potential to generate a much broader set\nof augmentations, we design and train a generative model to do data augmentation.\nThe model, based on image conditional Generative Adversarial Networks, takes\ndata from a source domain and learns to take any data item and generalise it\nto generate other within-class data items. As this generative process does not\ndepend on the classes themselves, it can be applied to novel unseen classes of data.\nWe show that a Data Augmentation Generative Adversarial Network (DAGAN)\naugments standard vanilla classifiers well. We also show a DAGAN can enhance\nfew-shot learning systems such as Matching Networks. We demonstrate these\napproaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and\nVGG-Face data. In our experiments we can see over 13% increase in accuracy in\nthe low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%\nto 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we\nobserve an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in\nEMNIST (from 59.5% to 61.3%).","pdf":"/pdf/30db496b2453da8d96dde909f8aadd97369fc82a.pdf","TL;DR":"Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance","paperhash":"anonymous|data_augmentation_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1Auv-WRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper687/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1512222720127,"tcdate":1511665743984,"number":1,"cdate":1511665743984,"id":"H1O8xnDlM","invitation":"ICLR.cc/2018/Conference/-/Paper687/Official_Review","forum":"S1Auv-WRZ","replyto":"S1Auv-WRZ","signatures":["ICLR.cc/2018/Conference/Paper687/AnonReviewer1"],"readers":["everyone"],"content":{"title":"This paper considers the data-augmentation problem which is very interesting. However, I don't see enough contribution in the current version.","rating":"3: Clear rejection","review":"This paper proposes a conditional Generative Adversarial Networks that is used for data augmentation. In order to evaluate the performance of the proposed model, they use Omniglot, EMNIST, and VGG-Faces datasets and uses in the meta-learning task and standard classification task in the low-data regime. The paper is well-written and consistent. \n\nEven though this paper learns to do data-augmentation (which is very interesting ) rather than just simply applies some standard data augmentation techniques and shows improvements in some tasks, I am not convinced about novelty and originality of this paper, especially on the model side. To be more specific, the paper uses the previously proposed conditional GAN as the main component of their model. And for the one-shot learning tasks, it only trains the previously proposed models with these newly augmented data. \n\nIn addition, there are some other works that used GAN as a method for some version of data augmentation:\n- RenderGAN: Generating Realistic Labeled Data\n  https://arxiv.org/abs/1611.01331\n-Data Augmentation in Emotion Classification Using Generative Adversarial Networks\nhttps://arxiv.org/abs/1711.00648\n\nIt is fair to say that their model shows improvement on the above tasks but this improvement comes with a cost of training of GAN network. \n\nIn summary, the idea of the paper is very interesting to learn data-augmentation but yet I am not convinced the current paper has enough novelty and contribution and see the contribution of paper as on more the application side rather than on model and problem side. That said I'd be happy to hear the argument of the author about my comments. ","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Data Augmentation Generative Adversarial Networks","abstract":"Effective training of neural networks requires much data. In the low-data regime,\nparameters are underdetermined, and learnt networks generalise poorly. Data\nAugmentation (Krizhevsky et al., 2012) alleviates this by using existing data\nmore effectively. However standard data augmentation produces only limited\nplausible alternative data. Given there is potential to generate a much broader set\nof augmentations, we design and train a generative model to do data augmentation.\nThe model, based on image conditional Generative Adversarial Networks, takes\ndata from a source domain and learns to take any data item and generalise it\nto generate other within-class data items. As this generative process does not\ndepend on the classes themselves, it can be applied to novel unseen classes of data.\nWe show that a Data Augmentation Generative Adversarial Network (DAGAN)\naugments standard vanilla classifiers well. We also show a DAGAN can enhance\nfew-shot learning systems such as Matching Networks. We demonstrate these\napproaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and\nVGG-Face data. In our experiments we can see over 13% increase in accuracy in\nthe low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%\nto 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we\nobserve an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in\nEMNIST (from 59.5% to 61.3%).","pdf":"/pdf/30db496b2453da8d96dde909f8aadd97369fc82a.pdf","TL;DR":"Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance","paperhash":"anonymous|data_augmentation_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1Auv-WRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper687/Authors"],"keywords":[]}},{"tddate":null,"ddate":null,"tmdate":1509739159376,"tcdate":1509132150278,"number":687,"cdate":1509739156698,"id":"S1Auv-WRZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"S1Auv-WRZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Data Augmentation Generative Adversarial Networks","abstract":"Effective training of neural networks requires much data. In the low-data regime,\nparameters are underdetermined, and learnt networks generalise poorly. Data\nAugmentation (Krizhevsky et al., 2012) alleviates this by using existing data\nmore effectively. However standard data augmentation produces only limited\nplausible alternative data. Given there is potential to generate a much broader set\nof augmentations, we design and train a generative model to do data augmentation.\nThe model, based on image conditional Generative Adversarial Networks, takes\ndata from a source domain and learns to take any data item and generalise it\nto generate other within-class data items. As this generative process does not\ndepend on the classes themselves, it can be applied to novel unseen classes of data.\nWe show that a Data Augmentation Generative Adversarial Network (DAGAN)\naugments standard vanilla classifiers well. We also show a DAGAN can enhance\nfew-shot learning systems such as Matching Networks. We demonstrate these\napproaches on Omniglot, on EMNIST having learnt the DAGAN on Omniglot, and\nVGG-Face data. In our experiments we can see over 13% increase in accuracy in\nthe low-data regime experiments in Omniglot (from 69% to 82%), EMNIST (73.9%\nto 76%) and VGG-Face (4.5% to 12%); in Matching Networks for Omniglot we\nobserve an increase of 0.5% (from 96.9% to 97.4%) and an increase of 1.8% in\nEMNIST (from 59.5% to 61.3%).","pdf":"/pdf/30db496b2453da8d96dde909f8aadd97369fc82a.pdf","TL;DR":"Conditional GANs trained to generate data augmented samples of their conditional inputs used to enhance vanilla classification and one shot learning systems such as matching networks and pixel distance","paperhash":"anonymous|data_augmentation_generative_adversarial_networks","_bibtex":"@article{\n  anonymous2018data,\n  title={Data Augmentation Generative Adversarial Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1Auv-WRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper687/Authors"],"keywords":[]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}