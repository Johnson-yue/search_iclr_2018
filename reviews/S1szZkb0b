{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222663703,"tcdate":1511818441439,"number":3,"cdate":1511818441439,"id":"Hy-CEZ5lM","invitation":"ICLR.cc/2018/Conference/-/Paper472/Official_Review","forum":"S1szZkb0b","replyto":"S1szZkb0b","signatures":["ICLR.cc/2018/Conference/Paper472/AnonReviewer2"],"readers":["everyone"],"content":{"title":"A learning framework that does not seem to be greater than its parts","rating":"5: Marginally below acceptance threshold","review":"The authors present a framework that combines multiple learning approaches, including active, interactive, and strategic learning. The robot can improve motor primitives or create procedures (sequences of two motor primitives) either through experience or from a teacher. The framework was evaluated on a simulated manipulation task with two joysticks and a pen for drawing.\n\n\nThe paper could be written more clearly and concretely. The introduction is quite vague and the terminology is at times confusing (A policy is not an action, and an outcome is not a task). \n\nWhy limit the procedures to only chaining two primitives? Why not allow procedures of procedures?  \n\nThe evaluation environment is somewhat abstract. How much engineering would be required for defining the prior knowledge and hierarchical task structure for more complex real world scenarios? The authors should consider using a more realistic interrelated task environment, such as operating a microwave. \n\nMy main concern is that the bigger message of the paper is not clear. Combining different types of learning is an important research topic. It is not clear though if there is any synergy between these learning approaches, and whether or not the overall approach for selecting between methods is suitable.  The fact that the frameworks that use procedures explored further then those that do not is not surprising. The fact that the proposed method learned faster because it had access to expert teachers is also to be expected. The authors should include a comparison to a method that has access to the same resources as the proposed method, but selects them randomly or in a fixed order. A table highlighting the differences between the evaluated methods would also help the reader interpret the results of the experiments. \n\nThe evaluations seem to focus on the ability to cover the largest region of the outcome space. Is this really the most important/relevant measure of success?  One of the challenges of real world manipulation is that there are vast numbers of things an agent could do, but only a very small subset of these are actually useful. The authors should include an additional set of manually designed outcomes, e.g., drawing a circle or moving the game agent into a corner, and evaluating on these as well as the linear outcomes. \n\n\nMinor comments:\n- Add error bars to figure 3\n- I don’t understand Alg. 1, please add text explaining the steps.\n- Rather than introducing “procedures”, could you not use an existing term like macro actions, skill chains, or sequences?\n- The Acknowledgements should ideally be omitted for double-blind reviews.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner","abstract":"We propose an active learning architecture, capable of organizing its learning process to learn complex motor policies (which are succession of primitive motor policies) achieving multiple outcomes: Socially Guided Intrinsic Motivation at High Level (SGIM-HL). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.\n\nWe introduce a new framework called \"procedures\", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our \"procedures\" increases the agent's capability to learn complex tasks.","pdf":"/pdf/73c1153a4a047dedb403b54c16c48ac8509b418c.pdf","TL;DR":"The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.","paperhash":"anonymous|learning_a_set_of_interrelated_tasks_by_using_a_succession_of_motor_policies_for_a_socially_guided_intrinsically_motivated_learner","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1szZkb0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper472/Authors"],"keywords":["developmental robotics","intrinsic motivation","strategic learning","complex motor policies"]}},{"tddate":null,"ddate":null,"tmdate":1512222663747,"tcdate":1511568927997,"number":2,"cdate":1511568927997,"id":"BJuQ8N8lf","invitation":"ICLR.cc/2018/Conference/-/Paper472/Official_Review","forum":"S1szZkb0b","replyto":"S1szZkb0b","signatures":["ICLR.cc/2018/Conference/Paper472/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Not self-contained.  ","rating":"5: Marginally below acceptance threshold","review":"Clarity \n- The method description is not self-contained. Key parts of the algorithm are borrowed from Baranes & Oudeyer (2010) and Nguyen & Oudeyer (2012) without sufficient details.  \n- The competence progress metric (p(\\omega_{g})) is never specified in the paper. \n- It is not clear what the agent will do if a goal in the plan is not achieved.\n\nOriginality\nThe proposed SGIM-HL is similar to SGIM-ACTS (Nguyen & Oudeyer 2012). The only difference is that SGIM-HL leverages a new procedure mechanism. But the motivation of utilizing procedures is not clear and there is no empirical comparison against SGIM-ACTS.  \n\nSignificance\n- The method requires pre-defined policy space split and task space split. Such requirement may limit the practical value of the method. \n- The test domain is not very interesting in that it assumes perfect low-dimensional perception and the transitions are deterministic by design. \n- The method is not compared against some general RL method. \n- The method is closely related to SGIM-ACTS, but no comparison is provided. \n- Figure 3 and 4 require confidence intervals or standard errors. \n\nThe acknowledgements might violate the double-blind reviews.\n\nPros:\n- Learning to choose when to request human information or learn in autonomy sounds like a good topic.\n\nCons:\n- Method description is not self-contained.  \n- The test domain is artificial and not interesting. \n- There is no evidence that the method could work on general domains. \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner","abstract":"We propose an active learning architecture, capable of organizing its learning process to learn complex motor policies (which are succession of primitive motor policies) achieving multiple outcomes: Socially Guided Intrinsic Motivation at High Level (SGIM-HL). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.\n\nWe introduce a new framework called \"procedures\", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our \"procedures\" increases the agent's capability to learn complex tasks.","pdf":"/pdf/73c1153a4a047dedb403b54c16c48ac8509b418c.pdf","TL;DR":"The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.","paperhash":"anonymous|learning_a_set_of_interrelated_tasks_by_using_a_succession_of_motor_policies_for_a_socially_guided_intrinsically_motivated_learner","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1szZkb0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper472/Authors"],"keywords":["developmental robotics","intrinsic motivation","strategic learning","complex motor policies"]}},{"tddate":null,"ddate":null,"tmdate":1512222663786,"tcdate":1511540702743,"number":1,"cdate":1511540702743,"id":"SJvJ_TrxG","invitation":"ICLR.cc/2018/Conference/-/Paper472/Official_Review","forum":"S1szZkb0b","replyto":"S1szZkb0b","signatures":["ICLR.cc/2018/Conference/Paper472/AnonReviewer1"],"readers":["everyone"],"content":{"title":"How general is this?","rating":"4: Ok but not good enough - rejection","review":"Quality\n======\nThe paper proposes an extension of a (somewhat niche) method and evaluates it on a task that seems fairly constructed. The new approach consistently outperforms prior approaches.\n\nClarity\n=====\nThe paper reads well. Quite a lot of details are glossed over and some properties only become clear very late on.\n\nOriginality\n=========\nThe approach seems original.\n\nSignificance\n==========\nA wider applicability of the approach remains to be demonstrated.\n\nPros and Cons\n============\n+ challenging task\n+ interesting framework\n- constructed evaluation\n- many assumptions and a lot of prior knowledge needed\n- embedding in the state-of-the-art missing","confidence":"2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner","abstract":"We propose an active learning architecture, capable of organizing its learning process to learn complex motor policies (which are succession of primitive motor policies) achieving multiple outcomes: Socially Guided Intrinsic Motivation at High Level (SGIM-HL). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.\n\nWe introduce a new framework called \"procedures\", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our \"procedures\" increases the agent's capability to learn complex tasks.","pdf":"/pdf/73c1153a4a047dedb403b54c16c48ac8509b418c.pdf","TL;DR":"The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.","paperhash":"anonymous|learning_a_set_of_interrelated_tasks_by_using_a_succession_of_motor_policies_for_a_socially_guided_intrinsically_motivated_learner","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1szZkb0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper472/Authors"],"keywords":["developmental robotics","intrinsic motivation","strategic learning","complex motor policies"]}},{"tddate":null,"ddate":null,"tmdate":1511540246754,"tcdate":1511540177725,"number":1,"cdate":1511540177725,"id":"By50raBlf","invitation":"ICLR.cc/2018/Conference/-/Paper472/Official_Comment","forum":"S1szZkb0b","replyto":"S1szZkb0b","signatures":["ICLR.cc/2018/Conference/Paper472/AnonReviewer1"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper472/AnonReviewer1"],"content":{"title":"many open questions...","comment":"What a long title...\n\n- I did not get why using the Euclidean distance is a good idea for the outcomes (e.g., when considering positions and orientations, forces, etc.)\n- Section 2.2: I was already wondering here why we are limited to combining 2 procedures\n- Section 2.2.: So we have a fixed sequence. How about recovery movements if something does not go as planned?\n- Algo 1: is totally unclear\n- I would have liked a more explicit discussion on what's different compared to (Nguyen & Oudeyer, 2012)\n- The task seems rather artificial\n- Sect. 3.1.: How limiting is always starting at the same position?\n- Sect. 3.2.2. \"the robot learns\", I don't get that, it learns which ones to use, but not the task spaces themselves, I think\n- Sect. 3: You include lots and lots of prior knowledge. How general is this approach? How quickly does it break down if the task spaces and/or teachers don't match the skills you want to learn?\n\nMinor comments:\n===============\n- Correct (opening) quote marks in LaTeX https://en.wikibooks.org/wiki/LaTeX/Text_Formatting#Quote-marks\n- The formatting of the references is strange \"(Lungarella et al. (2003))\" => \"(Lungarella et al., 2003)\"\n- (Theodorou et al., 2010) is a great paper but probably not the best reference for general RL\n- The related work all seem to be a bit on the old side (mainly up to 2010)\n- \"don't\" => \"do not\" etc.\n- would be nice to have variances for the figures\n- acknowledgements should be removed for double blind review\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner","abstract":"We propose an active learning architecture, capable of organizing its learning process to learn complex motor policies (which are succession of primitive motor policies) achieving multiple outcomes: Socially Guided Intrinsic Motivation at High Level (SGIM-HL). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.\n\nWe introduce a new framework called \"procedures\", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our \"procedures\" increases the agent's capability to learn complex tasks.","pdf":"/pdf/73c1153a4a047dedb403b54c16c48ac8509b418c.pdf","TL;DR":"The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.","paperhash":"anonymous|learning_a_set_of_interrelated_tasks_by_using_a_succession_of_motor_policies_for_a_socially_guided_intrinsically_motivated_learner","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1szZkb0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper472/Authors"],"keywords":["developmental robotics","intrinsic motivation","strategic learning","complex motor policies"]}},{"tddate":null,"ddate":null,"tmdate":1509739283351,"tcdate":1509122323103,"number":472,"cdate":1509739280695,"id":"S1szZkb0b","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"S1szZkb0b","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner","abstract":"We propose an active learning architecture, capable of organizing its learning process to learn complex motor policies (which are succession of primitive motor policies) achieving multiple outcomes: Socially Guided Intrinsic Motivation at High Level (SGIM-HL). The learner can generalize over its experience to continuously learn new outcomes, by choosing actively what and how to learn guided by empirical measures of its own progress. In this paper, we are considering the learning of a set of interrelated complex outcomes hierarchically organized.\n\nWe introduce a new framework called \"procedures\", which enables the autonomous discovery of how to combine previously learned skills in order to learn increasingly more complex motor policies (combinations of primitive motor policies). Our architecture can actively decide which outcome to focus on and which exploration strategy to apply. Those strategies could be autonomous exploration, or active social guidance, where it relies on the expertise of a human teacher providing demonstrations at the learner's request. We show on a simulated environment that our new architecture is capable of tackling the learning of complex motor policies, to adapt the complexity of its policies to the task at hand. We also show that our \"procedures\" increases the agent's capability to learn complex tasks.","pdf":"/pdf/73c1153a4a047dedb403b54c16c48ac8509b418c.pdf","TL;DR":"The paper describes a strategic intrinsically motivated learning algorithm which tackles the learning of complex motor policies.","paperhash":"anonymous|learning_a_set_of_interrelated_tasks_by_using_a_succession_of_motor_policies_for_a_socially_guided_intrinsically_motivated_learner","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning a set of interrelated tasks by using a succession of motor policies for a socially guided intrinsically motivated learner},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=S1szZkb0b}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper472/Authors"],"keywords":["developmental robotics","intrinsic motivation","strategic learning","complex motor policies"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}