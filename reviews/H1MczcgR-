{"notes":[{"tddate":null,"ddate":null,"tmdate":1512187474304,"tcdate":1512187474304,"number":1,"cdate":1512187474304,"id":"By9IIjkZM","invitation":"ICLR.cc/2018/Conference/-/Paper348/Official_Comment","forum":"H1MczcgR-","replyto":"B1EVroyWG","signatures":["ICLR.cc/2018/Conference/Paper348/AnonReviewer4"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper348/AnonReviewer4"],"content":{"title":"another comment regarding Figure 1","comment":"I think you could make a figure that much more clearly demonstrates the issue to replace or add to the current Figure 1.\n\nCompute the meta-loss for learning the learning rate for some small problem (e.g. stochastic quadratics). This meta-loss is a 1D function over the learning rate. For a small number of unrolled steps, this function should have minima at low values of the learning rate. You can plot this meta-loss for different numbers of unrolls on the same graph, which should show that the minima of the meta-loss shifts to higher learning rates as you unroll for more steps. This is related to Figure 4, but I think would be a nice way to introduce the problem in an easily digestible picture."},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Understanding Short-Horizon Bias in Stochastic Meta-Optimization","abstract":"Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.","pdf":"/pdf/0c4d4ac33c7d38f86775a6ac02ba3bd1c8a07780.pdf","TL;DR":"We investigate the bias in the short-horizon meta-optimization objective.","paperhash":"anonymous|understanding_shorthorizon_bias_in_stochastic_metaoptimization","_bibtex":"@article{\n  anonymous2018understanding,\n  title={Understanding Short-Horizon Bias in Stochastic Meta-Optimization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1MczcgR-}\n}","keywords":["meta-learning; optimization; short-horizon bias."],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper348/Authors"]}},{"tddate":null,"ddate":null,"tmdate":1512222623714,"tcdate":1512187179738,"number":3,"cdate":1512187179738,"id":"B1EVroyWG","invitation":"ICLR.cc/2018/Conference/-/Paper348/Official_Review","forum":"H1MczcgR-","replyto":"H1MczcgR-","signatures":["ICLR.cc/2018/Conference/Paper348/AnonReviewer4"],"readers":["everyone"],"content":{"title":"A clear and well written demonstration of a fundamental issue with meta-optimization.","rating":"8: Top 50% of accepted papers, clear accept","review":"This paper studies the issue of truncated backpropagation for meta-optimization. Backpropagation through an optimization process requires unrolling the optimization, which due to computational and memory constraints, is typically restricted or truncated to a smaller number of unrolled steps than we would like.\n\nThis paper highlights this problem as a fundamental issue limiting meta-optimization approaches. The authors perform a number of experiments on a toy problem (stochastic quadratics) which is amenable to some theoretical analysis as well as a small fully connected network trained on MNIST.  \n\n(side note: I was assigned this paper quite late in the review process, and have not carefully gone through the derivations--specifically Theorems 1 and 2).\n\nThe paper is generally clear and well written.\n\nMajor comments\n-------------------------\nI was a bit confused why 1000 SGD+mom steps pre-training steps were needed. As far as I can tell, pre-training is not typically done in the other meta-optimization literature? The authors suggest this is needed because \"the dynamics of training are different at the very start compared to later stages\", which is a bit vague. Perhaps the authors can expand upon  this point?\n\nThe conclusion suggests that the difference in greedy vs. fully optimized schedule is due to the curvature (poor scaling) of the objective--but Fig 2. and earlier discussion talked about the noise in the objective as introducing the bias (e.g. from earlier in the paper, \"The noise in the problem adds uncertainty to the objective, resulting in failures of greedy schedule\"). Which is the real issue, noise or curvature? Would running the problem on quadratics with different condition numbers be insightful?\n\nMinor comments\n-------------------------\nThe stochastic gradient equation in Sec 2.2.2 is missing a subscript: \"h_i\" instead of \"h\"\n\nIt would be nice to include the loss curve for a fixed learning rate and momentum for the noisy quadratic in Figure 2, just to get a sense of how that compares with the greedy and optimized curves.\n\nIt looks like there was an upper bound constraint placed on the optimized learning rate in Figure 2--is that correct? I couldn't find a mention of the constraint in the paper. (the optimized learning rate remains at 0.2 for the first ~60 steps)?\n\nFigure 2 (and elsewhere): I would change 'optimal' to 'optimized' to distinguish it from an optimal curve that might result from an analytic derivation. 'Optimized' makes it more clear that the curve was obtained using an optimization process.\n\nFigure 2: can you change the line style or thickness so that we can see both the red and blue curves for the deterministic case? I assume the red curve is hiding beneath the blue one--but it would be good to see this explicitly.\n\nFigure 4 is fantastic--it succinctly and clearly demonstrates the problem of truncated unrolls. I would add a note in the caption to make it clear that the SMD trajectories are the red curves, e.g.: \"SMD trajectories (red) during meta-optimization of initial effective ...\". I would also change the caption to use \"meta-training losses\" instead of \"training losses\" (I believe those numbers are for the meta-loss, correct?). Finally, I would add a colorbar to indicate numerical values for the different grayscale values.\n\nSome recent references that warrant a mention in the text:\n- both of these learn optimizers using longer numbers of unrolled steps:\nLearning gradient descent: better generalization and longer horizons, Lv et al, ICML 2017\nLearned optimizers that scale and generalize, Wichrowska et al, ICML 2017\n- another application of unrolled optimization:\nUnrolled generative adversarial networks, Metz et al, ICLR 2017\n\nIn the text discussing Figure 4 (middle of pg. 8) , \"which is obtained by using...\" should be \"which are obtained by using...\"\n\nIn the conclusion, \"optimal for deterministic objective\" should be \"deterministic objectives\"","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Understanding Short-Horizon Bias in Stochastic Meta-Optimization","abstract":"Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.","pdf":"/pdf/0c4d4ac33c7d38f86775a6ac02ba3bd1c8a07780.pdf","TL;DR":"We investigate the bias in the short-horizon meta-optimization objective.","paperhash":"anonymous|understanding_shorthorizon_bias_in_stochastic_metaoptimization","_bibtex":"@article{\n  anonymous2018understanding,\n  title={Understanding Short-Horizon Bias in Stochastic Meta-Optimization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1MczcgR-}\n}","keywords":["meta-learning; optimization; short-horizon bias."],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper348/Authors"]}},{"tddate":null,"ddate":null,"tmdate":1512222623751,"tcdate":1511827332115,"number":2,"cdate":1511827332115,"id":"Hkhtvm5eM","invitation":"ICLR.cc/2018/Conference/-/Paper348/Official_Review","forum":"H1MczcgR-","replyto":"H1MczcgR-","signatures":["ICLR.cc/2018/Conference/Paper348/AnonReviewer3"],"readers":["everyone"],"content":{"title":"simplified model demonstrating a problem of meta-learning learning rate","rating":"6: Marginally above acceptance threshold","review":"This paper proposes a simple problem to demonstrate the short-horizon bias of the learning rate meta-optimization.\n\n- The idealized case of quadratic function the analytical solution offers a good way to understand how T-step look ahead can benefit the meta-algorithm.\n- The second part of the paper seems to be a bit disconnected to the quadratic function analysis. It would be helpful to understand if there is gap between gradient based meta-optimization and the best effort(given by the analytical solution)\n- Unfortunately, no guideline or solution is offered in the paper.\n\nIn summary, the idealized model gives a good demonstration of the problem itself. I think it might be of interest to some audiences in ICLR.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Understanding Short-Horizon Bias in Stochastic Meta-Optimization","abstract":"Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.","pdf":"/pdf/0c4d4ac33c7d38f86775a6ac02ba3bd1c8a07780.pdf","TL;DR":"We investigate the bias in the short-horizon meta-optimization objective.","paperhash":"anonymous|understanding_shorthorizon_bias_in_stochastic_metaoptimization","_bibtex":"@article{\n  anonymous2018understanding,\n  title={Understanding Short-Horizon Bias in Stochastic Meta-Optimization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1MczcgR-}\n}","keywords":["meta-learning; optimization; short-horizon bias."],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper348/Authors"]}},{"ddate":null,"tddate":1511275839365,"tmdate":1512222623786,"tcdate":1511275721353,"number":1,"cdate":1511275721353,"id":"BkZRhnbxz","invitation":"ICLR.cc/2018/Conference/-/Paper348/Official_Review","forum":"H1MczcgR-","replyto":"H1MczcgR-","signatures":["ICLR.cc/2018/Conference/Paper348/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting work on meta-optimization","rating":"7: Good paper, accept","review":"The paper discusses the problems of meta optimization with small look-ahead: do small runs bias the results of tuning? The result is yes and the authors show how differently the tuning can be compared to tuning the full run. The Greedy schedules are far inferior to hand-tuned schedules as they focus on optimizing the large eigenvalues while the small eigenvalues can not be \"seen\" with a small lookahead. The authors show that this effect is caused by the noise in the obective function.\n\npro:\n- Thorough discussion of the issue with theoretical understanding on small benchmark functions as well as theoretical work\n- Easy to read and follow\n\ncons:\n-Small issues in presentation: \n* Figure 2 \"optimal learning rate\" -> \"optimal greedy learning rate\", also reference to Theorem 2 for increased clarity.\n* The optimized learning rate in 2.3 is not described. This reduces reproducibility.\n* Figure 4 misses the red trajectories, also it would be easier to have colors on the same (log?)-scale. \n  The text unfortunately does not explain why the loss function looks so vastly different\n  with different look-ahead. I would assume from the description that the colors are based\n  on the final loss values obtaine dby choosing a fixed pair of decay exponent and effective LR. \n\nTypos and notation:\npage 7 last paragraph: \"We train the all\" -> We train all\nnotation page 5: i find \\nabla_{\\theta_i} confusing when \\theta_i is a scalar, i would propose \\frac{\\partial}{\\partial \\theta_i}\npage 2: \"But this would come at the expense of long-term optimization process\": at this point of the paper it is not clear how or why this should happen. Maybe add a sentence regarding the large/Small eigenvalues?","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Understanding Short-Horizon Bias in Stochastic Meta-Optimization","abstract":"Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.","pdf":"/pdf/0c4d4ac33c7d38f86775a6ac02ba3bd1c8a07780.pdf","TL;DR":"We investigate the bias in the short-horizon meta-optimization objective.","paperhash":"anonymous|understanding_shorthorizon_bias_in_stochastic_metaoptimization","_bibtex":"@article{\n  anonymous2018understanding,\n  title={Understanding Short-Horizon Bias in Stochastic Meta-Optimization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1MczcgR-}\n}","keywords":["meta-learning; optimization; short-horizon bias."],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper348/Authors"]}},{"ddate":null,"tddate":1509200780981,"tmdate":1509739351163,"tcdate":1509102218399,"number":348,"cdate":1509739348507,"id":"H1MczcgR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H1MczcgR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Understanding Short-Horizon Bias in Stochastic Meta-Optimization","abstract":"Careful tuning of the learning rate, or even schedules thereof, can be crucial to effective neural net training. There has been much recent interest in gradient-based meta-optimization, where one tunes hyperparameters, or even learns an optimizer, in order to minimize the expected loss when the training procedure is unrolled. But because the training procedure must be unrolled thousands of times, the meta-objective must be defined with an orders-of-magnitude shorter time horizon than is typical for neural net training. We show that such short-horizon meta-objectives cause a serious bias towards small step sizes, an effect we term short-horizon bias. We introduce a toy problem, a noisy quadratic cost function, on which we analyze short-horizon bias by deriving and comparing the optimal schedules for short and long time horizons. We then run meta-optimization experiments (both offline and online) on standard benchmark datasets, showing that meta-optimization chooses too small a learning rate by multiple orders of magnitude, even when run with a moderately long time horizon (100 steps) typical of work in the area. We believe short-horizon bias is a fundamental problem that needs to be addressed if meta-optimization is to scale to practical neural net training regimes.","pdf":"/pdf/0c4d4ac33c7d38f86775a6ac02ba3bd1c8a07780.pdf","TL;DR":"We investigate the bias in the short-horizon meta-optimization objective.","paperhash":"anonymous|understanding_shorthorizon_bias_in_stochastic_metaoptimization","_bibtex":"@article{\n  anonymous2018understanding,\n  title={Understanding Short-Horizon Bias in Stochastic Meta-Optimization},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H1MczcgR-}\n}","keywords":["meta-learning; optimization; short-horizon bias."],"authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper348/Authors"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}