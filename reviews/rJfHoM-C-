{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222819237,"tcdate":1512000304420,"number":3,"cdate":1512000304420,"id":"H1_Nsp3gz","invitation":"ICLR.cc/2018/Conference/-/Paper922/Official_Review","forum":"rJfHoM-C-","replyto":"rJfHoM-C-","signatures":["ICLR.cc/2018/Conference/Paper922/AnonReviewer1"],"readers":["everyone"],"content":{"title":"No Title","rating":"6: Marginally above acceptance threshold","review":"This paper proposes an approach for few-shot classification based on a geometric idea. The basic assumption is that a query instance will be closest to the polytope corresponding to the correct class than to other classes, where they consider polytopes formed by selecting samples from each class as vertices. As a distance metric, authors consider the variation of the volume of each class-polytope when a query instance is added to the corresponding class. Given that there is not a method to calculate the volume of a general convex polytope, they approximate the polytope by the corresponding simplex convex (convex polytope with the condition of n = d). Fortunately, in the case of the simplex, there is close form solution to obtain the volume.\n\nIn general, the paper is well presented and, as far as I know, the proposed idea is novel and sound. Experimentation is correct. Results indicate that the proposed method is able to outperform related state-of-the-art techniques, achieving a reasonable improvement, approx. 1-3% depending of the dataset. \n\nAs a drawback, for each query instance, the method needs to estimate the distance to the simplex of each class, therefore it does not scale well with the number of classes. Authors should comment about this issue, in particular, about the computational complexity of the proposed method. Also, in the cases presented in the paper, the selection of the training instances used to calculate the simplex is straight-forward, however, in a more general case, this could be a relevant problem. It will be good to comment about this issue.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-shot learning with simplex","abstract":"Deep learning has made remarkable achievement in many fields. However, learning\nparameters of a neural networks usually needs a large amount of labeled data.\nThe algorithms of deep learning, therefore, encounter difficulty when applied to\nsupervised learning where only little data are available. This problem is called\none-shot learning. To address it, we propose a novel algorithm for few-shot learning\nusing discrete geometry, in the sense that the samples in a class are modeled\nas a reduced simplex. The volume of the simplex is used for the measurement of\nclass scatter. During testing, combined with the test sample and the points in the\nclass, a new simplex is formed. Then the similarity between the test sample and\nthe class can be quantized with the ratio of volumes of the new simplex to the original\nclass simplex. Moreover, we present an approach to constructing simplices\nusing local regions of feature maps yielded by convolutional neural networks. Experiments\non Omniglot and miniImageNet verify the superiority of our simplex\nalgorithm on few-shot learning.","pdf":"/pdf/fddb579342c402e865d07408e33a91d47f614525.pdf","TL;DR":"A simplex-based geometric method is proposed to cope with few-shot learning problems.","paperhash":"anonymous|fewshot_learning_with_simplex","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-shot learning with simplex},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJfHoM-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper922/Authors"],"keywords":["one-shot learning","few-shot learning","deep learning","simplex"]}},{"tddate":null,"ddate":null,"tmdate":1512222819283,"tcdate":1511913711902,"number":2,"cdate":1511913711902,"id":"r1_gtOolG","invitation":"ICLR.cc/2018/Conference/-/Paper922/Official_Review","forum":"rJfHoM-C-","replyto":"rJfHoM-C-","signatures":["ICLR.cc/2018/Conference/Paper922/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Interesting technique but more complicated and lower performance than recent approaches","rating":"4: Ok but not good enough - rejection","review":"This work proposes a method for few-shot classification that treats a set of embedded points belonging to a class as a simplex. Classification for an unlabeled test point is performed by selecting the class whose augmented simplex has the smallest volume relative to the original class simplex.\n\nStrengths\n- The use of simplices for representing classes in few-shot learning is novel.\n\nWeaknesses\n- A number of recent related few-shot learning approaches are missing from the related work.\n- In light of missing baselines, the proposed method does not perform better than recent few-shot approaches.\n\nI am not an expert on simplices, but the derivations in the paper appear to be correct, with two exceptions: (a) equation 6 appears to be the ratio of C^2(Y U t) / C(Y), (b) equation 6 appears to be missing a minus sign.\n\nThe writing of the paper is relatively clear, however there are several important issues:\n- Background on metric learning is missing.\n- The training loss is not described (i.e. how is the volume ratio from equation 7 converted into a probability distribution over classes?).\n- The local feature representation in Section 3 is unclear and should be explained in more detail.\n- Related work is missing recent few-shot learning approaches, including MAML [1], Prototypical Networks [2], and TCML [3].\n\nThe proposed method is a metric learning approach but it has some additional restrictions relative to other such techniques for few-shot learning such as Matching Networks or Prototypical Networks. One is that the computation of volume ratio involves matrix inversion of P and Q. Another is that the method is not defined when the number of points exceeds the dimensionality of the embedding space. These are not likely to be an issue for few-shot learning, but should be noted as interest in methods that scale gracefully from the few-shot to ordinary classification increases.\n\nRegarding Omniglot results, 20-way 1-shot/5-shot experiments are widely reported in related work but missing from the paper.\n\nWhen the results are viewed in light of missing baselines, such as Prototypical Networks (68.2% on 5-way 5-shot miniImagenet), the proposed method is more complicated and performs significantly worse.\n\nOverall, the proposed approach is interesting but there are significant issues with both background/related work and performance relative to missing baselines.\n\n[1] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. \"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.\" ICML 2017.\n[2] Snell, Jake, Kevin Swersky, and Richard S. Zemel. \"Prototypical Networks for Few-shot Learning.\" NIPS 2017.\n[3] Mishra, Nikhil, et al. \"Meta-Learning with Temporal Convolutions.\" arXiv preprint arXiv:1707.03141 (2017).","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-shot learning with simplex","abstract":"Deep learning has made remarkable achievement in many fields. However, learning\nparameters of a neural networks usually needs a large amount of labeled data.\nThe algorithms of deep learning, therefore, encounter difficulty when applied to\nsupervised learning where only little data are available. This problem is called\none-shot learning. To address it, we propose a novel algorithm for few-shot learning\nusing discrete geometry, in the sense that the samples in a class are modeled\nas a reduced simplex. The volume of the simplex is used for the measurement of\nclass scatter. During testing, combined with the test sample and the points in the\nclass, a new simplex is formed. Then the similarity between the test sample and\nthe class can be quantized with the ratio of volumes of the new simplex to the original\nclass simplex. Moreover, we present an approach to constructing simplices\nusing local regions of feature maps yielded by convolutional neural networks. Experiments\non Omniglot and miniImageNet verify the superiority of our simplex\nalgorithm on few-shot learning.","pdf":"/pdf/fddb579342c402e865d07408e33a91d47f614525.pdf","TL;DR":"A simplex-based geometric method is proposed to cope with few-shot learning problems.","paperhash":"anonymous|fewshot_learning_with_simplex","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-shot learning with simplex},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJfHoM-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper922/Authors"],"keywords":["one-shot learning","few-shot learning","deep learning","simplex"]}},{"tddate":null,"ddate":null,"tmdate":1512222819328,"tcdate":1511807620209,"number":1,"cdate":1511807620209,"id":"ryht5AYlM","invitation":"ICLR.cc/2018/Conference/-/Paper922/Official_Review","forum":"rJfHoM-C-","replyto":"rJfHoM-C-","signatures":["ICLR.cc/2018/Conference/Paper922/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Interesting approach but missing baselines and state of the art claims wrong","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a geometric based approach to solving the problem of one-shot and few-shot learning. The basic idea is to use the feature vectors of a particular class to construct a simplex. (I am assuming the dimensions of the vectors are selected so as to exactly construct a simplex? It is not clearly written in the paper). The volume of the simplex is then taken to be a measure of class scatter, and classification happens by assigning the test feature vector to the nearest simplex, where the distances are normalized by the volume of the simplex. \n\nWhile the approach makes sense, I am not convinced that this geometric method plays an important role in increasing the performance on one-shot/few-shot tasks. In particular, one could try simpler approaches like k-NN where the distances to the cluster centers are also normalized by the variance within the clusters. I would suspect that this method is not superior to this simpler baseline. \n\nThe other issue I have with this paper is misleading claims about being state of the art on Omniglot. In particular see Kaiser et al (ICLR 2017), where on 5-way-1-shot an accuracy of 98.4% is reached compared to 94.6% in this paper, and on 5-way-5-shot an accuracy of 99.6% is reached compared to 99.1% in this work. The paper also misses evaluations on various other data sets such as GNMT etc., on which Kaiser et al evaluated their approach.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Few-shot learning with simplex","abstract":"Deep learning has made remarkable achievement in many fields. However, learning\nparameters of a neural networks usually needs a large amount of labeled data.\nThe algorithms of deep learning, therefore, encounter difficulty when applied to\nsupervised learning where only little data are available. This problem is called\none-shot learning. To address it, we propose a novel algorithm for few-shot learning\nusing discrete geometry, in the sense that the samples in a class are modeled\nas a reduced simplex. The volume of the simplex is used for the measurement of\nclass scatter. During testing, combined with the test sample and the points in the\nclass, a new simplex is formed. Then the similarity between the test sample and\nthe class can be quantized with the ratio of volumes of the new simplex to the original\nclass simplex. Moreover, we present an approach to constructing simplices\nusing local regions of feature maps yielded by convolutional neural networks. Experiments\non Omniglot and miniImageNet verify the superiority of our simplex\nalgorithm on few-shot learning.","pdf":"/pdf/fddb579342c402e865d07408e33a91d47f614525.pdf","TL;DR":"A simplex-based geometric method is proposed to cope with few-shot learning problems.","paperhash":"anonymous|fewshot_learning_with_simplex","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-shot learning with simplex},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJfHoM-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper922/Authors"],"keywords":["one-shot learning","few-shot learning","deep learning","simplex"]}},{"tddate":null,"ddate":null,"tmdate":1510092385865,"tcdate":1509137213676,"number":922,"cdate":1510092362406,"id":"rJfHoM-C-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"rJfHoM-C-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Few-shot learning with simplex","abstract":"Deep learning has made remarkable achievement in many fields. However, learning\nparameters of a neural networks usually needs a large amount of labeled data.\nThe algorithms of deep learning, therefore, encounter difficulty when applied to\nsupervised learning where only little data are available. This problem is called\none-shot learning. To address it, we propose a novel algorithm for few-shot learning\nusing discrete geometry, in the sense that the samples in a class are modeled\nas a reduced simplex. The volume of the simplex is used for the measurement of\nclass scatter. During testing, combined with the test sample and the points in the\nclass, a new simplex is formed. Then the similarity between the test sample and\nthe class can be quantized with the ratio of volumes of the new simplex to the original\nclass simplex. Moreover, we present an approach to constructing simplices\nusing local regions of feature maps yielded by convolutional neural networks. Experiments\non Omniglot and miniImageNet verify the superiority of our simplex\nalgorithm on few-shot learning.","pdf":"/pdf/fddb579342c402e865d07408e33a91d47f614525.pdf","TL;DR":"A simplex-based geometric method is proposed to cope with few-shot learning problems.","paperhash":"anonymous|fewshot_learning_with_simplex","_bibtex":"@article{\n  anonymous2018few-shot,\n  title={Few-shot learning with simplex},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=rJfHoM-C-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper922/Authors"],"keywords":["one-shot learning","few-shot learning","deep learning","simplex"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}