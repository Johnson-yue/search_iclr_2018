{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222708477,"tcdate":1511793426395,"number":2,"cdate":1511793426395,"id":"Hy9zmitlG","invitation":"ICLR.cc/2018/Conference/-/Paper647/Official_Review","forum":"HkZy-bW0-","replyto":"HkZy-bW0-","signatures":["ICLR.cc/2018/Conference/Paper647/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Spike based learning for temporal redundant data","rating":"6: Marginally above acceptance threshold","review":"This paper presents a novel method for spike based learning that aims at reducing the needed computation during learning and testing when classifying temporal redundant data. This approach extends the method presented on Arxiv on Sigma delta quantized networks (Peter O’Connor and Max Welling. Sigma delta quantized networks. arXiv preprint arXiv:1611.02024, 2016b.). Overall, the paper is interesting and promising; only a few works tackle the problem of learning with spikes showing the potential advantages of such form of computing. The paper, however, is not flawless. The authors demonstrate the method on just two datasets, and effectively they show results of training only for Feed-Forward Neural Nets (the authors claim that “the entire spiking network end-to-end works” referring to their pre-trained VGG19, but this paper presents only training for the three top layers). Furthermore, even if suitable datasets are not available, the authors could have chosen to train different architectures. The first dataset is the well-known benchmark MNIST also presented in a customized Temporal-MNIST. Although it is a common base-line, some choices are not clear: why using a FFNN instead that a CNN which performs better on this dataset; how data is presented in terms of temporal series – this applies to the Temporal MNIST too; why performances for Temporal MNIST – which should be a more suitable dataset — are worse than for the standard MNIST; what is the meaning of the right column of Figure 5 since it’s just a linear combination of the GOps results. For the second dataset, some points are not clear too: why the labels and the pictures seem not to match (in appendix E); why there are more training iterations with spikes w.r.t. the not-spiking case. Overall, the paper is mathematically sound, except for the “future updates” meaning which probably deserves a clearer explanation. Moreover, I don’t see why the learning rule equations (14-15) are described in the appendix, while they are referred constantly in the main text. The final impression is that the problem of the dynamical range of the hidden layer activations is not fully resolved by the empirical solution described in Appendix D: perhaps this problem affects CCNs more than FFN. \nFinally, there are some minor issues here and there (the authors show quite some lack of attention for just 7 pages):\n-\tTwo times “get” in “we get get a decoding scheme” in the introduction;\n-\tTwo times “update” in “our true update update as” in Sec. 2.6;\n-\tPag3 correct the capital S in 2.3.1\n-\tPag4 Figure 1 increase font size (also for Figure2); close bracket after Equation 3; N (number of spikes) is not defined\n-\tPag5 “one-hot” or “onehot”; \n-\tin the inline equation the sum goes from n=1 to S, while in eq.(8) it goes from n=1 to N;\n-\tEq(10)(11)(12) and some lines have a typo (a \\cdot) just before some of the ws;\n-\tPag6 k_{beta} is not defined in the main text;\n-\tPag7 there are two “so that” in 3.1; capital letter “It used 32x10^12..”; beside, here, why do not report the difference in computation w.r.t. not-spiking nets?\n-\tPag7 in 3.2 “discussed in 1” is section 1?\n-\tPag14 Appendix E, why the labels don’t match the pictures;\n-\tPag14 Appendix F, explain better the architecture used for this experiment.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Temporally Efficient Deep Learning with Spikes","abstract":"The vast majority of natural sensory data is temporally redundant. Video frames or audio samples which are sampled at nearby points in time tend to have similar values.  Typically, deep learning algorithms take no advantage of this redundancy to reduce computation.  This can be an obscene waste of energy.  We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data.  We do this by having neurons communicate a combination of their state, and their temporal change in state.  Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a weight-update rule that is equivalent to a form of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain.  We demonstrate that on MNIST, on a temporal variant of MNIST, and on Youtube-BB, a dataset with videos in the wild, our algorithm performs about as well as a standard deep network trained with backpropagation, despite only communicating discrete values between layers.  ","pdf":"/pdf/503670c2f150e40fd8ba8bff48614c0d3a673169.pdf","TL;DR":"An algorithm for training neural networks efficiently on temporally redundant data.","paperhash":"anonymous|temporally_efficient_deep_learning_with_spikes","_bibtex":"@article{\n  anonymous2018temporally,\n  title={Temporally Efficient Deep Learning with Spikes},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkZy-bW0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper647/Authors"],"keywords":["online learning","spiking networks","deep learning","temporal"]}},{"tddate":null,"ddate":null,"tmdate":1512222708515,"tcdate":1511775020876,"number":1,"cdate":1511775020876,"id":"ryHEjLtgz","invitation":"ICLR.cc/2018/Conference/-/Paper647/Official_Review","forum":"HkZy-bW0-","replyto":"HkZy-bW0-","signatures":["ICLR.cc/2018/Conference/Paper647/AnonReviewer2"],"readers":["everyone"],"content":{"title":"The paper describes a neural coding scheme for spike based learning in deep neural networks. ","rating":"7: Good paper, accept","review":"The principal problem that the paper addresses is how to integrate error-backpropagation learning in a network of spiking neurons that use a form of sigma-delta coding. The main observation is that static sigma-delta coding as proposed in OConnor and Welling (2016b), is not correct when the weights change during training, as past activations are taken into account with the old rather than the new weights.\n\nThe solution proposed in this work is to have past activations decay exponentially, to reduce this problem. The coding scheme then mimics the proporitional-integral-derivative idea from control-theory. The result, spikes having an exponentially decaying effect on the postsynaptic neuron, is similar to that observed in biological spiking neurons. \n\nThe authors show how spike-based learning can be implemented with spiking neurons using such coding, and demonstrate the results on an MLP with one hidden layer applied to the temporal MNIST dataset, and to the Youtube-BB dataset. \n\nThis approach is original and significant, though the presented results are a bit on the thin side. As presented, the spiking networks are not exactly \"deep\": I am puzzled by the statement that in the youtube-bb dataset only the top 3 layers are \"spiking\". The network for the MNIST dataset is similarly only 3 layers deep (input, hidden, output). Is there a particular reason for this?  The presentation right now suggests that the scheme does in practise not work for deep networks...\n\nWith regard to the learning rule: while the rule is formulated in terms of spikes, it should be noted that for neuron with many inputs and outputs, this update will have to be computed very very often, even for networks with low average firing rates. \n\nThe paper is clear in most points, with some parts that could use further elucidation. In particular, in Sec 2.5 the feedback pass for weight updating is computed. It is unclear from the text that this is an ongoing process, in parallel to the feedforward pass. In Sec 2.6 e_t is termed the postsynaptic (pre-nonlinearity) activation, which is confusing as the computation is going the other way (post-to-pre). These two sections would benefit from a more careful layout of the process, what is going on in a forward pass, a backward pass, how does this interact. \n\nSection 2.7 tries to relate the spike-based learning rule to the biologically observed STDP phenomenon. While the formulation in terms of pre-post spike-times is interesting, the result is clearly different from STDP, and ignores the fact that e_t refers to the backpropagating error (which presumably would be conveyed by a feedback network): applying the plotted pre-post spike-time rule in the same setting as where STDP is observed will not achieve error-backpropagation. \n\nThe shorthand notation in the paper is hard to follow in the first place btw, perhaps this could be elaborated/remedied in an appendix, there is also some rather colloquial writing in places: \"obscene wast of energy\" (abstract), \"There's\" \"aren't\" (2.6, p5). \n\nThe correspondence of spiking neurons to sigma-delta modulation is incorrectly attributed to Zambrano and Bohte (2016), but is rather presented in Yoon (2017/2016, check original date of publication!). \n\n","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Temporally Efficient Deep Learning with Spikes","abstract":"The vast majority of natural sensory data is temporally redundant. Video frames or audio samples which are sampled at nearby points in time tend to have similar values.  Typically, deep learning algorithms take no advantage of this redundancy to reduce computation.  This can be an obscene waste of energy.  We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data.  We do this by having neurons communicate a combination of their state, and their temporal change in state.  Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a weight-update rule that is equivalent to a form of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain.  We demonstrate that on MNIST, on a temporal variant of MNIST, and on Youtube-BB, a dataset with videos in the wild, our algorithm performs about as well as a standard deep network trained with backpropagation, despite only communicating discrete values between layers.  ","pdf":"/pdf/503670c2f150e40fd8ba8bff48614c0d3a673169.pdf","TL;DR":"An algorithm for training neural networks efficiently on temporally redundant data.","paperhash":"anonymous|temporally_efficient_deep_learning_with_spikes","_bibtex":"@article{\n  anonymous2018temporally,\n  title={Temporally Efficient Deep Learning with Spikes},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkZy-bW0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper647/Authors"],"keywords":["online learning","spiking networks","deep learning","temporal"]}},{"tddate":null,"ddate":null,"tmdate":1509739182546,"tcdate":1509130456640,"number":647,"cdate":1509739179884,"id":"HkZy-bW0-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"HkZy-bW0-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Temporally Efficient Deep Learning with Spikes","abstract":"The vast majority of natural sensory data is temporally redundant. Video frames or audio samples which are sampled at nearby points in time tend to have similar values.  Typically, deep learning algorithms take no advantage of this redundancy to reduce computation.  This can be an obscene waste of energy.  We present a variant on backpropagation for neural networks in which computation scales with the rate of change of the data - not the rate at which we process the data.  We do this by having neurons communicate a combination of their state, and their temporal change in state.  Intriguingly, this simple communication rule give rise to units that resemble biologically-inspired leaky integrate-and-fire neurons, and to a weight-update rule that is equivalent to a form of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule observed in the brain.  We demonstrate that on MNIST, on a temporal variant of MNIST, and on Youtube-BB, a dataset with videos in the wild, our algorithm performs about as well as a standard deep network trained with backpropagation, despite only communicating discrete values between layers.  ","pdf":"/pdf/503670c2f150e40fd8ba8bff48614c0d3a673169.pdf","TL;DR":"An algorithm for training neural networks efficiently on temporally redundant data.","paperhash":"anonymous|temporally_efficient_deep_learning_with_spikes","_bibtex":"@article{\n  anonymous2018temporally,\n  title={Temporally Efficient Deep Learning with Spikes},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=HkZy-bW0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper647/Authors"],"keywords":["online learning","spiking networks","deep learning","temporal"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}