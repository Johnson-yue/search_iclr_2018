{"notes":[{"tddate":null,"ddate":null,"tmdate":1511939412869,"tcdate":1511938919598,"number":1,"cdate":1511938919598,"id":"S1eOo0sez","invitation":"ICLR.cc/2018/Conference/-/Paper315/Official_Comment","forum":"Hk9Xc_lR-","replyto":"r16zP8jlG","signatures":["ICLR.cc/2018/Conference/Paper315/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper315/Authors"],"content":{"title":"the uniqueness of our discrimination results","comment":"Thank you for your interest, questions and comments! \n\nFirst, as far as we know, no previous work gives a sufficient and necessary conditions of the discriminator set under which the neural distance is discriminative. In previous work, the discriminative power of GANs is typically justified by assuming that the discriminator set has enough capacity, such as all functions taking values in [0,1] in vanilla GAN or all Lipchitz functions with Lipchitz constant 1 in WGAN. However, we use neural networks with bounded parameters in practice. The main goal of our results is to close this gap between previous theoretical results and practices.  We'd like to mention the following points on the discriminative power. \n(1). [1] and [2] also noticed that GANs with restricted discriminators may not be discriminative, but this problem was addressed in neither [1] nor [2].\n(2). Previous work also uses the universal approximation property of neural networks to justify the discriminative power empirically. Our results show that the neural distance is discriminative under much weaker condition, that is, span of the discriminator set can approximate any continuous functions. This justifies why neural network with bounded parameters works in practice.  \n(3). Our discriminative results also apply to neural divergence (Theorem 4.1), which requires that span of the discriminators without the nonlinear activation in the last layer is dense in bounded continuous functions. This coincides with the implementation difference between vanilla GAN and WGAN, where WGAN simply uses discriminators in the vanilla GAN without the nonlinear activation in the last layer. \n\nYes, the generalization part shares similarities with the supervised learning. However, the most important difference is that: in supervise learning, the complexity of the hypothesis set (G) bounds the generalization error; in GANs, the complexity of the discriminator set (F) bounds the generalization error, which can be independent of the hypothesis set. \n\nWe agree that we do not consider the impact of training on GANs, which is very important in practice. We noticed several recent papers are working in this direction, e.g., [3, 4]. We are currently working on stabilizing the training of GANs through our approach.\n\n[1] Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium in generative adversarial nets (gans). arXiv preprint arXiv:1703.00573, 2017.\n[2] Shuang Liu, Olivier Bousquet, and Kamalika Chaudhuri. Approximation and convergence properties\nof generative adversarial learning. arXiv preprint arXiv:1705.08991, 2017.\n[3] Jerry Li, Aleksander Madry, John Peebles, and Ludwig Schmidt. Towards understanding the dynamics of generative adversarial networks. arXiv preprint arXiv:1706.09884, 2017b.\n[4] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, GÂ¨unter Klambauer, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a nash equilibrium. arXiv preprint arXiv:1706.08500, 2017.\n\n"},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the Discrimination-Generalization Tradeoff in GANs","abstract":"Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.","pdf":"/pdf/0983a99d4a01e417f0be3032ca515e1a226746a5.pdf","TL;DR":"This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.","paperhash":"anonymous|on_the_discriminationgeneralization_tradeoff_in_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On the Discrimination-Generalization Tradeoff in GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk9Xc_lR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper315/Authors"],"keywords":["generative adversarial network","discrimination","generalization"]}},{"tddate":null,"ddate":null,"tmdate":1511905045342,"tcdate":1511905045342,"number":1,"cdate":1511905045342,"id":"r16zP8jlG","invitation":"ICLR.cc/2018/Conference/-/Paper315/Public_Comment","forum":"Hk9Xc_lR-","replyto":"Hk9Xc_lR-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Some questions","comment":"I'm going over papers on theoretical results on GANs and got into this one.\n\nIn the first part of the paper, the author asks whether the neural distance is \"discriminative\" or not, that is, whether being equal in neural distance implies that the two distributions are actually identical. It is shown that the answer is affirmative for a large class of discriminators, including neural networks. Based on this property, it is shown that the learned distribution weakly converge to the target distribution. I found that the proof for this \"discriminative\" result seems like a straightforward exercise in real analysis. I wonder whether this result has been discovered before. \n\nThe generalization part seems reasonable, and shares several similarities with supervised learning. A drawback of this paper is that they do not consider the impact of training on GANs, which matters a lot in practice.  \n"},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the Discrimination-Generalization Tradeoff in GANs","abstract":"Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.","pdf":"/pdf/0983a99d4a01e417f0be3032ca515e1a226746a5.pdf","TL;DR":"This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.","paperhash":"anonymous|on_the_discriminationgeneralization_tradeoff_in_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On the Discrimination-Generalization Tradeoff in GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk9Xc_lR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper315/Authors"],"keywords":["generative adversarial network","discrimination","generalization"]}},{"tddate":null,"ddate":null,"tmdate":1512222619214,"tcdate":1511808038754,"number":2,"cdate":1511808038754,"id":"ByyV3Atez","invitation":"ICLR.cc/2018/Conference/-/Paper315/Official_Review","forum":"Hk9Xc_lR-","replyto":"Hk9Xc_lR-","signatures":["ICLR.cc/2018/Conference/Paper315/AnonReviewer3"],"readers":["everyone"],"content":{"title":"This paper provides a mathematical analysis of the role of the size of the adversary/discriminator set in GANs.  It argues that on the one hand, large discriminator sets are useful as they help isolate the target distribution; on the other hand, small discriminator sets help with small sample effects.  Unfortunately, I seem to have found some flaws.","rating":"3: Clear rejection","review":"In more detail, the analysis of the paper is as follows.  Firstly, it primarily focuses on GAN objective functions which are \"integral probability metrics (IPMs)\"; one way to define these is by way of similarity to the W-GAN, namely IPMs replace the 1-Lipschitz functions in W-GAN with a generic set of functions F.  The paper overall avoids computational issues and treats the suprema as though exactly solved by sgd or related heuristic (the results of the paper simply state supremum, but some of the prose seems to touch on this issue).\n\nThe key arguments of the paper are as follows.\n\n1. It argues that the discriminator set should be not simply large, it should be dense in all bounded continuous functions; as a consequence of this, the IPM is 0 iff the distributions are equal (in the weak sense).  Due to this assertion, it says that it suffices to use two layer neural networks as the discriminator set (as a consequence of the \"universal approximation\" results well-known in the neural network literature).\n\n2. It argues the discriminator set should be small in order to mitigate small-sample effects.  (Together, points 1 and 2 mimic a standard bias-variance tradeoff in statistics.)  For this step, the paper relies upon standard Rademacher results plus a little bit of algebraic glue.  Curiously, the paper chooses to argue (and forms as a key tenet, indeed in the abstract) that the size of the generator set is irrelevant for this, only the size of the discriminator matters.\n\nUnfortunately, I find significant problems with the paper, in order from most severe to least severe.\n\nA.  The calculation ruling out the impact of the generator in generalization calculations in 2 above is flawed.  Before pointing out the concrete bug, I note that this assertion runs completely counter to intuition, and thus should be made with more explanation (as opposed to the fortunate magic it is presented as).  Moreover, I'll say that if the authors choose to \"fix\" this bug by adding a generator generalization term, the bound is still a remedial application of Rademacher complexity, so I'm not exactly blown away.  Anyway, the bug is as follows.  The equation which drops the role of the generator in the generalization calculation is the equation (10).  The proof of this inequality is at the start of appendix E.  Looking at the derivation in that appendix, everything is correct up to the second-to-last display, the one with a supremum over nu in G.  First of all, this right hand side should set off alarm bells; e.g., if we make the generator class big, we can make this right hand side essentially as big as the IPM allows even when mu = mu_m.  Now the bug itself appears when going to the next display: if the definition of d_F is expanded, one obtains two suprema, each own over _their own_ optimization variable (in this case the variables are discriminator functions).  When going to the next equation, the authors accidentally made the two suprema have the same variable and invoke a fortuitous but incorrect cancellation.  As stated a few sentences back, one can construct trivial counterexamples to these inequalities, for instance by making mu and mu_m arbitrarily close (even exactly equal if you wish) and then making nu arbitrarily far away and the discriminator set large enough to identify this.\n\nB. The assertions in 1, regarding sizes of discriminator sets needed to achieve the goal of the IPM being 0 iff the distributions are equal (in the weak sense), are nothing more than immediate corollaries of approximation results well-known for decades in the neural network literature.  It is thus hard to consider this a serious contribution.\n\nC. I will add on a non-technical note that the paper's assertion on what a good IPM \"should be\" is arguably misled.  There is not only a meaning to specific function classes (as with Lip_1 in Wasserstein_1) beyond simply \"many functions\", but moreover there is an interplay between the size of the generator set and the size of the discriminator set.  If the generator set is simple, then the discriminator set can also get away with being simple (this is dicussed in the Arora et al 2017 ICML paper, amongst other places).  Perhaps I am the one that is misled, but even so the paper does not appear to give a good justification of its standpoint.\n\nI will conclude with typos and minor remarks.  I found the paper to contain a vast number of small errors, to the point that I doubted a single proofread.\n\nAbstract, first line: \"a minimizing\"?  general grammar issue in this sentence; this sort of issue throughout the paper.\n\nAbstract, \"this is a mild condition\".  Optimizing over a function class which is dense in all bounded measurable functions is not a mild assumption.  In the particular case under discussion, the size of the network can not be bounded (even though it has just two layers, or as the authors say is the span of single neurons).\n\nAbstract, \"...regardless of the size of the generator or hypothesis set\".  This really needs explanation in the abstract, it is such a bold claim.  For instance, I wrote \"no\" in the margin while reading the abstract the first time.\n\nIntro, first line: its -> their.\n\nIntro, #3 \"energy-based GANs\": 'm' clashes with sample size.\n\nIntro, bottom of page 1, the sentence with \"irrelenvant\": I can't make any sense of this sentence.\n\nIntro, bottom of page 1, \"is a much smaller discriminator set\": no, the Lip_1 functions are in general incomparable to arbitrary sets of neural nets.\n\nFrom here on I'll comment less on typos.\n\nMiddle of page 2, point (i): this is the only place it is argued/asserted that the discriminator set should contain essentially everything?  I think this needs a much more serious justification.\n\nSection 1.1: Lebegure -> Lebesgue.\n\nPage 4, vicinity of equation 5: there should really be a mention that none of these universal approximation results give a meaningful bound on the size of the network (the bound given by Barron's work, while nice, is still massive).\n\nStart of section 3.  To be clear, while one can argue that the Lipschitz-1 constraint has a regularization effect, the reason it was originally imposed is to match the Kantorovich duality for Wasserstein_1.  Moreover I'll say this is another instance of the paper treating the discriminator set as irrelevant other than how close it is to being dense in all bounded measurable functions.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the Discrimination-Generalization Tradeoff in GANs","abstract":"Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.","pdf":"/pdf/0983a99d4a01e417f0be3032ca515e1a226746a5.pdf","TL;DR":"This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.","paperhash":"anonymous|on_the_discriminationgeneralization_tradeoff_in_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On the Discrimination-Generalization Tradeoff in GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk9Xc_lR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper315/Authors"],"keywords":["generative adversarial network","discrimination","generalization"]}},{"tddate":null,"ddate":null,"tmdate":1512222619257,"tcdate":1511474003042,"number":1,"cdate":1511474003042,"id":"HJjLXT4gM","invitation":"ICLR.cc/2018/Conference/-/Paper315/Official_Review","forum":"Hk9Xc_lR-","replyto":"Hk9Xc_lR-","signatures":["ICLR.cc/2018/Conference/Paper315/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Purely theoretical paper on GANs with several novel but not groundbreaking contributions","rating":"6: Marginally above acceptance threshold","review":"== Paper Summary ==\nThe paper addresses the problem of balancing capacities of generator and discriminator classes in generative adversarial nets (GANs) from purely theoretical (function analytical and statistical learning) perspective. In my point of view, the main *novel* contributions are: \n(a) Conditions on function classes guaranteeing that the induced IPMs are metrics and not pseudo-metrics (Theorem 2.2). Especially I liked an argument explaining why ReLu activations could work better in discriminator that tanh.\n(b) Proving that convergence in the neural distance implies a weak convergence (Theorem 2.5)\n(c) Listing particular cases when the neural distance upper bounds the so-called bounded Lipschitz distance (also know as the Fortet-Mourier distance) and the symmetrized KL-divergence (Corollary 2.8 and Proposition 2.9).\n\nThe paper is well written (although with *many* typos), the topic is clearly motivated and certainly interesting. The related literature is mainly covered well, apart from several important points listed below.\n\n== Major comments ==\nIn my opinion, the authors are slightly overselling the results. Next I shortly explain why:\n\n(1) First, point (a) above is indeed novel, but not groundbreaking. A very similar result previously appeared in [1, Theorem 5]. The authors may argue that the referenced result deals only with MMDs, that is IPMs specified to the function classes belonging to the Reproducing Kernel Hilbert Spaces. However, the technique used to prove the \"sufficient\" part of the statement is literally *identical*. \n\n(2) As discussed in the paragraph right after Theorem 2.5, Theorem 10 of [2] presents the same result which is on one hand stronger than Theorem 2.5 of the current paper because it allows for more general divergences than the neural distance and on the other hand weaker because in [2] the authors assumes a compact input space. Overall, Theorem 2.5 of course makes a novel contribution, because the compactness assumption is not required, however conceptually it is not that novel.\n\n(3) In Section 3 the authors discuss the generalization properties of the neural network distance. One of the main messages (emphasized several times throughout the paper) is that surprisingly the capacity of the generator class does not enter the generalization error bound. However, this is not surprising at all as it is a consequence of the way in which the authors define the generalization. In short, the capacity of discriminators (D) naturally enters the picture, because the generalization error accounts for the mismatch between the true data distribution mu (used for testing) and its empirical version hat{mu} (used for training). However, the authors assume the model distribution (nu) is the same both during testing and training. In practice this is not true and during testing GANs use the empirical version of nu. If the authors were to account for this mismatch, capacity of G would certainly pop up as well.\n\n(4) The error bounds of Section 3 are based on a very standard machinery (empirical processes, Rademacher complexity) and to the best of my knowledge do not lead to any new interesting conclusions in terms of GANs.\n\n(5) Finally, I would suggest the authors to remove Section 4. I suggest this mainly because the authors admit in Remark 4.1 that the main result of this section (Theorem 4.1) is a corollary of a stronger result appearing in [2]. Also, the main part of the paper has 13 pages, while a recommended amount is 8. \n\n== Minor comments ==\n\n(1) There are *MANY* typos in the paper. Only few of them are listed below.\n(2) First paragraph of page 18, proof of Theorem 2.2. This part is of course well known and the authors may just cite Lemma 9.3.2. of Dudley's \"Real analysis and probability\" for instance.\n(3) Theorem 2.5: \"Let ...\"\n(4) Page 7, \"...we may BE interested...\"\n(5) Corollary 3.2. I doubt that in practice anyone uses discriminator with one hidden unit. The authors may want to consider using the bound on the Rademacher complexity of DNNs recently derived in [3]. \n(6) Page 8, \"..is neural networK\"\n(7) Page 9: \"...interested IN evaluating...\"\n(8) Page 10. All most ---> almost.\n\n[1] Gretton et al., A Kernel Two-Sample Test, JMLR 2012.\n[2] Liu et al, Approximation and Convergence Properties of Generative Adversarial Learning, 2017\n[3] Bartlett et al, Spectrally-normalized margin bounds for neural networks, 2017","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"On the Discrimination-Generalization Tradeoff in GANs","abstract":"Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.","pdf":"/pdf/0983a99d4a01e417f0be3032ca515e1a226746a5.pdf","TL;DR":"This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.","paperhash":"anonymous|on_the_discriminationgeneralization_tradeoff_in_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On the Discrimination-Generalization Tradeoff in GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk9Xc_lR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper315/Authors"],"keywords":["generative adversarial network","discrimination","generalization"]}},{"tddate":null,"ddate":null,"tmdate":1512199826422,"tcdate":1509095969600,"number":315,"cdate":1509739365855,"id":"Hk9Xc_lR-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"Hk9Xc_lR-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"On the Discrimination-Generalization Tradeoff in GANs","abstract":"Generative adversarial training can be generally understood as minimizing certain moment matching loss defined by a set of discriminator functions, typically  neural networks. The discriminator set should be large enough to be able to uniquely identify the true distribution (discriminative), and also be small enough to go beyond memorizing samples (generalizable). In this paper, we show that a discriminator set is guaranteed to be discriminative whenever its linear span is dense in the set of bounded continuous functions. This is a very mild condition satisfied even by neural networks with a single neuron. Further, we develop generalization bounds between the learned distribution and true distribution under different evaluation metrics. When evaluated with neural distance, our bounds show that generalization is guaranteed as long as the discriminator set is small enough, regardless of the size of the generator or hypothesis set. When evaluated with KL divergence, our bound provides an explanation on the counter-intuitive behaviors of testing likelihood in GAN training. Our analysis sheds lights on understanding the practical performance of GANs.","pdf":"/pdf/0983a99d4a01e417f0be3032ca515e1a226746a5.pdf","TL;DR":"This paper studies the discrimination and generalization properties of GANs when the discriminator set is a restricted function class like neural networks.","paperhash":"anonymous|on_the_discriminationgeneralization_tradeoff_in_gans","_bibtex":"@article{\n  anonymous2018on,\n  title={On the Discrimination-Generalization Tradeoff in GANs},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=Hk9Xc_lR-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper315/Authors"],"keywords":["generative adversarial network","discrimination","generalization"]},"nonreaders":[],"replyCount":4,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}