{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222622208,"tcdate":1512106333012,"number":3,"cdate":1512106333012,"id":"r1BvYvAeG","invitation":"ICLR.cc/2018/Conference/-/Paper338/Official_Review","forum":"r1YUtYx0-","replyto":"r1YUtYx0-","signatures":["ICLR.cc/2018/Conference/Paper338/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Clear accept","rating":"8: Top 50% of accepted papers, clear accept","review":"The paper studied the generalization ability of learning algorithms from the robustness viewpoint in a deep learning context. To achieve this goal, the authors extended the notion of the (K, \\epsilon)- robustness proposed in Xu and Mannor, 2012 and introduced the ensemble robustness. \n\nPros: \n\n1, The problem studied in this paper is interesting. Both robustness and generalization are important properties of learning algorithms. It is good to see that the authors made some efforts towards this direction.\n2, The paper is well shaped and is easy to follow. The analysis conducted in this paper is sound. Numerical experiments are also convincing. \n3, The extended notion \"ensemble robustness\" is shown to be very useful in studying the generalization properties of several deep learning algorithms. \n\nCons:    \n\n1,  The terminology \"ensemble\" seems odd to me, and seems not to be informative enough.\n2,  Given that the stability is considered as a weak notion of robustness, and the fact that the stability of a learning algorithm and its relations to the generalization property have been well studied, in my view, it is quite necessary to mention the relation of the present study with stability arguments. \n3, After Definition 3, the author stated that ensemble robustness is a weak notion of robustness proposed in Xu and Manner, 2012. It is better to present an example here immediately to illustrate. ","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512034340649,"tcdate":1512034340649,"number":1,"cdate":1512034340649,"id":"H1T7gLalM","invitation":"ICLR.cc/2018/Conference/-/Paper338/Official_Comment","forum":"r1YUtYx0-","replyto":"SJx-TCsxz","signatures":["ICLR.cc/2018/Conference/Paper338/Authors"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference/Paper338/Authors"],"content":{"title":"Reply to: Please discuss relationship to randomized stability-based bounds","comment":"Thank you for your comment. Stability and robustness are two examples of desired properties of a learning algorithm that can also guarantee generalization under some conditions.\n\nA stable algorithm produces an output hypothesis that is stable to small changes in the data set, i.e., if a training example is replaced with another example from the same distribution, the training error will not change much. Elisseeff et al. (JMLR, 2005), indeed showed that algorithm that fulfills this requirement generalize well. \n\nRobustness, on the other hand, is a different property of learning algorithms. A Robust algorithm produces a hypothesis that is robust to bounded perturbations of the entire data set, as we explain in more detail in our paper. Robustness and Stability are different properties, to see that observe that robustness is a global property while stability is local, and that robustness concerns properties of a single hypothesis, while stability concerns two (one for the original data set and one for the modified one).  \n\nWe emphasize that a learning algorithm may be both stable and robust, e.g., SVM, \"Robustness and Regularization of Support Vector Machines,\" Huan Xu, Constantine Caramanis, Shie Mannor 2009). However, there also exist algorithms that are robust but not stable, e.g., Lasso Regression, \"Robust Regression and Lasso,\" Huan Xu, Constantine Caramanis, Shie Mannor 2008). \n\nWe will further expand the discussion on these issues in a future revision of the paper. "},"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]}},{"tddate":null,"ddate":null,"tmdate":1511939319999,"tcdate":1511939319999,"number":1,"cdate":1511939319999,"id":"SJx-TCsxz","invitation":"ICLR.cc/2018/Conference/-/Paper338/Public_Comment","forum":"r1YUtYx0-","replyto":"r1YUtYx0-","signatures":["(anonymous)"],"readers":["everyone"],"writers":["(anonymous)"],"content":{"title":"Please discuss relationship to randomized stability-based bounds","comment":"Ensemble robustness is conceptually very similar to randomized algorithm stability. The latter concept has been thoroughly analyzed by Elisseeff et al. (JMLR, 2005), who derived a number of generalization bounds for randomized algorithms based on different notions of stability (uniform, hypothesis, pointwise hypothesis). Given the similarity between robustness and stability, it seems to me that the submitted paper should discuss the connections to Elisseeff et al.'s work (which is not cited) and compare the bounds in both."},"nonreaders":[],"replyCount":1,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222622243,"tcdate":1511734221557,"number":2,"cdate":1511734221557,"id":"SkLRjndlG","invitation":"ICLR.cc/2018/Conference/-/Paper338/Official_Review","forum":"r1YUtYx0-","replyto":"r1YUtYx0-","signatures":["ICLR.cc/2018/Conference/Paper338/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Paper proposes to study generalization ability via new notion of stability. Improtant problem and a beginning of interesting idea but paper is not ready for a publication since results are not sufficiently strong.","rating":"4: Ok but not good enough - rejection","review":"This paper proposes a study of the generalization ability of deep learning algorithms using an extension of notion of stability called ensemble robustness. It requires that algorithm is stable on average with respect to randomness of the algorithm. The paper then gives bounds on the generalization error of a randomized algorithm in terms of stability parameter and provides empirical study attempting to connect theory with practice.\n\nWhile I believe that paper is trying to tackle an important problem and maybe on the right path to find notions that are responsible for generalization in NNs, I believe that contributions in this work are not sufficiently strong for acceptance.\n\nFirstly, it should be noted that the notion of generalization considered in this work is significantly weaker than standard notions of generalization in learning theory since (a) results are not high probability results (b) the bounds are with respect to randomness of both sample and sample (which gives extra slack).\n\nStabiltiy parameter epsilon_bar(n) is not studied anywhere. How does it scale with sample size n for standard algorithms? How do we know it does not make bounds vacuous?\n\nIt is only allude it to that NN learning algorithms may poses ensemble robustness. It is not clear and not shown anywhere that they do. Indeed, simulations demonstrate that this could be the case but this still presents a significant gap between theory and practice (just like any other analysis that paper criticizes in intro).\n\nMinor:\n\n1. After Theorem 2: \"... can substantially improve ...\" not sure if improvement is substantial since it is still not a high probability bound.\n\n2. In intro, \"Thus statistical learning theory ... struggle to explain generalization ...\". Note that the work of Zhang et al does not establish that learning theory struggle to explain generalization ability of NNs since results in that paper do not study margin bounds. To this end refer to some recent work Bartlett et al, Cortes et al., Neyshabur et al.\n\n3. Typos in def. 3. missing z in \"If s \\in C_i...\". No bar on epsilon.","confidence":"5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]}},{"tddate":null,"ddate":null,"tmdate":1512222622278,"tcdate":1511561108468,"number":1,"cdate":1511561108468,"id":"rJhcwfLgf","invitation":"ICLR.cc/2018/Conference/-/Paper338/Official_Review","forum":"r1YUtYx0-","replyto":"r1YUtYx0-","signatures":["ICLR.cc/2018/Conference/Paper338/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Paper that provides a novel theoretical framework for stochastic learning of Deep Networks, the proposed framework is an extension of an existing framework and the contribution is a bit limited in its present form.","rating":"4: Ok but not good enough - rejection","review":"Summary:\nThis paper presents an adaptation of the algorithmic robustness of Xu&Mannor'12 to a notion robustness of ensemble of hypothesis allowing the authors to study generalization ability of stochastic learning algorithms for Deep Learning Networks. \nGeneralization can be established as long as the sensitiveness of the learning algorithm to adversarial perturbations is bounded.\nThe paper presents learning bounds and an experimental showing correlation between empirical ensemble robustness and generalization error.\n\nQuality:\nGlobally correct\n\nClarity:\nPaper clear\n\nOriginality:\nLimited with respect to the original definition of algorithmic robustness\n\nSignificance:\nThe paper provides a new theoretical analysis for stochastic learning of Deep Networks but the contribution is limited in its present form.\n\n\nPros:\n-New theoretical study for DL algorithms \n-Focus on adversarial learning\nCons\n-I find the contribution a bit limited\n-Some aspects have to be precised/more argumented\n-Experimental study could have been more complete\n\n\nComments:\n---------\n\n\n*About the proposed framework.\nThe idea of taking a max over instances of partition C_i (Def 3) already appeared in the proof of results of Xu&Mannor, and the originality of the contribution is essentially to add an expectation over the result of the algorithm.\n\n\nIn Xu&Mannor paper, there is a notion of weak robustness that is proved to be necessary and sufficient to generalize. The contribution of the authors would be stronger if they can discuss an equivalent notion in their context.\n\nThe partition considered by the framework is never discussed nor taken into account, while this is an important aspect of the analysis. In particular, there is a tradeoff between \\epsilon(s) and K:  using a very fine tiling it is always possible to have a very small \\epsilon(s) at the price of a very large K (if you think of a covering number, K can be exponential in the size of the tiling and hard to calculate). \nIn the context of adversarial examples, this is actually important because it can be very likely that the adversarial example can belong to a partition set different from the set the original example belong to. \nIn this context, I am not sure to understand the validity of the framework because we can then compare 2 instances of different set which is outside of the framework. \nSo I wonder if the way the adervarial examples are generates should be taken into account for the definition of the partition.\nAdditionnally, the result is given in the contect of IID data, and with a multinomial distribution according to the partition set - adversarial generation can violate this IID assumption.\n\nIn the experimental setup, the partition set is not explained and we have no guarantee to compare instances of the same set. Nothing is said about $r$ and its impact on the results. This is a clear weak aspect of the experimental analysis\nIn the experimental setup, as far as I understand the setup, I find the term \"generalization error\" a bit abusive since it is actually the error on the test set. \nUsing cross validation or considering multiple training/test sets would be more appropriate.\n\n\nIn the proof of Lemma 2, I am not sure to understand where the term 1/n comes from in the term 2M^2/2 (before \"We then bound the term H as follows\")\n\n","confidence":"3: The reviewer is fairly confident that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]}},{"tddate":null,"ddate":null,"tmdate":1509739356613,"tcdate":1509099857249,"number":338,"cdate":1509739353958,"id":"r1YUtYx0-","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1YUtYx0-","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms","abstract":"The question why deep learning algorithms generalize so well has attracted increasing\nresearch interest. However, most of the well-established approaches,\nsuch as hypothesis capacity, stability or sparseness, have not provided complete\nexplanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus\non the robustness approach (Xu & Mannor, 2012), i.e., if the error of a hypothesis\nwill not change much due to perturbations of its training examples, then it\nwill also generalize well. As most deep learning algorithms are stochastic (e.g.,\nStochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness\narguments of Xu & Mannor, and introduce a new approach – ensemble\nrobustness – that concerns the robustness of a population of hypotheses. Through\nthe lens of ensemble robustness, we reveal that a stochastic learning algorithm can\ngeneralize well as long as its sensitiveness to adversarial perturbations is bounded\nin average over training examples. Moreover, an algorithm may be sensitive to\nsome adversarial examples (Goodfellow et al., 2015) but still generalize well. To\nsupport our claims, we provide extensive simulations for different deep learning\nalgorithms and different network architectures exhibiting a strong correlation between\nensemble robustness and the ability to generalize.","pdf":"/pdf/114725b63fc7c4c98b0d51d1541592387ac2d341.pdf","TL;DR":"Explaining the generalization of stochastic deep learning algorithms, theoretically and empirically, via ensemble robustness","paperhash":"anonymous|ensemble_robustness_and_generalization_of_stochastic_deep_learning_algorithms","_bibtex":"@article{\n  anonymous2018ensemble,\n  title={Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1YUtYx0-}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper338/Authors"],"keywords":["Robustness","Generalization","Deep Learning","Adversarial Learning"]},"nonreaders":[],"replyCount":5,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}