{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222737468,"tcdate":1511811099075,"number":3,"cdate":1511811099075,"id":"r1XXuJcgM","invitation":"ICLR.cc/2018/Conference/-/Paper733/Official_Review","forum":"H113pWZRb","replyto":"H113pWZRb","signatures":["ICLR.cc/2018/Conference/Paper733/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Interesting improvement idea, clarity could be improved","rating":"5: Marginally below acceptance threshold","review":"The paper introduces Topology Adaptive GCN (TAGCN) to generalize convolutional\nnetworks to graph-structured data.\nI find the paper interesting but not very clearly written in some sections,\nfor instance I would better explain what is the main contribution and devote\nsome more text to the motivation. Why is the proposed approach better than the\npreviously published ones, and when is that there is an advantage in using it?\n\nThe main contribution seems to be the use of the \"graph shift\" operator from\nSandryhaila and Moura (2013), which closely resembles the one from\nShuman et al. (2013). It is actually not very well explained what is the main\ndifference.\n\nEquation (2) shows that the learnable filters g are operating on the k-th power\nof the normalized adjacency matrix A, so when K=1 this equals classical GCN\nfrom T. Kipf et al.\nBy using K > 1 the method is able to leverage information at a farther distance\nfrom the reference node.\n\nSection 2.2 requires some polishing as I found hard to follow the main story\nthe authors wanted to tell. The definition of the weight of a path seems\ndisconnected from the main text, ins't A^k kind of a a diffusion operator or\nrandom walk?\nThis makes me wonder what would be the performance of GCN when the k-th power\nof the adjacency is used.\n\nI liked Section 3, however while it is true that all methods differ in the way they\ndo the filtering, they also differ in the way the input graph is represented\n(use of the adjacency or not).\n\nExperiments are performed on the usual reference benchmarks for the task and show\nsensible improvements with respect to the state-of-the-art. TAGCN with K=2 has\ntwice the number of parameters of GCN, which makes the comparison not entirely\nfair. Did the author experiment with a comparable architecture?\nAlso, how about using A^2 in GCN or making two GCN and concatenate them in\nfeature space to make the representational power comparable?\n\nIt is also known that these benchmarks, while being widely used, are small and\nresult in high variance results. The authors should report statistics over\nmultiple runs.\nGiven the systematic parameter search, with reference to the actual validation\n(or test?) set I am afraid there could be some overfitting. It is quite easy\nto probe the test set to get best performance on these benchmarks.\n\nAs a minor remark, please make figures readable also in BW.\n\nOverall I found the paper interesting but also not very clear at pointing out\nthe major contribution and the motivation behind it. At risk of being too reductionist:\nit looks as learning a set of filters on different coordinate systems given\nby the various powers of A. GCN looks at the nearest neighbors and the paper\nshows that using also the 2-ring improves performance.\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topology Adaptive Graph Convolutional  Networks","abstract":"Convolution acts as a local feature extractor in convolutional neural networks (CNNs). However, the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks, citation networks, or knowledge graphs. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution, replacing the square filter for the grid-structured data in traditional CNNs. The outputs are the weighted sum of these filters’ outputs, extraction of both vertex features and strength of correlation between vertices. It can be used with both directed and undirected graphs. The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution in traditional signal processing. We apply TAGCN to semi-supervised learning problems for graph vertex classification; experiments on a number of data sets demonstrate that our method outperforms the existing graph convolutional neural networks and achieves state-of-the-art performance for each data set tested.","pdf":"/pdf/70696d17ea67de6acfd25501ee9188623fc8d3b2.pdf","TL;DR":"A systematic way to design a fixed-size learnable filters to extract feature from nodes and strength of correlation for both directed and undirected  graph.","paperhash":"anonymous|topology_adaptive_graph_convolutional_networks","_bibtex":"@article{\n  anonymous2018topology,\n  title={Topology Adaptive Graph Convolutional  Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H113pWZRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper733/Authors"],"keywords":["graph convolutional neural networks","graph-structured data","semi-classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222737506,"tcdate":1511795476632,"number":2,"cdate":1511795476632,"id":"ry6GiiKlz","invitation":"ICLR.cc/2018/Conference/-/Paper733/Official_Review","forum":"H113pWZRb","replyto":"H113pWZRb","signatures":["ICLR.cc/2018/Conference/Paper733/AnonReviewer3"],"readers":["everyone"],"content":{"title":"Reasonable technical contribution, solid evaluation, well written, clear relation to previous work","rating":"6: Marginally above acceptance threshold","review":"The authors propose a new CNN approach to graph classification that generalizes previous work. Instead of considering the direct neighborhood of a vertex in the convolution step, a filter based on outgoing walks of increasing length is proposed. This incorporates information from more distant vertices in one propagation step.\n\nThe proposed idea is not exceptional original, but the paper has several strong points:\n\n* The relation to previous work is made explicit and it is show that several previous approaches are generalized by the proposed one.\n* The paper is clearly written and well illustrated by figures and examples. The paper is easy to follow although it is on an adequate technical level.\n* The relation between the vertex and spectrum domain is well elaborated and nice (although neither important for understanding nor implementing the approach).\n* The experimental evaluation appears to be sound. A moderate improvement compared to other approaches is observed for all data sets.\n\nIn summary, I think the paper can be accepted for ICLR.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topology Adaptive Graph Convolutional  Networks","abstract":"Convolution acts as a local feature extractor in convolutional neural networks (CNNs). However, the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks, citation networks, or knowledge graphs. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution, replacing the square filter for the grid-structured data in traditional CNNs. The outputs are the weighted sum of these filters’ outputs, extraction of both vertex features and strength of correlation between vertices. It can be used with both directed and undirected graphs. The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution in traditional signal processing. We apply TAGCN to semi-supervised learning problems for graph vertex classification; experiments on a number of data sets demonstrate that our method outperforms the existing graph convolutional neural networks and achieves state-of-the-art performance for each data set tested.","pdf":"/pdf/70696d17ea67de6acfd25501ee9188623fc8d3b2.pdf","TL;DR":"A systematic way to design a fixed-size learnable filters to extract feature from nodes and strength of correlation for both directed and undirected  graph.","paperhash":"anonymous|topology_adaptive_graph_convolutional_networks","_bibtex":"@article{\n  anonymous2018topology,\n  title={Topology Adaptive Graph Convolutional  Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H113pWZRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper733/Authors"],"keywords":["graph convolutional neural networks","graph-structured data","semi-classification"]}},{"tddate":null,"ddate":null,"tmdate":1512222737544,"tcdate":1511752007002,"number":1,"cdate":1511752007002,"id":"H1kIb-Kef","invitation":"ICLR.cc/2018/Conference/-/Paper733/Official_Review","forum":"H113pWZRb","replyto":"H113pWZRb","signatures":["ICLR.cc/2018/Conference/Paper733/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Major revision is recommended","rating":"4: Ok but not good enough - rejection","review":"In this paper a new neural network architecture for semi-supervised graph classification is proposed. The new construction builds upon graph polynomial filters and utilizes them on each successive layer of the neural network with ReLU activation functions.\n\nIn my opinion writing of this paper requires major revision. The first 8 pages mostly constitute a literature review and experimental section provides no insights about the performance of the TAGCN besides the slight improvement of the Cora, Pubmed and Citeseer benchmarks.\n\nThe one layer analysis in sections 2.1, 2.2 and 2.3 is simply an explanation of graph polynomial filters, which were previously proposed and analyzed in cited work of Sandryhaila and Moura (2013). Together with the summary of other methods and introduction, it composes the first 8 pages of the paper. I think that the graph polynomial filters can be summarized in much more succinct way and details deferred to the appendix for interested reader. I also recommend stating which ideas came from the Sandryhaila and Moura (2013) work in a more pronounced manner.\n\nNext, I disagree with the statement that \"it is not clear how to keep the vertex local property when filtering in the spectrum domain\". Graph Laplacian preserves the information about connectivity of the vertices and filtering in the vertex domain can be done via polynomial filters in the Fourier domain. See Eq. 18 and 19 in [1].\n\nFinally, I should say that TAGCN idea is interesting. I think it can be viewed as an extension of the GCN (Kipf and Welling, 2017), where instead of an adjacency matrix with self connections (i.e. first degree polynomial), a higher degree graph polynomial filter is used on every layer (please correct me if this comparison is not accurate). With more experiments and interpretation of the model, including some sort of multilayer analysis, this can be a good acceptance candidate.\n\n\n[1] David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst.\nThe emerging field of signal processing on graphs: Extending high-dimensional data analysis to\nnetworks and other irregular domains. IEEE Signal Processing Magazine, 30(3):83–98, 2013.","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Topology Adaptive Graph Convolutional  Networks","abstract":"Convolution acts as a local feature extractor in convolutional neural networks (CNNs). However, the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks, citation networks, or knowledge graphs. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution, replacing the square filter for the grid-structured data in traditional CNNs. The outputs are the weighted sum of these filters’ outputs, extraction of both vertex features and strength of correlation between vertices. It can be used with both directed and undirected graphs. The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution in traditional signal processing. We apply TAGCN to semi-supervised learning problems for graph vertex classification; experiments on a number of data sets demonstrate that our method outperforms the existing graph convolutional neural networks and achieves state-of-the-art performance for each data set tested.","pdf":"/pdf/70696d17ea67de6acfd25501ee9188623fc8d3b2.pdf","TL;DR":"A systematic way to design a fixed-size learnable filters to extract feature from nodes and strength of correlation for both directed and undirected  graph.","paperhash":"anonymous|topology_adaptive_graph_convolutional_networks","_bibtex":"@article{\n  anonymous2018topology,\n  title={Topology Adaptive Graph Convolutional  Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H113pWZRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper733/Authors"],"keywords":["graph convolutional neural networks","graph-structured data","semi-classification"]}},{"tddate":null,"ddate":null,"tmdate":1509739134884,"tcdate":1509133735158,"number":733,"cdate":1509739132224,"id":"H113pWZRb","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"H113pWZRb","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Topology Adaptive Graph Convolutional  Networks","abstract":"Convolution acts as a local feature extractor in convolutional neural networks (CNNs). However, the convolution operation is not applicable when the input data is supported on an irregular graph such as with social networks, citation networks, or knowledge graphs. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network that generalizes CNN architectures to graph-structured data and provides a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution, replacing the square filter for the grid-structured data in traditional CNNs. The outputs are the weighted sum of these filters’ outputs, extraction of both vertex features and strength of correlation between vertices. It can be used with both directed and undirected graphs. The proposed TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution in traditional signal processing. We apply TAGCN to semi-supervised learning problems for graph vertex classification; experiments on a number of data sets demonstrate that our method outperforms the existing graph convolutional neural networks and achieves state-of-the-art performance for each data set tested.","pdf":"/pdf/70696d17ea67de6acfd25501ee9188623fc8d3b2.pdf","TL;DR":"A systematic way to design a fixed-size learnable filters to extract feature from nodes and strength of correlation for both directed and undirected  graph.","paperhash":"anonymous|topology_adaptive_graph_convolutional_networks","_bibtex":"@article{\n  anonymous2018topology,\n  title={Topology Adaptive Graph Convolutional  Networks},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=H113pWZRb}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper733/Authors"],"keywords":["graph convolutional neural networks","graph-structured data","semi-classification"]},"nonreaders":[],"replyCount":3,"writable":false,"revisions":true,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}