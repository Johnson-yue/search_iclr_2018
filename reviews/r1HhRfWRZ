{"notes":[{"tddate":null,"ddate":null,"tmdate":1512222547832,"tcdate":1511845221641,"number":2,"cdate":1511845221641,"id":"ryAPav5lz","invitation":"ICLR.cc/2018/Conference/-/Paper1065/Official_Review","forum":"r1HhRfWRZ","replyto":"r1HhRfWRZ","signatures":["ICLR.cc/2018/Conference/Paper1065/AnonReviewer2"],"readers":["everyone"],"content":{"title":"Learning a world representation through state prediction, implemented and evaluated in an unclear manner.","rating":"4: Ok but not good enough - rejection","review":"Summary:\nThe paper describes a system which creates an internal representation of the scene given observations, being this internal representation advantageous over raw sensory input for object classification and control. The internal representation comes from a recurrent network (more specifically, a sequence2sequence net) trained to maximize the likelihood of the observations from training\n\nPositive aspects:\nThe authors suggest an interesting hypothesis: an internal representation of the world which is useful for control could be obtained just by forcing the agent to be able to predict the outcome of its actions in the world. This hypothesis would enable robots to train it in a self-supervised manner, which would be extremely valuable.\n\nNegative aspects:\nAlthough the premise of the paper is interesting, its execution is not ideal. The formulation of the problem is unclear and difficult to follow, with a number of important terms left undefined. Moreover, the experiment task is too simplistic; from the results, it's not clear whether the representation is anything more than trivial accumulation of sensory input\n\n- Lack of clarity:\n-- what exactly is the \"generic cost\" C in section 7.1?\n-- why are both f and z parameters of C? f is directly a function of z. Given that the form of C is not explained, seems like f could be directly computing as part of C.\n-- what is the relation between actions a in section 7.1 and u in section 4?\n-- How is the minimization problem of u_{1:T} solved?\n-- Are the authors sure that they perform gathering information through \"maximizing uncertainty\" (section 7.1)? This sounds profoundly counterintuitive. Maximizing the uncertainty in the world state should result in minimum information about the worlds state. I would assume this is a serious typo, but cannot confirm given that the relation between the minimize cost C and the Renyi entropy H is not explicitely stated. \n-- When the authors state that \"The learner trains the model by maximum likelihood\" in section 7.1, do they refer to the prediction model or the control model? It would seem that it is the control model, but the objective being \"the same as in section 6\" points in the opposite direction\n-- What is the method for classifying and/or regressing given the features and internal representation? This is important because, if the method was a recurrent net with memory, the differences between the two representations would probably be minimal.\n\n- Simplistic experimental task:\nMy main intake from the experiments is that having a recurrent network processing the sensory input provides some \"memory\" to the system which reduces uncertainty when sensory data is ambiguous. This is visible from the fact that the performance from both systems is comparable at the beginning, but degrades for sensory input when the hand is open. This could be achievable in many simple ways, like modeling the classification/regression problem directly with an LSTM for example. Simpler modalities of providing a memory to the system should be used as a baseline.\n\n\nConclusion:\nAlthough the idea of learning an internal representation of the world by being able to predict its state from observations is interesting, the presented paper is a) too simplistic in its experimental evaluation and b) too unclear about its implementation. Consequently, I believe the authors should improve these aspects before the article is valuable to the community\n\n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Awareness Models","abstract":"We consider the setting of an agent with a fixed body interacting with an unknown and uncertain external world.  In this setting we show how predictive models of proprioception can be used to reason about interactions between our agent and external objects.  Such models are appealing because they can be fit using data that is readily available to the agent through the course of its existence without requiring access to privileged information about the state of the external world.  In spite being trained with only internally available signals these predictive models come to represent external objects through the necessity of predicting their effects on the agent's own body.  We demonstrate this in simulation by using the proprioceptive models to make predictions about properties of external objects.  We also collect data from a real robotic platform and show that the same models can be used to answer questions about properties of objects in the real world.\n","pdf":"/pdf/65f824e1d702c5e541a08c20c9700fd3c3c6aa8f.pdf","TL;DR":"We train predictive models on proprioceptive information and show they represent properties of external objects.","paperhash":"anonymous|learning_awareness_models","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Awareness Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1HhRfWRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1065/Authors"],"keywords":["Awareness","Prediction","Seq2seq","Robots"]}},{"tddate":null,"ddate":null,"tmdate":1512222547882,"tcdate":1511645640760,"number":1,"cdate":1511645640760,"id":"BJb0-vDxz","invitation":"ICLR.cc/2018/Conference/-/Paper1065/Official_Review","forum":"r1HhRfWRZ","replyto":"r1HhRfWRZ","signatures":["ICLR.cc/2018/Conference/Paper1065/AnonReviewer1"],"readers":["everyone"],"content":{"title":"Great Paper","rating":"9: Top 15% of accepted papers, strong accept","review":"The paper proposes an architecture for internal model learning of a robotic system and applies it to a simulated and a real robotic hand.  The model allows making relatively long-term predictions with uncertainties. The models are used to perform model predictive control to achieve informative actions. It is shown that the hidden state of the learned models contains relevant information about the objects the hand was interacting with. \n\nThe paper reads well. The method is sufficiently well explained and the results are presented in an illustrative and informative way. I have only a few minor points:\n\n- Sec 2: you may consider to cite the work on maximising predictive information as intrinsic motivation:\nG. Martius, R. Der, and N. Ay. Information driven self-organization of complex robotic behaviors. PLoS ONE, 8(5):e63400, 2013.\n- Fig 2: bottom: add labels to axis, and maybe mention that same color code as above\n- Sec 4 par 3: .... intentionally not autoregressive: w.r.t. to what? to the observations? \n- Sec 7.1: how is the optimization for the MPC performed? Which algorithm did you use and long does the optimization take? \n in first Eq: should f not be sampled from GMMpdf, so replace = with \\sim\n\nTypos:\n- Sec1 par2: This pattern has has ...\n- Sec 2 par2: statistics ofthe\n- Sec 4 line2: prefix of an episode , where  (space before ,)\n \n","confidence":"4: The reviewer is confident but not absolutely certain that the evaluation is correct"},"writers":[],"nonreaders":[],"replyCount":0,"writable":false,"revisions":false,"tags":[],"forumContent":{"title":"Learning Awareness Models","abstract":"We consider the setting of an agent with a fixed body interacting with an unknown and uncertain external world.  In this setting we show how predictive models of proprioception can be used to reason about interactions between our agent and external objects.  Such models are appealing because they can be fit using data that is readily available to the agent through the course of its existence without requiring access to privileged information about the state of the external world.  In spite being trained with only internally available signals these predictive models come to represent external objects through the necessity of predicting their effects on the agent's own body.  We demonstrate this in simulation by using the proprioceptive models to make predictions about properties of external objects.  We also collect data from a real robotic platform and show that the same models can be used to answer questions about properties of objects in the real world.\n","pdf":"/pdf/65f824e1d702c5e541a08c20c9700fd3c3c6aa8f.pdf","TL;DR":"We train predictive models on proprioceptive information and show they represent properties of external objects.","paperhash":"anonymous|learning_awareness_models","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Awareness Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1HhRfWRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1065/Authors"],"keywords":["Awareness","Prediction","Seq2seq","Robots"]}},{"tddate":null,"ddate":null,"tmdate":1510092381361,"tcdate":1509138093489,"number":1065,"cdate":1510092360219,"id":"r1HhRfWRZ","invitation":"ICLR.cc/2018/Conference/-/Blind_Submission","forum":"r1HhRfWRZ","signatures":["ICLR.cc/2018/Conference"],"readers":["everyone"],"writers":["ICLR.cc/2018/Conference"],"content":{"title":"Learning Awareness Models","abstract":"We consider the setting of an agent with a fixed body interacting with an unknown and uncertain external world.  In this setting we show how predictive models of proprioception can be used to reason about interactions between our agent and external objects.  Such models are appealing because they can be fit using data that is readily available to the agent through the course of its existence without requiring access to privileged information about the state of the external world.  In spite being trained with only internally available signals these predictive models come to represent external objects through the necessity of predicting their effects on the agent's own body.  We demonstrate this in simulation by using the proprioceptive models to make predictions about properties of external objects.  We also collect data from a real robotic platform and show that the same models can be used to answer questions about properties of objects in the real world.\n","pdf":"/pdf/65f824e1d702c5e541a08c20c9700fd3c3c6aa8f.pdf","TL;DR":"We train predictive models on proprioceptive information and show they represent properties of external objects.","paperhash":"anonymous|learning_awareness_models","_bibtex":"@article{\n  anonymous2018learning,\n  title={Learning Awareness Models},\n  author={Anonymous},\n  journal={International Conference on Learning Representations},\n  year={2018},\n  url={https://openreview.net/forum?id=r1HhRfWRZ}\n}","authors":["Anonymous"],"authorids":["ICLR.cc/2018/Conference/Paper1065/Authors"],"keywords":["Awareness","Prediction","Seq2seq","Robots"]},"nonreaders":[],"replyCount":2,"writable":false,"revisions":false,"tags":[],"forumContent":null,"tauthor":"ICLR.cc/2018/Conference"}],"limit":2000,"offset":0}